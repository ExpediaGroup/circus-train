[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.hotels:circus-train-integration-tests:jar:11.5.1-SNAPSHOT
[WARNING] 'dependencies.dependency.(groupId:artifactId:type:classifier)' must be unique: com.hotels:circus-train-common-test:jar -> duplicate declaration of version ${project.version} @ com.hotels:circus-train-integration-tests:[unknown-version], /Users/cedwards/Documents/workspace/circus-train/circus-train-integration-tests/pom.xml, line 115, column 17
[WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-surefire-plugin is missing. @ com.hotels:circus-train-integration-tests:[unknown-version], /Users/cedwards/Documents/workspace/circus-train/circus-train-integration-tests/pom.xml, line 164, column 15
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO] Inspecting build with total of 25 modules...
[INFO] Installing Nexus Staging features:
[INFO]   ... total of 25 executions of maven-deploy-plugin replaced with nexus-staging-maven-plugin
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Circus Train Parent
[INFO] API
[INFO] Circus Train Avro
[INFO] Hive
[INFO] Comparator
[INFO] Core
[INFO] AWS utils
[INFO] Metrics
[INFO] DistCp Copier
[INFO] Google Cloud Platform Utils
[INFO] Common Test Classes
[INFO] S3 MapReduce Copy
[INFO] S3MapReduceCp Copier
[INFO] S3 To S3 Copier
[INFO] Circus Train Housekeeping
[INFO] Hive View
[INFO] Integration Tests
[INFO] CT packager
[INFO] AWS/SNS Events
[INFO] Tools Parent
[INFO] Tools Core
[INFO] Filter tool
[INFO] Vacuum tool
[INFO] Comparison tool
[INFO] Tool Package
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Circus Train Parent 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-parent ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-parent ---
[INFO] Skipping cobertura mojo for project with packaging type 'pom'
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-parent ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-parent ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-parent ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-parent ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-parent ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-parent/11.5.1-SNAPSHOT/circus-train-parent-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building API 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-api ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-api/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-api ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-api ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-api ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-api/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-api ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-api ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-api ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-api/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-api ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 40 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-api/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-api ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-api/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-api ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 6 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-api/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-api ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-api/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.api.copier.CompositeCopierFactoryTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.254 sec
Running com.hotels.bdp.circustrain.api.copier.CopierPathGeneratorTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 sec
Running com.hotels.bdp.circustrain.api.copier.MetricsMergerTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.017 sec
Running com.hotels.bdp.circustrain.api.metadata.ColumnStatisticsTransformationTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.028 sec
Running com.hotels.bdp.circustrain.api.metadata.PartitionTransformationTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.044 sec
Running com.hotels.bdp.circustrain.api.metadata.TableTransformationTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.004 sec

Results :

Tests run: 10, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-api ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-api/target/circus-train-api-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-api ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-api/target/circus-train-api-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-api/11.5.1-SNAPSHOT/circus-train-api-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-api/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-api/11.5.1-SNAPSHOT/circus-train-api-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Circus Train Avro 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-avro ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-avro/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-avro ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-avro ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-avro ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-avro/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-avro ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-avro ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-avro ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-avro/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-avro ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 9 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-avro/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-avro ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-avro ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 8 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-avro/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-avro ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-avro/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.avro.hive.HiveObjectUtilsTest
Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.119 sec
Running com.hotels.bdp.circustrain.avro.transformation.AvroSerDePartitionTransformationTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.371 sec
Running com.hotels.bdp.circustrain.avro.transformation.AvroSerDeTableTransformationTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.007 sec
Running com.hotels.bdp.circustrain.avro.transformation.AvroSerDeTransformationTest
2018-05-25 11:38:38,595 INFO  org.apache.hadoop.hive.conf.HiveConf:181 - Found configuration file null
2018-05-25 11:38:39,262 WARN  org.apache.hadoop.util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-25 11:38:39,372 INFO  com.hotels.bdp.circustrain.avro.transformation.AvroSerDeTransformation:70 - Avro schema has been copied from '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8448600158634997932/junit2617713667104117539.tmp' to '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8448600158634997932/junit7501876067583459018/1'
2018-05-25 11:38:39,373 INFO  com.hotels.bdp.circustrain.avro.transformation.AvroSerDeTransformation:121 - Avro SerDe transformation has been applied to partition 'Partition(values:null, dbName:null, tableName:null, createTime:0, lastAccessTime:0, sd:null, parameters:{avro.schema.url=/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8448600158634997932/junit7501876067583459018/1/junit2617713667104117539.tmp})'
2018-05-25 11:38:39,550 INFO  com.hotels.bdp.circustrain.avro.transformation.AvroSerDeTransformation:70 - Avro schema has been copied from '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8414086026869944919/junit3577823884573169023.tmp' to '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8414086026869944919/junit155490853211109798/1'
2018-05-25 11:38:39,550 INFO  com.hotels.bdp.circustrain.avro.transformation.AvroSerDeTransformation:104 - Avro SerDe transformation has been applied to table 'null'
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.126 sec
Running com.hotels.bdp.circustrain.avro.util.AvroStringUtilsTest
Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.007 sec
Running com.hotels.bdp.circustrain.avro.util.NameServicePathResolverTest
2018-05-25 11:38:39,761 INFO  com.hotels.bdp.circustrain.avro.util.NameServicePathResolver:52 - Added nameservice to path. hdfs:/etl/test/avsc/schema.avsc became hdfs://hdp-ha/etl/test/avsc/schema.avsc
2018-05-25 11:38:39,791 INFO  com.hotels.bdp.circustrain.avro.util.NameServicePathResolver:52 - Added nameservice to path. /etl/test/avsc/schema.avsc became /hdp-ha/etl/test/avsc/schema.avsc
2018-05-25 11:38:39,801 INFO  com.hotels.bdp.circustrain.avro.util.NameServicePathResolver:52 - Added nameservice to path. hdfs:///etl/test/avsc/schema.avsc became hdfs://hdp-ha/etl/test/avsc/schema.avsc
Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.098 sec
Running com.hotels.bdp.circustrain.avro.util.SchemaCopierTest
2018-05-25 11:38:39,906 INFO  com.hotels.bdp.circustrain.avro.util.SchemaCopier:87 - Copy from /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5446795797598704908/test.txt to /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/avro-schema-download-folder3584390935688604361/test.txt succeeded
2018-05-25 11:38:39,917 INFO  com.hotels.bdp.circustrain.avro.util.SchemaCopier:67 - Avro schema has been copied from '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5446795797598704908/test.txt' to '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5446795797598704908/junit7008073116468204688/test.txt'
2018-05-25 11:38:40,062 INFO  com.hotels.bdp.circustrain.avro.util.SchemaCopier:87 - Copy from /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3835939127432833951/test.txt to /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/avro-schema-download-folder6687876180455756551/test.txt succeeded
2018-05-25 11:38:40,076 INFO  com.hotels.bdp.circustrain.avro.util.SchemaCopier:67 - Avro schema has been copied from '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3835939127432833951/test.txt' to '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3835939127432833951/junit4290467685154286930/test.txt'
2018-05-25 11:38:40,213 INFO  com.hotels.bdp.circustrain.avro.util.SchemaCopier:87 - Copy from /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7172561357372336226/test.txt to /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/avro-schema-download-folder6646486184784918575/test.txt succeeded
2018-05-25 11:38:40,422 INFO  com.hotels.bdp.circustrain.avro.util.SchemaCopier:87 - Copy from /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4530714650062210953/test.txt to /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/avro-schema-download-folder7534112597840528943/test.txt succeeded
2018-05-25 11:38:40,433 INFO  com.hotels.bdp.circustrain.avro.util.SchemaCopier:67 - Avro schema has been copied from '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4530714650062210953/test.txt' to '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4530714650062210953/junit7468549472150266066/test.txt'
2018-05-25 11:38:40,508 INFO  com.hotels.bdp.circustrain.avro.util.SchemaCopier:87 - Copy from /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4403691893125955663/test.txt to /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/avro-schema-download-folder5289717219455032408/test.txt succeeded
2018-05-25 11:38:40,518 INFO  com.hotels.bdp.circustrain.avro.util.SchemaCopier:67 - Avro schema has been copied from '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4403691893125955663/test.txt' to '/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4403691893125955663/junit1865956609597102625/test.txt'
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.746 sec

Results :

Tests run: 66, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-avro ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-avro/target/circus-train-avro-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-avro ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-avro/target/circus-train-avro-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-avro/11.5.1-SNAPSHOT/circus-train-avro-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-avro/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-avro/11.5.1-SNAPSHOT/circus-train-avro-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-hive ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-hive/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-hive ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-hive ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-hive ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-hive/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-hive ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-hive ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-hive ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-hive/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-hive ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 6 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-hive/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-hive ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-hive/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-hive ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 2 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-hive/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-hive ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-hive/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcherTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.738 sec
Running com.hotels.bdp.circustrain.hive.parser.HiveLanguageParserTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.255 sec

Results :

Tests run: 6, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-hive ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-hive/target/circus-train-hive-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-hive ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-hive/target/circus-train-hive-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-hive/11.5.1-SNAPSHOT/circus-train-hive-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-hive/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-hive/11.5.1-SNAPSHOT/circus-train-hive-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Comparator 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-comparator ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-comparator ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-comparator ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-comparator ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-comparator ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-comparator ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-comparator ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-comparator ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 23 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[WARNING] /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/src/main/java/com/hotels/bdp/circustrain/comparator/hive/wrappers/PartitionAndMetadata.java:[49,9] toStringHelper(java.lang.Object) in com.google.common.base.Objects has been deprecated
[WARNING] /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/src/main/java/com/hotels/bdp/circustrain/comparator/api/BaseDiff.java:[48,19] toStringHelper(java.lang.Object) in com.google.common.base.Objects has been deprecated
[WARNING] /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/src/main/java/com/hotels/bdp/circustrain/comparator/hive/wrappers/TableAndMetadata.java:[49,9] toStringHelper(java.lang.Object) in com.google.common.base.Objects has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-comparator ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-comparator ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 14 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/src/test/java/com/hotels/bdp/circustrain/comparator/hive/HiveDifferencesIntegrationTest.java: Some input files use unchecked or unsafe operations.
[INFO] /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/src/test/java/com/hotels/bdp/circustrain/comparator/hive/HiveDifferencesIntegrationTest.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-comparator ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.comparator.comparator.AbstractComparatorTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.202 sec
Running com.hotels.bdp.circustrain.comparator.ComparatorRegistryTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.01 sec
Running com.hotels.bdp.circustrain.comparator.hive.comparator.FieldSchemaComparatorTest
Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.167 sec
Running com.hotels.bdp.circustrain.comparator.hive.comparator.PartitionAndMetadataComparatorTest
Tests run: 34, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.06 sec
Running com.hotels.bdp.circustrain.comparator.hive.comparator.TableAndMetadataComparatorTest
Tests run: 42, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.032 sec
Running com.hotels.bdp.circustrain.comparator.hive.functions.CleanPartitionFunctionTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.comparator.hive.functions.CleanTableFunctionTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec
Running com.hotels.bdp.circustrain.comparator.hive.functions.PathDigestTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.107 sec
Running com.hotels.bdp.circustrain.comparator.hive.functions.PathToPathMetadataIntegrationTest
2018-05-25 11:38:45,863 WARN  org.apache.hadoop.util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.312 sec
Running com.hotels.bdp.circustrain.comparator.hive.functions.PathToPathMetadataTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.047 sec
Running com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest
2018-05-25 11:38:46,033 INFO  org.apache.hadoop.hive.conf.HiveConf:181 - Found configuration file null
2018-05-25 11:38:46,403 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:46,442 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:46,941 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:bf5879dd-6fb0-462c-a764-fba79c208a9d;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:38:47,705 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:38:48,511 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:bf5879dd-6fb0-462c-a764-fba79c208a9d;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:38:49,232 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:49,234 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:49,291 WARN  org.apache.hadoop.hive.metastore.ObjectStore:7566 - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
2018-05-25 11:38:49,291 WARN  org.apache.hadoop.hive.metastore.ObjectStore:7654 - setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore cedwards@172.21.175.71
2018-05-25 11:38:49,297 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:38:49,439 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:38:49,440 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:38:49,480 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:38:49,591 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:38:49,596 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58181]...
2018-05-25 11:38:49,596 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:38:49,596 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:38:49,597 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:38:50,641 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58181
2018-05-25 11:38:50,659 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:38:50,710 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:38:50,711 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58181
2018-05-25 11:38:50,712 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:38:50,714 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:38:50,718 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 2: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2940741760903943372/ct_database, parameters:null)
2018-05-25 11:38:50,719 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2940741760903943372/ct_database, parameters:null)	
2018-05-25 11:38:50,744 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:50,745 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:50,751 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:50,752 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:50,753 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:38:50,755 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2940741760903943372/ct_database
2018-05-25 11:38:50,777 DEBUG shims.HdfsUtils:200 - {-chgrp,-R,SEA\Domain,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2940741760903943372/ct_database}
2018-05-25 11:38:50,799 DEBUG shims.HdfsUtils:202 - Return value is :-1
2018-05-25 11:38:50,799 DEBUG shims.HdfsUtils:200 - {-chmod,-R,755,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2940741760903943372/ct_database}
2018-05-25 11:38:50,811 DEBUG shims.HdfsUtils:202 - Return value is :0
2018-05-25 11:38:50,819 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:38:50,821 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:50,824 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:50,824 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:50,824 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 2: Cleaning up thread local RawStore...
2018-05-25 11:38:50,824 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:38:50,824 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 2: Done cleaning up thread local RawStore
2018-05-25 11:38:50,825 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:38:50,834 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7632483391850542361/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:38:50,834 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7632483391850542361/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:38:50,856 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:50,857 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:50,860 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:50,860 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:50,886 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7632483391850542361/source-warehouse/ct_database/ct_table_1/ specified for non-external table:ct_table_1
2018-05-25 11:38:51,006 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,008 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,008 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,008 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 add_partition
2018-05-25 11:38:51,009 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:38:51,009 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: add_partitions
2018-05-25 11:38:51,009 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:38:51,086 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:38:51,086 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:38:51,088 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:38:51,088 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:38:51,125 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:38:51,128 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,130 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,130 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,131 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7632483391850542361/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7632483391850542361/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:38:51,131 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7632483391850542361/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7632483391850542361/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:38:51,133 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7632483391850542361/replica-warehouse/ct_database/ct_table_2/ specified for non-external table:ct_table_2
2018-05-25 11:38:51,164 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,167 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,167 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,167 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 add_partition
2018-05-25 11:38:51,167 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:38:51,168 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: add_partitions
2018-05-25 11:38:51,168 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:38:51,178 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:38:51,179 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:38:51,180 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:38:51,180 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:38:51,213 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:38:51,219 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,221 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,221 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,222 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:38:51,223 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:51,233 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:118 - >>>> Source Table = Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:1527244730, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7632483391850542361/source-warehouse/ct_database/ct_table_1, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244730}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:38:51,234 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,236 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,236 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,237 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:38:51,237 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:51,246 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:119 - >>>> Replica Table = Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:1527244731, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7632483391850542361/replica-warehouse/ct_database/ct_table_2, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244731, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7632483391850542361/source-warehouse/ct_database/ct_table_1/, com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:38:51,247 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,249 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,249 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,250 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:38:51,250 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:51,263 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,265 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,265 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,265 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 alter_table: db=ct_database tbl=ct_table_1 newtbl=ct_table_1
2018-05-25 11:38:51,265 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: db=ct_database tbl=ct_table_1 newtbl=ct_table_1	
2018-05-25 11:38:51,316 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,319 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,319 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,320 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:38:51,320 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:51,328 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,330 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,330 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,330 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:38:51,331 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:51,340 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:41 - Fetching all partition names.
2018-05-25 11:38:51,345 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,347 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,347 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,347 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1
2018-05-25 11:38:51,347 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:51,370 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:43 - Fetched 2 partition names for table ct_database.ct_table_1.
2018-05-25 11:38:51,370 DEBUG com.hotels.hcommon.hive.metastore.iterator.BatchResolver:42 - Number of partitions (2) is less than batch size (3).
2018-05-25 11:38:51,371 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:49 - Fetching all partition names.
2018-05-25 11:38:51,372 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,374 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,375 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,375 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2
2018-05-25 11:38:51,375 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:51,383 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:51 - Fetched 2 partition names for table ct_database.ct_table_2.
2018-05-25 11:38:51,389 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,391 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,391 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,391 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1
2018-05-25 11:38:51,392 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:51,443 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:81 - Retrieved 2 partitions, total: 2.
2018-05-25 11:38:51,443 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:82 - Fetching 2 partitions.
2018-05-25 11:38:51,444 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,446 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,446 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,447 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2
2018-05-25 11:38:51,447 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:51,480 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:85 - Fetched 2 partitions for table ct_database.ct_table_2.
2018-05-25 11:38:51,482 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:38:51,482 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,484 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:51,484 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:51,484 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: Cleaning up thread local RawStore...
2018-05-25 11:38:51,485 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:38:51,485 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: Done cleaning up thread local RawStore
2018-05-25 11:38:51,485 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:38:51,553 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:51,556 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:51,772 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:6b2a5230-4d05-4f2e-92d5-2e6dc09e2687;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:38:51,905 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:38:51,966 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:6b2a5230-4d05-4f2e-92d5-2e6dc09e2687;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:38:52,456 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:52,456 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:52,458 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:38:52,508 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:38:52,509 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:38:52,532 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:38:52,532 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:38:52,533 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58184]...
2018-05-25 11:38:52,533 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:38:52,533 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:38:52,533 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:38:53,561 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58184
2018-05-25 11:38:53,562 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:38:53,563 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:38:53,564 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58184
2018-05-25 11:38:53,564 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:38:53,565 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:38:53,565 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 5: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit1587319044561448211/ct_database, parameters:null)
2018-05-25 11:38:53,566 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit1587319044561448211/ct_database, parameters:null)	
2018-05-25 11:38:53,585 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:53,586 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,593 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,593 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,594 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:38:53,595 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit1587319044561448211/ct_database
2018-05-25 11:38:53,603 DEBUG shims.HdfsUtils:200 - {-chgrp,-R,SEA\Domain,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit1587319044561448211/ct_database}
2018-05-25 11:38:53,604 DEBUG shims.HdfsUtils:202 - Return value is :-1
2018-05-25 11:38:53,604 DEBUG shims.HdfsUtils:200 - {-chmod,-R,755,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit1587319044561448211/ct_database}
2018-05-25 11:38:53,612 DEBUG shims.HdfsUtils:202 - Return value is :0
2018-05-25 11:38:53,615 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:38:53,616 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,617 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5588257699035448845/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:38:53,617 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5588257699035448845/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:38:53,618 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,618 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,618 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 5: Cleaning up thread local RawStore...
2018-05-25 11:38:53,619 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:38:53,619 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 5: Done cleaning up thread local RawStore
2018-05-25 11:38:53,619 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:38:53,636 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:53,637 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,639 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,639 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,650 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5588257699035448845/source-warehouse/ct_database/ct_table_1/ specified for non-external table:ct_table_1
2018-05-25 11:38:53,714 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,715 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,715 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,716 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 add_partition
2018-05-25 11:38:53,716 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:38:53,716 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: add_partitions
2018-05-25 11:38:53,716 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:38:53,766 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:38:53,767 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:38:53,767 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:38:53,768 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:38:53,790 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:38:53,793 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,795 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,795 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,795 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5588257699035448845/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5588257699035448845/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:38:53,795 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5588257699035448845/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5588257699035448845/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:38:53,796 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5588257699035448845/replica-warehouse/ct_database/ct_table_2/ specified for non-external table:ct_table_2
2018-05-25 11:38:53,805 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,806 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,806 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,807 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 add_partition
2018-05-25 11:38:53,807 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:38:53,807 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: add_partitions
2018-05-25 11:38:53,807 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:38:53,815 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:38:53,815 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:38:53,816 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:38:53,816 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:38:53,836 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:38:53,837 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,838 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,838 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,839 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:38:53,839 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:53,845 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:118 - >>>> Source Table = Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:1527244733, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5588257699035448845/source-warehouse/ct_database/ct_table_1, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244733}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:38:53,846 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,848 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,848 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,848 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:38:53,848 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:53,856 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:119 - >>>> Replica Table = Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:1527244733, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5588257699035448845/replica-warehouse/ct_database/ct_table_2, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244733, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5588257699035448845/source-warehouse/ct_database/ct_table_1/, com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:38:53,857 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,858 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,858 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,859 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:38:53,859 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:53,866 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,868 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,868 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,868 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:38:53,869 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:53,876 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:41 - Fetching all partition names.
2018-05-25 11:38:53,878 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,879 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,879 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,879 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1
2018-05-25 11:38:53,879 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:53,892 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:43 - Fetched 2 partition names for table ct_database.ct_table_1.
2018-05-25 11:38:53,892 DEBUG com.hotels.hcommon.hive.metastore.iterator.BatchResolver:42 - Number of partitions (2) is less than batch size (3).
2018-05-25 11:38:53,892 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:49 - Fetching all partition names.
2018-05-25 11:38:53,893 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,894 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,894 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,895 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2
2018-05-25 11:38:53,895 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:53,901 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:51 - Fetched 2 partition names for table ct_database.ct_table_2.
2018-05-25 11:38:53,902 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,904 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,904 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,904 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1
2018-05-25 11:38:53,904 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:53,936 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:81 - Retrieved 2 partitions, total: 2.
2018-05-25 11:38:53,936 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:82 - Fetching 2 partitions.
2018-05-25 11:38:53,936 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,938 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,938 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,938 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2
2018-05-25 11:38:53,938 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:53,966 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:85 - Fetched 2 partitions for table ct_database.ct_table_2.
2018-05-25 11:38:53,968 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:38:53,969 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:53,971 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:53,971 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:53,971 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: Cleaning up thread local RawStore...
2018-05-25 11:38:53,972 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:38:53,972 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: Done cleaning up thread local RawStore
2018-05-25 11:38:53,972 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:38:54,034 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:54,035 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:54,240 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:86e9e096-4b64-46f7-944d-24492d086da3;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:38:54,330 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:38:54,375 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:86e9e096-4b64-46f7-944d-24492d086da3;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:38:54,926 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:54,926 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:54,929 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:38:54,980 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:38:54,982 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:38:55,004 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:38:55,005 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:38:55,005 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58187]...
2018-05-25 11:38:55,005 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:38:55,005 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:38:55,005 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:38:56,031 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58187
2018-05-25 11:38:56,031 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:38:56,033 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:38:56,033 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58187
2018-05-25 11:38:56,034 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:38:56,035 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:38:56,035 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 8: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3585469317689706764/ct_database, parameters:null)
2018-05-25 11:38:56,035 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3585469317689706764/ct_database, parameters:null)	
2018-05-25 11:38:56,052 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:56,053 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,060 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,060 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,061 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:38:56,062 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3585469317689706764/ct_database
2018-05-25 11:38:56,069 DEBUG shims.HdfsUtils:200 - {-chgrp,-R,SEA\Domain,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3585469317689706764/ct_database}
2018-05-25 11:38:56,069 DEBUG shims.HdfsUtils:202 - Return value is :-1
2018-05-25 11:38:56,069 DEBUG shims.HdfsUtils:200 - {-chmod,-R,755,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3585469317689706764/ct_database}
2018-05-25 11:38:56,076 DEBUG shims.HdfsUtils:202 - Return value is :0
2018-05-25 11:38:56,079 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:38:56,080 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,081 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7578522844724139281/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:38:56,081 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7578522844724139281/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:38:56,082 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,082 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,082 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 8: Cleaning up thread local RawStore...
2018-05-25 11:38:56,082 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:38:56,083 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 8: Done cleaning up thread local RawStore
2018-05-25 11:38:56,083 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:38:56,099 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:56,100 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,102 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,102 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,111 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7578522844724139281/source-warehouse/ct_database/ct_table_1/ specified for non-external table:ct_table_1
2018-05-25 11:38:56,156 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,158 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,158 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,158 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 add_partition
2018-05-25 11:38:56,158 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:38:56,158 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: add_partitions
2018-05-25 11:38:56,158 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:38:56,198 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:38:56,199 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:38:56,199 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:38:56,200 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:38:56,218 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:38:56,221 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,222 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,222 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,222 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7578522844724139281/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7578522844724139281/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:38:56,222 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7578522844724139281/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7578522844724139281/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:38:56,223 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7578522844724139281/replica-warehouse/ct_database/ct_table_2/ specified for non-external table:ct_table_2
2018-05-25 11:38:56,230 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,232 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,232 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,232 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 add_partition
2018-05-25 11:38:56,232 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:38:56,232 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: add_partitions
2018-05-25 11:38:56,232 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:38:56,238 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:38:56,239 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:38:56,239 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:38:56,239 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:38:56,255 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:38:56,256 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,258 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,258 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,258 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:38:56,258 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:56,264 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:118 - >>>> Source Table = Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:1527244736, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7578522844724139281/source-warehouse/ct_database/ct_table_1, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244736}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:38:56,266 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,267 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,267 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,267 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:38:56,268 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:56,273 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:119 - >>>> Replica Table = Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:1527244736, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7578522844724139281/replica-warehouse/ct_database/ct_table_2, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244736, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7578522844724139281/source-warehouse/ct_database/ct_table_1/, com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:38:56,274 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,276 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,276 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,276 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:38:56,276 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:56,287 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,288 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,288 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,289 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 add_partition : db=ct_database tbl=ct_table_1
2018-05-25 11:38:56,289 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:56,294 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:38:56,294 WARN  hive.log:380 - Updated size to 18
2018-05-25 11:38:56,300 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,302 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,302 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,302 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:38:56,302 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:56,307 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:41 - Fetching all partition names.
2018-05-25 11:38:56,308 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,309 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,310 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,310 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1
2018-05-25 11:38:56,310 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:56,324 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:43 - Fetched 3 partition names for table ct_database.ct_table_1.
2018-05-25 11:38:56,324 DEBUG com.hotels.hcommon.hive.metastore.iterator.BatchResolver:42 - Number of partitions (3) is less than batch size (3).
2018-05-25 11:38:56,324 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:49 - Fetching all partition names.
2018-05-25 11:38:56,325 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,326 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,327 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,327 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2
2018-05-25 11:38:56,327 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:56,334 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:51 - Fetched 2 partition names for table ct_database.ct_table_2.
2018-05-25 11:38:56,335 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,336 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,336 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,337 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1
2018-05-25 11:38:56,337 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:56,371 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:81 - Retrieved 3 partitions, total: 3.
2018-05-25 11:38:56,371 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:82 - Fetching 2 partitions.
2018-05-25 11:38:56,372 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,374 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,374 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,374 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2
2018-05-25 11:38:56,375 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:56,406 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:85 - Fetched 2 partitions for table ct_database.ct_table_2.
2018-05-25 11:38:56,411 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,412 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,412 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,413 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_1 part=part=2
2018-05-25 11:38:56,413 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_1 part=part=2	
2018-05-25 11:38:56,438 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:38:56,439 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,440 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:56,440 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:56,441 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: Cleaning up thread local RawStore...
2018-05-25 11:38:56,441 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:38:56,441 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: Done cleaning up thread local RawStore
2018-05-25 11:38:56,441 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:38:56,499 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:56,500 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:56,698 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:bf853e2c-66e0-4134-8202-873598cf0649;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:38:56,781 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:38:56,821 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:bf853e2c-66e0-4134-8202-873598cf0649;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:38:57,182 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:57,182 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:57,184 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:38:57,229 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:38:57,230 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:38:57,249 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:38:57,250 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:38:57,250 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58190]...
2018-05-25 11:38:57,250 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:38:57,250 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:38:57,250 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:38:58,271 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58190
2018-05-25 11:38:58,272 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:38:58,273 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:38:58,274 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58190
2018-05-25 11:38:58,274 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:38:58,275 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:38:58,276 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 11: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3444292619426913488/ct_database, parameters:null)
2018-05-25 11:38:58,276 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3444292619426913488/ct_database, parameters:null)	
2018-05-25 11:38:58,294 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:58,295 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,302 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,302 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,303 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:38:58,303 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3444292619426913488/ct_database
2018-05-25 11:38:58,311 DEBUG shims.HdfsUtils:200 - {-chgrp,-R,SEA\Domain,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3444292619426913488/ct_database}
2018-05-25 11:38:58,311 DEBUG shims.HdfsUtils:202 - Return value is :-1
2018-05-25 11:38:58,311 DEBUG shims.HdfsUtils:200 - {-chmod,-R,755,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3444292619426913488/ct_database}
2018-05-25 11:38:58,319 DEBUG shims.HdfsUtils:202 - Return value is :0
2018-05-25 11:38:58,322 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:38:58,322 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,323 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4723362105143354958/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:38:58,324 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4723362105143354958/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:38:58,324 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,324 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,324 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 11: Cleaning up thread local RawStore...
2018-05-25 11:38:58,325 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:38:58,325 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 11: Done cleaning up thread local RawStore
2018-05-25 11:38:58,325 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:38:58,340 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:58,341 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,344 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,344 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,352 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4723362105143354958/source-warehouse/ct_database/ct_table_1/ specified for non-external table:ct_table_1
2018-05-25 11:38:58,398 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,399 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,399 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,399 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 add_partition
2018-05-25 11:38:58,399 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:38:58,399 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: add_partitions
2018-05-25 11:38:58,399 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:38:58,431 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:38:58,432 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:38:58,432 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:38:58,432 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:38:58,451 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:38:58,453 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,455 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,455 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,455 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4723362105143354958/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4723362105143354958/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:38:58,455 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4723362105143354958/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4723362105143354958/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:38:58,456 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4723362105143354958/replica-warehouse/ct_database/ct_table_2/ specified for non-external table:ct_table_2
2018-05-25 11:38:58,464 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,465 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,465 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,465 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 add_partition
2018-05-25 11:38:58,465 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:38:58,465 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: add_partitions
2018-05-25 11:38:58,466 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:38:58,471 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:38:58,472 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:38:58,472 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:38:58,472 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:38:58,488 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:38:58,488 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,490 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,490 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,490 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:38:58,490 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:58,495 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:118 - >>>> Source Table = Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:1527244738, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4723362105143354958/source-warehouse/ct_database/ct_table_1, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244738}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:38:58,496 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,497 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,497 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,497 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:38:58,497 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:58,502 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:119 - >>>> Replica Table = Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:1527244738, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4723362105143354958/replica-warehouse/ct_database/ct_table_2, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244738, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4723362105143354958/source-warehouse/ct_database/ct_table_1/, com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:38:58,503 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,504 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,505 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,505 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_2 part=part=1
2018-05-25 11:38:58,505 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_2 part=part=1	
2018-05-25 11:38:58,537 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,538 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,538 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,538 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 alter_partition : db=ct_database tbl=ct_table_2
2018-05-25 11:38:58,538 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 alter_partition : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:58,539 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:3749 - New partition values:[1]
2018-05-25 11:38:58,573 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,574 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,574 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,575 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:38:58,575 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:58,581 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,582 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,583 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,583 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:38:58,583 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:58,588 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:41 - Fetching all partition names.
2018-05-25 11:38:58,589 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,590 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,591 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,591 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1
2018-05-25 11:38:58,591 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:58,601 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:43 - Fetched 2 partition names for table ct_database.ct_table_1.
2018-05-25 11:38:58,601 DEBUG com.hotels.hcommon.hive.metastore.iterator.BatchResolver:42 - Number of partitions (2) is less than batch size (3).
2018-05-25 11:38:58,601 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:49 - Fetching all partition names.
2018-05-25 11:38:58,602 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,604 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,604 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,604 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2
2018-05-25 11:38:58,604 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:58,610 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:51 - Fetched 2 partition names for table ct_database.ct_table_2.
2018-05-25 11:38:58,611 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,613 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,613 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,613 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1
2018-05-25 11:38:58,613 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:38:58,648 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:81 - Retrieved 2 partitions, total: 2.
2018-05-25 11:38:58,648 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:82 - Fetching 2 partitions.
2018-05-25 11:38:58,648 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,650 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,650 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,650 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2
2018-05-25 11:38:58,650 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:38:58,674 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:85 - Fetched 2 partitions for table ct_database.ct_table_2.
2018-05-25 11:38:58,675 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,677 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,677 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,677 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_1 part=part=1
2018-05-25 11:38:58,677 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_1 part=part=1	
2018-05-25 11:38:58,693 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:38:58,694 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,695 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:58,696 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:58,696 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: Cleaning up thread local RawStore...
2018-05-25 11:38:58,696 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:38:58,696 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 10: Done cleaning up thread local RawStore
2018-05-25 11:38:58,696 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:38:58,755 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:38:58,756 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:38:58,969 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:9e795eb9-8f67-4962-9ad5-e30540b0d639;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:38:59,049 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:38:59,092 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:9e795eb9-8f67-4962-9ad5-e30540b0d639;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:38:59,448 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:38:59,448 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:38:59,450 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:38:59,498 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:38:59,499 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:38:59,520 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:38:59,520 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:38:59,520 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58193]...
2018-05-25 11:38:59,520 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:38:59,520 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:38:59,520 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:39:00,545 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58193
2018-05-25 11:39:00,545 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:39:00,546 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:00,547 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58193
2018-05-25 11:39:00,548 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:00,548 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:00,549 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 14: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5701968810446957010/ct_database, parameters:null)
2018-05-25 11:39:00,549 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5701968810446957010/ct_database, parameters:null)	
2018-05-25 11:39:00,565 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:00,565 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,574 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,574 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,575 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:39:00,575 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5701968810446957010/ct_database
2018-05-25 11:39:00,583 DEBUG shims.HdfsUtils:200 - {-chgrp,-R,SEA\Domain,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5701968810446957010/ct_database}
2018-05-25 11:39:00,583 DEBUG shims.HdfsUtils:202 - Return value is :-1
2018-05-25 11:39:00,583 DEBUG shims.HdfsUtils:200 - {-chmod,-R,755,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5701968810446957010/ct_database}
2018-05-25 11:39:00,590 DEBUG shims.HdfsUtils:202 - Return value is :0
2018-05-25 11:39:00,592 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:00,593 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,594 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3901281570665707962/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:00,595 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3901281570665707962/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:00,595 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,595 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,595 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 14: Cleaning up thread local RawStore...
2018-05-25 11:39:00,595 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:00,596 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 14: Done cleaning up thread local RawStore
2018-05-25 11:39:00,596 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:00,611 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:00,612 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,613 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,613 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,622 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3901281570665707962/source-warehouse/ct_database/ct_table_1/ specified for non-external table:ct_table_1
2018-05-25 11:39:00,666 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,667 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,667 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,667 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 add_partition
2018-05-25 11:39:00,667 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:39:00,667 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: add_partitions
2018-05-25 11:39:00,668 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:39:00,698 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:39:00,699 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:39:00,699 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:39:00,700 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:39:00,719 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:39:00,722 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,723 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,723 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,723 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3901281570665707962/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3901281570665707962/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:00,723 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3901281570665707962/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3901281570665707962/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:00,724 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3901281570665707962/replica-warehouse/ct_database/ct_table_2/ specified for non-external table:ct_table_2
2018-05-25 11:39:00,731 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,732 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,733 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,733 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 add_partition
2018-05-25 11:39:00,733 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:39:00,733 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: add_partitions
2018-05-25 11:39:00,733 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:39:00,738 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:39:00,739 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:39:00,740 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:39:00,740 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:39:00,754 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:39:00,755 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,756 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,756 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,756 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:39:00,756 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:00,761 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:118 - >>>> Source Table = Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:1527244740, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3901281570665707962/source-warehouse/ct_database/ct_table_1, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244740}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:39:00,762 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,763 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,763 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,763 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:39:00,763 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:00,769 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:119 - >>>> Replica Table = Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:1527244740, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3901281570665707962/replica-warehouse/ct_database/ct_table_2, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244740, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3901281570665707962/source-warehouse/ct_database/ct_table_1/, com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:39:00,770 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,771 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,771 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,771 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_2 part=part=1
2018-05-25 11:39:00,771 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_2 part=part=1	
2018-05-25 11:39:00,795 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,796 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,796 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,796 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 alter_partition : db=ct_database tbl=ct_table_2
2018-05-25 11:39:00,796 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 alter_partition : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:00,797 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:3749 - New partition values:[1]
2018-05-25 11:39:00,822 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,823 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,823 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,824 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:39:00,824 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:00,829 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,830 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,830 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,830 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:39:00,830 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:00,835 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,837 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,837 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,837 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 alter_table: db=ct_database tbl=ct_table_2 newtbl=ct_table_2
2018-05-25 11:39:00,837 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: db=ct_database tbl=ct_table_2 newtbl=ct_table_2	
2018-05-25 11:39:00,849 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:41 - Fetching all partition names.
2018-05-25 11:39:00,850 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,851 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,851 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,851 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1
2018-05-25 11:39:00,851 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:00,863 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:43 - Fetched 2 partition names for table ct_database.ct_table_1.
2018-05-25 11:39:00,863 DEBUG com.hotels.hcommon.hive.metastore.iterator.BatchResolver:42 - Number of partitions (2) is less than batch size (3).
2018-05-25 11:39:00,863 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:49 - Fetching all partition names.
2018-05-25 11:39:00,864 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,866 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,866 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,866 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2
2018-05-25 11:39:00,866 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:00,872 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:51 - Fetched 2 partition names for table ct_database.ct_table_2.
2018-05-25 11:39:00,873 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,874 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,874 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,874 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1
2018-05-25 11:39:00,874 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:00,904 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:81 - Retrieved 2 partitions, total: 2.
2018-05-25 11:39:00,905 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:82 - Fetching 2 partitions.
2018-05-25 11:39:00,906 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,907 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,907 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,907 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2
2018-05-25 11:39:00,907 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:00,928 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:85 - Fetched 2 partitions for table ct_database.ct_table_2.
2018-05-25 11:39:00,929 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:39:00,930 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:00,932 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:00,932 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:00,932 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: Cleaning up thread local RawStore...
2018-05-25 11:39:00,932 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:00,933 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 13: Done cleaning up thread local RawStore
2018-05-25 11:39:00,933 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:00,992 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:00,993 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:01,190 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:8bb40093-1957-4479-bfe9-6a2c5308af96;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:39:01,266 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:39:01,304 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:8bb40093-1957-4479-bfe9-6a2c5308af96;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:39:01,647 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:01,647 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:01,649 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:39:01,696 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:39:01,697 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:39:01,720 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:39:01,720 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:39:01,720 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58196]...
2018-05-25 11:39:01,720 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:39:01,720 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:39:01,720 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:39:02,742 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58196
2018-05-25 11:39:02,742 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:39:02,743 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:02,744 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58196
2018-05-25 11:39:02,745 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:02,746 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:02,746 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 17: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5659277350117844333/ct_database, parameters:null)
2018-05-25 11:39:02,746 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5659277350117844333/ct_database, parameters:null)	
2018-05-25 11:39:02,763 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:02,764 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,772 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,772 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,774 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:39:02,774 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5659277350117844333/ct_database
2018-05-25 11:39:02,783 DEBUG shims.HdfsUtils:200 - {-chgrp,-R,SEA\Domain,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5659277350117844333/ct_database}
2018-05-25 11:39:02,783 DEBUG shims.HdfsUtils:202 - Return value is :-1
2018-05-25 11:39:02,783 DEBUG shims.HdfsUtils:200 - {-chmod,-R,755,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5659277350117844333/ct_database}
2018-05-25 11:39:02,791 DEBUG shims.HdfsUtils:202 - Return value is :0
2018-05-25 11:39:02,793 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:02,793 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,795 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit544540986376960904/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:02,795 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,795 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit544540986376960904/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:02,795 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,795 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 17: Cleaning up thread local RawStore...
2018-05-25 11:39:02,795 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:02,795 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 17: Done cleaning up thread local RawStore
2018-05-25 11:39:02,796 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:02,812 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:02,812 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,815 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,815 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,822 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit544540986376960904/source-warehouse/ct_database/ct_table_1/ specified for non-external table:ct_table_1
2018-05-25 11:39:02,864 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,866 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,866 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,866 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 add_partition
2018-05-25 11:39:02,866 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:39:02,866 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: add_partitions
2018-05-25 11:39:02,867 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:39:02,898 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:39:02,899 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:39:02,899 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:39:02,899 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:39:02,917 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:39:02,919 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,920 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,920 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,920 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit544540986376960904/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit544540986376960904/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:02,920 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit544540986376960904/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit544540986376960904/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:02,921 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit544540986376960904/replica-warehouse/ct_database/ct_table_2/ specified for non-external table:ct_table_2
2018-05-25 11:39:02,927 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,928 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,928 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,928 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 add_partition
2018-05-25 11:39:02,928 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:39:02,928 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: add_partitions
2018-05-25 11:39:02,928 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:39:02,932 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:39:02,933 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:39:02,933 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:39:02,933 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:39:02,947 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:39:02,947 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,949 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,949 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,949 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:39:02,949 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:02,953 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:118 - >>>> Source Table = Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:1527244742, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit544540986376960904/source-warehouse/ct_database/ct_table_1, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244742}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:39:02,954 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,955 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,955 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,955 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:39:02,955 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:02,960 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:119 - >>>> Replica Table = Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:1527244742, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit544540986376960904/replica-warehouse/ct_database/ct_table_2, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244742, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit544540986376960904/source-warehouse/ct_database/ct_table_1/, com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:39:02,961 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,962 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,962 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,962 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:39:02,962 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:02,968 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,969 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,969 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,969 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 add_partition : db=ct_database tbl=ct_table_2
2018-05-25 11:39:02,969 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:02,974 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:39:02,974 WARN  hive.log:380 - Updated size to 18
2018-05-25 11:39:02,979 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,980 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,980 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,980 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:39:02,981 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:02,986 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:41 - Fetching all partition names.
2018-05-25 11:39:02,987 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:02,988 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:02,988 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:02,989 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1
2018-05-25 11:39:02,989 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:02,999 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:43 - Fetched 2 partition names for table ct_database.ct_table_1.
2018-05-25 11:39:03,000 DEBUG com.hotels.hcommon.hive.metastore.iterator.BatchResolver:42 - Number of partitions (2) is less than batch size (3).
2018-05-25 11:39:03,000 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:49 - Fetching all partition names.
2018-05-25 11:39:03,000 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:03,001 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:03,001 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:03,001 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2
2018-05-25 11:39:03,002 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:03,008 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:51 - Fetched 3 partition names for table ct_database.ct_table_2.
2018-05-25 11:39:03,009 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:03,010 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:03,010 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:03,010 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1
2018-05-25 11:39:03,010 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:03,041 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:81 - Retrieved 2 partitions, total: 2.
2018-05-25 11:39:03,041 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:82 - Fetching 3 partitions.
2018-05-25 11:39:03,042 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:03,043 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:03,043 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:03,044 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2
2018-05-25 11:39:03,044 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:03,067 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:85 - Fetched 3 partitions for table ct_database.ct_table_2.
2018-05-25 11:39:03,069 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:39:03,069 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:03,070 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:03,070 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:03,070 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: Cleaning up thread local RawStore...
2018-05-25 11:39:03,071 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:03,071 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 16: Done cleaning up thread local RawStore
2018-05-25 11:39:03,071 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:03,128 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:03,129 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:03,302 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:65049123-61b4-439c-beeb-3166d20c9f14;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:39:03,391 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:39:03,469 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:65049123-61b4-439c-beeb-3166d20c9f14;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:39:03,821 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:03,821 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:03,823 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:39:03,867 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:39:03,868 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:39:03,888 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:39:03,889 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:39:03,889 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58199]...
2018-05-25 11:39:03,889 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:39:03,889 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:39:03,889 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:39:04,912 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58199
2018-05-25 11:39:04,913 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:39:04,914 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:04,914 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58199
2018-05-25 11:39:04,915 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:04,916 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:04,916 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 20: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit844980003192853312/ct_database, parameters:null)
2018-05-25 11:39:04,916 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit844980003192853312/ct_database, parameters:null)	
2018-05-25 11:39:04,931 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:04,931 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:04,938 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:04,938 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:04,939 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:39:04,940 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit844980003192853312/ct_database
2018-05-25 11:39:04,947 DEBUG shims.HdfsUtils:200 - {-chgrp,-R,SEA\Domain,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit844980003192853312/ct_database}
2018-05-25 11:39:04,947 DEBUG shims.HdfsUtils:202 - Return value is :-1
2018-05-25 11:39:04,947 DEBUG shims.HdfsUtils:200 - {-chmod,-R,755,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit844980003192853312/ct_database}
2018-05-25 11:39:04,955 DEBUG shims.HdfsUtils:202 - Return value is :0
2018-05-25 11:39:04,957 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:04,958 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:04,959 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:04,959 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:04,959 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit9056106191634204490/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:04,959 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 20: Cleaning up thread local RawStore...
2018-05-25 11:39:04,959 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit9056106191634204490/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:04,960 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:04,960 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 20: Done cleaning up thread local RawStore
2018-05-25 11:39:04,960 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:04,977 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:04,978 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:04,980 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:04,980 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:04,987 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit9056106191634204490/source-warehouse/ct_database/ct_table_1/ specified for non-external table:ct_table_1
2018-05-25 11:39:05,026 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,027 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,027 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,027 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 add_partition
2018-05-25 11:39:05,027 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:39:05,027 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: add_partitions
2018-05-25 11:39:05,027 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:39:05,054 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:39:05,054 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:39:05,055 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:39:05,055 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:39:05,074 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:39:05,076 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,077 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,077 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,077 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit9056106191634204490/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit9056106191634204490/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:05,077 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit9056106191634204490/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit9056106191634204490/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:05,078 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit9056106191634204490/replica-warehouse/ct_database/ct_table_2/ specified for non-external table:ct_table_2
2018-05-25 11:39:05,084 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,085 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,085 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,085 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 add_partition
2018-05-25 11:39:05,085 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:39:05,085 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: add_partitions
2018-05-25 11:39:05,085 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:39:05,090 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:39:05,090 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:39:05,090 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:39:05,091 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:39:05,105 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:39:05,105 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,106 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,107 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,107 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:39:05,107 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:05,111 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:118 - >>>> Source Table = Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:1527244744, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit9056106191634204490/source-warehouse/ct_database/ct_table_1, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244744}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:39:05,112 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,113 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,113 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,113 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:39:05,113 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:05,117 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:119 - >>>> Replica Table = Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:1527244745, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit9056106191634204490/replica-warehouse/ct_database/ct_table_2, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244745, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit9056106191634204490/source-warehouse/ct_database/ct_table_1/, com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:39:05,118 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,119 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,120 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,120 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_1 part=part=1
2018-05-25 11:39:05,120 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_1 part=part=1	
2018-05-25 11:39:05,139 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,140 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,140 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,140 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 alter_partition : db=ct_database tbl=ct_table_1
2018-05-25 11:39:05,140 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 alter_partition : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:05,140 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:3749 - New partition values:[1]
2018-05-25 11:39:05,164 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,165 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,165 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,165 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:39:05,165 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:05,169 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,170 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,170 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,170 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:39:05,170 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:05,175 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:41 - Fetching all partition names.
2018-05-25 11:39:05,175 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,176 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,176 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,176 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1
2018-05-25 11:39:05,177 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:05,186 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:43 - Fetched 2 partition names for table ct_database.ct_table_1.
2018-05-25 11:39:05,186 DEBUG com.hotels.hcommon.hive.metastore.iterator.BatchResolver:42 - Number of partitions (2) is less than batch size (3).
2018-05-25 11:39:05,186 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:49 - Fetching all partition names.
2018-05-25 11:39:05,186 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,187 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,188 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,188 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2
2018-05-25 11:39:05,188 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:05,194 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:51 - Fetched 2 partition names for table ct_database.ct_table_2.
2018-05-25 11:39:05,195 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,197 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,197 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,197 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1
2018-05-25 11:39:05,197 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:05,226 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:81 - Retrieved 2 partitions, total: 2.
2018-05-25 11:39:05,226 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:82 - Fetching 2 partitions.
2018-05-25 11:39:05,227 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,228 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,228 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,228 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2
2018-05-25 11:39:05,228 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:05,252 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:85 - Fetched 2 partitions for table ct_database.ct_table_2.
2018-05-25 11:39:05,253 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,255 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,255 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,255 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_1 part=part=1
2018-05-25 11:39:05,255 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_1 part=part=1	
2018-05-25 11:39:05,268 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:39:05,268 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,270 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,270 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,270 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: Cleaning up thread local RawStore...
2018-05-25 11:39:05,270 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:05,270 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: Done cleaning up thread local RawStore
2018-05-25 11:39:05,270 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:05,320 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:05,320 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:05,492 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:b73a3120-12ee-440e-a3ca-bf812ae37ac5;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:39:05,572 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:39:05,609 DEBUG com.jolbox.bonecp.BoneCPDataSource:119 - JDBC URL = jdbc:derby:memory:b73a3120-12ee-440e-a3ca-bf812ae37ac5;create=true, Username = db_user, partitions = 1, max (per partition) = 10, min (per partition) = 0, idle max age = 60 min, idle test period = 240 min, strategy = DEFAULT
2018-05-25 11:39:05,979 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:05,980 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:05,981 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:39:06,027 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:39:06,028 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:39:06,048 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:39:06,048 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:39:06,048 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58203]...
2018-05-25 11:39:06,048 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:39:06,048 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:39:06,048 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:39:07,070 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58203
2018-05-25 11:39:07,070 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:39:07,071 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:07,073 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58203
2018-05-25 11:39:07,073 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:07,074 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:07,075 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 23: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit894237960882716388/ct_database, parameters:null)
2018-05-25 11:39:07,075 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit894237960882716388/ct_database, parameters:null)	
2018-05-25 11:39:07,090 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:07,090 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,097 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,097 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,098 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:39:07,098 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit894237960882716388/ct_database
2018-05-25 11:39:07,106 DEBUG shims.HdfsUtils:200 - {-chgrp,-R,SEA\Domain,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit894237960882716388/ct_database}
2018-05-25 11:39:07,107 DEBUG shims.HdfsUtils:202 - Return value is :-1
2018-05-25 11:39:07,107 DEBUG shims.HdfsUtils:200 - {-chmod,-R,755,file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit894237960882716388/ct_database}
2018-05-25 11:39:07,114 DEBUG shims.HdfsUtils:202 - Return value is :0
2018-05-25 11:39:07,117 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:07,118 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,119 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6881989555257309755/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:07,120 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6881989555257309755/source-warehouse/ct_database/ct_table_1/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:07,120 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,121 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,121 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 23: Cleaning up thread local RawStore...
2018-05-25 11:39:07,121 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:07,121 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 23: Done cleaning up thread local RawStore
2018-05-25 11:39:07,122 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:07,136 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:07,137 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,138 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,138 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,145 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6881989555257309755/source-warehouse/ct_database/ct_table_1/ specified for non-external table:ct_table_1
2018-05-25 11:39:07,187 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,188 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,188 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,188 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 add_partition
2018-05-25 11:39:07,188 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:39:07,188 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: add_partitions
2018-05-25 11:39:07,188 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:39:07,215 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:39:07,216 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:39:07,216 WARN  hive.log:377 - Updating partition stats fast for: ct_table_1
2018-05-25 11:39:07,216 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:39:07,231 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:39:07,233 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,233 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,234 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,234 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6881989555257309755/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6881989555257309755/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:07,234 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6881989555257309755/replica-warehouse/ct_database/ct_table_2/, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:{}), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6881989555257309755/source-warehouse/ct_database/ct_table_1/}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:07,235 WARN  org.apache.hadoop.hive.metastore.HiveMetaStore:1423 - Location: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6881989555257309755/replica-warehouse/ct_database/ct_table_2/ specified for non-external table:ct_table_2
2018-05-25 11:39:07,241 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,242 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,242 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,242 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 add_partition
2018-05-25 11:39:07,242 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition	
2018-05-25 11:39:07,242 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: add_partitions
2018-05-25 11:39:07,242 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=add_partitions	
2018-05-25 11:39:07,246 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:39:07,247 WARN  hive.log:377 - Updating partition stats fast for: ct_table_2
2018-05-25 11:39:07,247 WARN  hive.log:380 - Updated size to 15
2018-05-25 11:39:07,247 WARN  hive.log:380 - Updated size to 13
2018-05-25 11:39:07,260 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:167 - >>>> Partitions added: 2
2018-05-25 11:39:07,261 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,262 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,262 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,262 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:39:07,262 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:07,266 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:118 - >>>> Source Table = Table(tableName:ct_table_1, dbName:ct_database, owner:null, createTime:1527244747, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6881989555257309755/source-warehouse/ct_database/ct_table_1, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244747}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:39:07,266 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,267 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,267 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,267 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:39:07,267 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:07,272 INFO  com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesIntegrationTest:119 - >>>> Replica Table = Table(tableName:ct_table_2, dbName:ct_database, owner:null, createTime:1527244747, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:bigint, comment:), FieldSchema(name:bar, type:string, comment:)], location:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6881989555257309755/replica-warehouse/ct_database/ct_table_2, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:part, type:int, comment:)], parameters:{transient_lastDdlTime=1527244747, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6881989555257309755/source-warehouse/ct_database/ct_table_1/, com.hotels.bdp.circustrain.source.table=ct_database.ct_table_1}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, rewriteEnabled:false)
2018-05-25 11:39:07,274 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,275 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,275 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,275 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1
2018-05-25 11:39:07,275 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:07,279 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,280 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,280 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,280 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2
2018-05-25 11:39:07,281 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:07,285 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:41 - Fetching all partition names.
2018-05-25 11:39:07,286 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,287 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,287 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,287 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1
2018-05-25 11:39:07,288 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:07,297 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:43 - Fetched 2 partition names for table ct_database.ct_table_1.
2018-05-25 11:39:07,298 DEBUG com.hotels.hcommon.hive.metastore.iterator.BatchResolver:42 - Number of partitions (2) is less than batch size (3).
2018-05-25 11:39:07,298 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:49 - Fetching all partition names.
2018-05-25 11:39:07,299 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,300 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,300 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,300 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2
2018-05-25 11:39:07,300 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:07,305 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:51 - Fetched 2 partition names for table ct_database.ct_table_2.
2018-05-25 11:39:07,306 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,307 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,307 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,307 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1
2018-05-25 11:39:07,307 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_1	
2018-05-25 11:39:07,329 DEBUG com.hotels.hcommon.hive.metastore.iterator.PartitionIterator:81 - Retrieved 2 partitions, total: 2.
2018-05-25 11:39:07,330 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:82 - Fetching 2 partitions.
2018-05-25 11:39:07,330 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,331 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,331 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,331 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2
2018-05-25 11:39:07,332 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_names : db=ct_database tbl=ct_table_2	
2018-05-25 11:39:07,354 DEBUG com.hotels.bdp.circustrain.hive.fetcher.BufferedPartitionFetcher:85 - Fetched 2 partitions for table ct_database.ct_table_2.
2018-05-25 11:39:07,355 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,357 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,357 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,357 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_1 part=part=1
2018-05-25 11:39:07,357 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_partition_by_name: db=ct_database tbl=ct_table_1 part=part=1	
2018-05-25 11:39:07,376 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:39:07,376 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:07,378 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:07,378 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:07,378 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: Cleaning up thread local RawStore...
2018-05-25 11:39:07,378 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.351 sec
Running com.hotels.bdp.circustrain.comparator.hive.HiveDifferencesTest
2018-05-25 11:39:07,379 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: Done cleaning up thread local RawStore
2018-05-25 11:39:07,379 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.026 sec
Running com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListenerTest
2018-05-25 11:39:07,430 INFO  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:87 - Creating partition spec from '3' detected partitions.
2018-05-25 11:39:07,437 INFO  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:87 - Creating partition spec from '1' detected partitions.
2018-05-25 11:39:07,437 WARN  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:93 - Can't replicate partition with these values [__HIVE_DEFAULT_PARTITION__, val2], will skip them.
2018-05-25 11:39:07,443 INFO  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:87 - Creating partition spec from '2' detected partitions.
2018-05-25 11:39:07,449 INFO  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:87 - Creating partition spec from '2' detected partitions.
2018-05-25 11:39:07,455 INFO  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:87 - Creating partition spec from '2' detected partitions.
2018-05-25 11:39:07,461 INFO  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:87 - Creating partition spec from '3' detected partitions.
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.055 sec

Results :

Tests run: 127, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-comparator ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/target/circus-train-comparator-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-comparator ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/target/circus-train-comparator-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-comparator/11.5.1-SNAPSHOT/circus-train-comparator-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-comparator/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-comparator/11.5.1-SNAPSHOT/circus-train-comparator-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Core 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-core ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-core/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-core ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-core ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-core ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-core ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-core ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-core ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 78 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-core ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-core ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 56 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] /Users/cedwards/Documents/workspace/circus-train/circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/ReplicationFactoryImplTest.java: /Users/cedwards/Documents/workspace/circus-train/circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/ReplicationFactoryImplTest.java uses unchecked or unsafe operations.
[INFO] /Users/cedwards/Documents/workspace/circus-train/circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/ReplicationFactoryImplTest.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-core ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.CircusTrainHelpTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.062 sec
Running com.hotels.bdp.circustrain.CircusTrainTest
2018-05-25 11:39:10,695 INFO  org.apache.hadoop.hive.conf.HiveConf:181 - Found configuration file null
2018-05-25 11:39:11,318 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:11,364 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:11,503 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:39:11,504 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:39:12,990 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:39:14,816 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:14,819 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:14,910 WARN  org.apache.hadoop.hive.metastore.ObjectStore:7566 - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
2018-05-25 11:39:14,911 WARN  org.apache.hadoop.hive.metastore.ObjectStore:7654 - setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore cedwards@172.21.175.71
2018-05-25 11:39:14,927 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:39:15,001 WARN  org.apache.hadoop.util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-25 11:39:15,210 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:39:15,212 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:39:15,259 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:39:15,369 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:39:15,374 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58206]...
2018-05-25 11:39:15,374 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:39:15,374 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:39:15,374 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:39:16,450 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58206
2018-05-25 11:39:16,468 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:39:16,570 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:16,600 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58206
2018-05-25 11:39:16,601 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:16,604 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:16,611 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 2: source:127.0.0.1 create_database: Database(name:test_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7944046427860611324/test_database, parameters:null)
2018-05-25 11:39:16,612 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:test_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7944046427860611324/test_database, parameters:null)	
2018-05-25 11:39:16,642 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:16,644 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:16,652 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:16,653 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:16,654 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database test_database, returning NoSuchObjectException
2018-05-25 11:39:16,657 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7944046427860611324/test_database
2018-05-25 11:39:16,738 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:16,740 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:16,743 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:16,743 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:16,743 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 2: Cleaning up thread local RawStore...
2018-05-25 11:39:16,743 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:16,744 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 2: Done cleaning up thread local RawStore
2018-05-25 11:39:16,744 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:16,765 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 create_table: Table(tableName:source_test_table, dbName:test_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:null, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:null), partitionKeys:null, parameters:{EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:16,765 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:source_test_table, dbName:test_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:null, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:null), partitionKeys:null, parameters:{EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:16,813 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:16,814 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:16,818 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:16,818 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:16,851 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7944046427860611324/test_database/source_test_table
2018-05-25 11:39:17,036 INFO  com.hotels.bdp.circustrain.CircusTrain:123 - Ant-Version=Apache Ant 1.8.4; Created-By=1.6.0_65-b14-466-11M4802 (Apple Inc.); Manifest-Version=1.0; 
         ee@@@@@@@@@@@@@@@
       e@@@@@@@@@@@@@@@
      @@@"     .-.----.      ___ _                   ___ _                   _
     @@"___   / o )    \    / __\ |__   ___   ___   / __\ |__   ___   ___   / \
    II__[w]   ||  __  |'  / /  | '_ \ / _ \ / _ \ / /  | '_ \ / _ \ / _ \ /  /
   {======|_ '- |||  |||  / /___| | | | (_) | (_) / /___| | | | (_) | (_) /\_/
  /oO--000'"`--OO----OO-' \____/|_| |_|\___/ \___/\____/|_| |_|\___/ \___/\/
2018-05-25 11:39:17,664 INFO  com.hotels.bdp.circustrain.CircusTrain:48 - Starting CircusTrain on LONC02S91UPG8WL.sea.corp.expecn.com with PID 12851 (/Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/classes started by cedwards in /Users/cedwards/Documents/workspace/circus-train/circus-train-core)
2018-05-25 11:39:17,664 INFO  com.hotels.bdp.circustrain.CircusTrain:664 - The following profiles are active: replication,housekeeping
2018-05-25 11:39:17,894 INFO  org.springframework.context.annotation.AnnotationConfigApplicationContext:578 - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@3381b4fc: startup date [Fri May 25 11:39:17 BST 2018]; root of context hierarchy
2018-05-25 11:39:18,957 WARN  org.springframework.context.annotation.ConfigurationClassEnhancer:348 - @Bean method EnableEncryptablePropertySourcesConfiguration.enableEncryptablePropertySourcesPostProcessor is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2018-05-25 11:39:18,966 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:83 - Post-processing PropertySource instances
2018-05-25 11:39:18,975 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource commandLineArgs[org.springframework.core.env.SimpleCommandLinePropertySource] to EncryptableEnumerablePropertySourceWrapper
2018-05-25 11:39:18,976 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource systemProperties[org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:18,976 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource systemEnvironment[org.springframework.core.env.SystemEnvironmentPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:18,977 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource random[org.springframework.boot.context.config.RandomValuePropertySource] to EncryptablePropertySourceWrapper
2018-05-25 11:39:18,977 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource applicationConfig: [file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5929341831145140653/test-application2.yml][org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:18,977 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource applicationConfig: [file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5929341831145140653/test-application1.yml][org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:18,978 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource defaultProperties[org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:18,988 INFO  org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor:153 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-25 11:39:19,283 INFO  com.zaxxer.hikari.HikariDataSource:93 - HikariPool-1 - Started.
2018-05-25 11:39:19,494 INFO  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean:336 - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-25 11:39:19.527  INFO 12851 --- [           main] o.h.j.i.u.LogHelper                      : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-05-25 11:39:19.607  INFO 12851 --- [           main] o.h.Version                              : HHH000412: Hibernate Core {4.3.11.Final}
2018-05-25 11:39:19.609  INFO 12851 --- [           main] o.h.c.Environment                        : HHH000206: hibernate.properties not found
2018-05-25 11:39:19.611  INFO 12851 --- [           main] o.h.c.Environment                        : HHH000021: Bytecode provider name : javassist
2018-05-25 11:39:19.760  INFO 12851 --- [           main] o.h.a.c.Version                          : HCANN000001: Hibernate Commons Annotations {4.0.5.Final}
2018-05-25 11:39:19.830  INFO 12851 --- [           main] o.h.d.Dialect                            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-05-25 11:39:19.885  INFO 12851 --- [           main] o.h.h.i.a.ASTQueryTranslatorFactory      : HHH000397: Using ASTQueryTranslatorFactory
2018-05-25 11:39:20.043  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000227: Running hbm2ddl schema export
2018-05-25 11:39:20.046  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000230: Schema export complete
2018-05-25 11:39:20,105 INFO  com.hotels.bdp.circustrain.CircusTrain:123 - Ant-Version=Apache Ant 1.8.4; Created-By=1.6.0_65-b14-466-11M4802 (Apple Inc.); Manifest-Version=1.0; 
2018-05-25 11:39:20,368 INFO  com.hotels.bdp.circustrain.context.CommonBeans:88 - No Hadoop site XML is defined for catalog source.
2018-05-25 11:39:20,483 INFO  com.hotels.bdp.circustrain.context.CommonBeans:88 - No Hadoop site XML is defined for catalog replica.
2018-05-25 11:39:20,895 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:431 - Registering beans for JMX exposure on startup
2018-05-25 11:39:20,897 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:912 - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-05-25 11:39:20,900 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:667 - Located MBean 'dataSource': registering with JMX server as MBean [com.zaxxer.hikari:name=dataSource,type=HikariDataSource]
2018-05-25 11:39:20,910 INFO  com.hotels.bdp.circustrain.core.Locomotive:106 - 1 tables to replicate.
2018-05-25 11:39:20,910 INFO  com.hotels.bdp.circustrain.core.Locomotive:109 - Replicating source:test_database.source_test_table to replica:test_database.replica_test_table replication mode 'FULL'.
2018-05-25 11:39:20,915 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58206
2018-05-25 11:39:20,916 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:20,917 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:20,959 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 3: source:127.0.0.1 get_database: test_database
2018-05-25 11:39:20,960 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: test_database	
2018-05-25 11:39:21,002 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:21,004 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,007 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,007 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,011 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:21,012 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58206
2018-05-25 11:39:21,012 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,012 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:21,013 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:21,014 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: source:127.0.0.1 get_database: test_database
2018-05-25 11:39:21,014 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: test_database	
2018-05-25 11:39:21,015 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,015 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,015 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 3: Cleaning up thread local RawStore...
2018-05-25 11:39:21,016 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:21,016 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 3: Done cleaning up thread local RawStore
2018-05-25 11:39:21,016 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:21,045 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:21,046 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,048 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,048 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,050 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:21,051 INFO  com.hotels.bdp.circustrain.core.source.Source:113 - Retrieving table metadata for 'test_database.source_test_table'
2018-05-25 11:39:21,051 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,052 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58206
2018-05-25 11:39:21,052 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:21,054 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:21,054 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,054 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,054 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: Cleaning up thread local RawStore...
2018-05-25 11:39:21,055 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:21,055 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 4: Done cleaning up thread local RawStore
2018-05-25 11:39:21,055 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:21,061 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 5: source:127.0.0.1 get_table : db=test_database tbl=source_test_table
2018-05-25 11:39:21,061 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=source_test_table	
2018-05-25 11:39:21,092 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:21,093 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,095 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,095 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,160 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,162 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,162 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,162 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 5: source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table
2018-05-25 11:39:21,163 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table	
2018-05-25 11:39:21,181 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:21,182 INFO  com.hotels.bdp.circustrain.core.source.Source:113 - Retrieving table metadata for 'test_database.source_test_table'
2018-05-25 11:39:21,182 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,183 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58206
2018-05-25 11:39:21,183 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:21,185 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,185 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:21,185 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,185 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 5: Cleaning up thread local RawStore...
2018-05-25 11:39:21,185 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 6: source:127.0.0.1 get_table : db=test_database tbl=source_test_table
2018-05-25 11:39:21,185 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:21,186 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=source_test_table	
2018-05-25 11:39:21,186 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 5: Done cleaning up thread local RawStore
2018-05-25 11:39:21,186 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:21,217 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:21,218 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,221 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,221 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,235 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,237 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,237 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,237 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 6: source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table
2018-05-25 11:39:21,238 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table	
2018-05-25 11:39:21,251 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:21,252 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,255 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,255 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,255 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 6: Cleaning up thread local RawStore...
2018-05-25 11:39:21,255 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:21,256 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 6: Done cleaning up thread local RawStore
2018-05-25 11:39:21,256 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:21,289 INFO  com.hotels.bdp.circustrain.core.event.LoggingListener:REPLICATION_EVENTS:63 - [ctt-20180525t103921.255z-4hdjqbtn] Attempting to replicate 'source:test_database.source_test_table' to 'replica:test_database.replica_test_table'
2018-05-25 11:39:21,290 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58206
2018-05-25 11:39:21,290 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:21,291 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:21,292 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: source:127.0.0.1 get_table : db=test_database tbl=replica_test_table
2018-05-25 11:39:21,292 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=replica_test_table	
2018-05-25 11:39:21,324 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:21,325 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,328 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,328 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,329 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:21,330 INFO  com.hotels.bdp.circustrain.core.source.Source:113 - Retrieving table metadata for 'test_database.source_test_table'
2018-05-25 11:39:21,330 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58206
2018-05-25 11:39:21,331 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:21,331 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,332 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:21,332 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 8: source:127.0.0.1 get_table : db=test_database tbl=source_test_table
2018-05-25 11:39:21,332 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=source_test_table	
2018-05-25 11:39:21,334 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,334 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,334 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: Cleaning up thread local RawStore...
2018-05-25 11:39:21,334 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:21,334 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 7: Done cleaning up thread local RawStore
2018-05-25 11:39:21,335 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:21,362 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:21,362 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,367 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,367 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,378 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,380 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,380 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,381 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 8: source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table
2018-05-25 11:39:21,381 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table	
2018-05-25 11:39:21,390 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:21,390 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,393 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,393 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,393 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 8: Cleaning up thread local RawStore...
2018-05-25 11:39:21,393 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:21,393 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 8: Done cleaning up thread local RawStore
2018-05-25 11:39:21,393 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:21,399 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58206
2018-05-25 11:39:21,399 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:21,400 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:21,400 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:21,404 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 9: source:127.0.0.1 get_table : db=test_database tbl=replica_test_table
2018-05-25 11:39:21,404 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=replica_test_table	
2018-05-25 11:39:21,432 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:21,433 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,435 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,435 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,437 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,439 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,439 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,439 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 9: source:127.0.0.1 create_table: Table(tableName:replica_test_table, dbName:test_database, owner:null, createTime:1527244756, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5929341831145140653/replica/ctt-20180525t103921.255z-4hdjqbtn, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{com.hotels.bdp.circustrain.last.replicated=2018-05-25T10:39:21.403Z, transient_lastDdlTime=1527244756, STATS_GENERATED_VIA_STATS_TASK=true, DO_NOT_UPDATE_STATS=true, com.hotels.bdp.circustrain.source.metastore.uris=thrift://localhost:58206, EXTERNAL=TRUE, com.hotels.bdp.circustrain.replication.event=ctt-20180525t103921.255z-4hdjqbtn, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7944046427860611324/test_database/source_test_table, com.hotels.bdp.circustrain.source.table=test_database.source_test_table, STATS_GENERATED=true, com.hotels.bdp.circustrain.replication.mode=FULL}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, rewriteEnabled:false)
2018-05-25 11:39:21,440 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:replica_test_table, dbName:test_database, owner:null, createTime:1527244756, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5929341831145140653/replica/ctt-20180525t103921.255z-4hdjqbtn, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{com.hotels.bdp.circustrain.last.replicated=2018-05-25T10:39:21.403Z, transient_lastDdlTime=1527244756, STATS_GENERATED_VIA_STATS_TASK=true, DO_NOT_UPDATE_STATS=true, com.hotels.bdp.circustrain.source.metastore.uris=thrift://localhost:58206, EXTERNAL=TRUE, com.hotels.bdp.circustrain.replication.event=ctt-20180525t103921.255z-4hdjqbtn, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7944046427860611324/test_database/source_test_table, com.hotels.bdp.circustrain.source.table=test_database.source_test_table, STATS_GENERATED=true, com.hotels.bdp.circustrain.replication.mode=FULL}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, rewriteEnabled:false)	
2018-05-25 11:39:21,441 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5929341831145140653/replica/ctt-20180525t103921.255z-4hdjqbtn
2018-05-25 11:39:21,468 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:21,468 INFO  com.hotels.bdp.circustrain.core.UnpartitionedTableReplication:108 - Replicated table test_database.source_test_table.
2018-05-25 11:39:21,468 INFO  com.hotels.bdp.circustrain.core.Locomotive:115 - Completed replicating: source:test_database.source_test_table to replica:test_database.replica_test_table.
2018-05-25 11:39:21,469 INFO  com.hotels.bdp.circustrain.core.event.LoggingListener:REPLICATION_EVENTS:71 - [ctt-20180525t103921.255z-4hdjqbtn] Successfully replicated all of 'source:test_database.source_test_table' to 'replica:test_database.replica_test_table' (0 bytes)
2018-05-25 11:39:21,469 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,469 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - test_database.replica_test_table.replication_time : 180
2018-05-25 11:39:21,469 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - test_database.replica_test_table.completion_code : 1
2018-05-25 11:39:21,469 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - test_database.replica_test_table.bytes_replicated : 0
2018-05-25 11:39:21,470 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - tables_replicated : 1
2018-05-25 11:39:21,470 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - completion_code : 1
2018-05-25 11:39:21,471 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,471 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,471 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 9: Cleaning up thread local RawStore...
2018-05-25 11:39:21,471 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:21,471 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 9: Done cleaning up thread local RawStore
2018-05-25 11:39:21,471 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:21,472 INFO  com.hotels.bdp.circustrain.CircusTrain:57 - Started CircusTrain in 4.364 seconds (JVM running for 11.42)
2018-05-25 11:39:21,473 INFO  org.springframework.context.annotation.AnnotationConfigApplicationContext:960 - Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@3381b4fc: startup date [Fri May 25 11:39:17 BST 2018]; root of context hierarchy
2018-05-25 11:39:21,475 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:449 - Unregistering JMX-exposed beans on shutdown
2018-05-25 11:39:21,475 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:241 - Unregistering JMX-exposed beans
2018-05-25 11:39:21,476 INFO  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean:481 - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-05-25 11:39:21.477  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000227: Running hbm2ddl schema export
2018-05-25 11:39:21.478  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000230: Schema export complete
2018-05-25 11:39:21,479 INFO  com.zaxxer.hikari.pool.HikariPool:202 - HikariPool-1 - Close initiated...
2018-05-25 11:39:21,482 INFO  com.zaxxer.hikari.pool.HikariPool:242 - HikariPool-1 - Closed.
2018-05-25 11:39:21,484 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,487 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,487 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,487 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: source:127.0.0.1 get_table : db=test_database tbl=replica_test_table
2018-05-25 11:39:21,487 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=replica_test_table	
2018-05-25 11:39:21,501 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:39:21,502 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,504 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:21,505 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:21,505 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: Cleaning up thread local RawStore...
2018-05-25 11:39:21,505 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:21,505 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 1: Done cleaning up thread local RawStore
2018-05-25 11:39:21,505 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:21,596 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 10: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:21,599 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:21,613 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:39:21,613 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:39:21,992 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:39:22,603 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:22,603 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:22,606 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:39:22,696 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:39:22,697 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:39:22,723 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:39:22,723 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:39:22,723 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58216]...
2018-05-25 11:39:22,724 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:39:22,724 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:39:22,724 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:39:23,757 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58216
2018-05-25 11:39:23,757 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:39:23,758 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:23,759 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58216
2018-05-25 11:39:23,759 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:23,760 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:23,760 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 12: source:127.0.0.1 create_database: Database(name:test_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2889284280372402744/test_database, parameters:null)
2018-05-25 11:39:23,760 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:test_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2889284280372402744/test_database, parameters:null)	
2018-05-25 11:39:23,786 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:23,786 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:23,794 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:23,794 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:23,795 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database test_database, returning NoSuchObjectException
2018-05-25 11:39:23,796 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2889284280372402744/test_database
2018-05-25 11:39:23,813 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:23,814 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 11: source:127.0.0.1 create_table: Table(tableName:source_test_table, dbName:test_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:null, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:null), partitionKeys:null, parameters:{EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:23,814 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:source_test_table, dbName:test_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:null, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:null), partitionKeys:null, parameters:{EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:23,814 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:23,816 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:23,816 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:23,816 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 12: Cleaning up thread local RawStore...
2018-05-25 11:39:23,817 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:23,817 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 12: Done cleaning up thread local RawStore
2018-05-25 11:39:23,817 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:23,843 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:23,844 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:23,847 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:23,847 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:23,859 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2889284280372402744/test_database/source_test_table
2018-05-25 11:39:23,957 INFO  com.hotels.bdp.circustrain.CircusTrain:123 - Ant-Version=Apache Ant 1.8.4; Created-By=1.6.0_65-b14-466-11M4802 (Apple Inc.); Manifest-Version=1.0; 
         ee@@@@@@@@@@@@@@@
       e@@@@@@@@@@@@@@@
      @@@"     .-.----.      ___ _                   ___ _                   _
     @@"___   / o )    \    / __\ |__   ___   ___   / __\ |__   ___   ___   / \
    II__[w]   ||  __  |'  / /  | '_ \ / _ \ / _ \ / /  | '_ \ / _ \ / _ \ /  /
   {======|_ '- |||  |||  / /___| | | | (_) | (_) / /___| | | | (_) | (_) /\_/
  /oO--000'"`--OO----OO-' \____/|_| |_|\___/ \___/\____/|_| |_|\___/ \___/\/
2018-05-25 11:39:24,016 INFO  com.hotels.bdp.circustrain.CircusTrain:48 - Starting CircusTrain on LONC02S91UPG8WL.sea.corp.expecn.com with PID 12851 (/Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/classes started by cedwards in /Users/cedwards/Documents/workspace/circus-train/circus-train-core)
2018-05-25 11:39:24,016 INFO  com.hotels.bdp.circustrain.CircusTrain:664 - The following profiles are active: replication,housekeeping
2018-05-25 11:39:24,018 INFO  org.springframework.context.annotation.AnnotationConfigApplicationContext:578 - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5bb97fe7: startup date [Fri May 25 11:39:24 BST 2018]; root of context hierarchy
2018-05-25 11:39:24,425 WARN  org.springframework.context.annotation.ConfigurationClassEnhancer:348 - @Bean method EnableEncryptablePropertySourcesConfiguration.enableEncryptablePropertySourcesPostProcessor is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2018-05-25 11:39:24,425 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:83 - Post-processing PropertySource instances
2018-05-25 11:39:24,427 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource commandLineArgs[org.springframework.core.env.SimpleCommandLinePropertySource] to EncryptableEnumerablePropertySourceWrapper
2018-05-25 11:39:24,427 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource systemProperties[org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:24,427 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource systemEnvironment[org.springframework.core.env.SystemEnvironmentPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:24,427 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource random[org.springframework.boot.context.config.RandomValuePropertySource] to EncryptablePropertySourceWrapper
2018-05-25 11:39:24,428 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource defaultProperties[org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:24,430 INFO  org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor:153 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-25 11:39:24,510 INFO  com.zaxxer.hikari.HikariDataSource:93 - HikariPool-2 - Started.
2018-05-25 11:39:24,548 INFO  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean:336 - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-25 11:39:24.549  INFO 12851 --- [           main] o.h.j.i.u.LogHelper                      : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-05-25 11:39:24.567  INFO 12851 --- [           main] o.h.d.Dialect                            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-05-25 11:39:24.568  INFO 12851 --- [           main] o.h.h.i.a.ASTQueryTranslatorFactory      : HHH000397: Using ASTQueryTranslatorFactory
2018-05-25 11:39:24.572  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000227: Running hbm2ddl schema export
2018-05-25 11:39:24.573  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000230: Schema export complete
2018-05-25 11:39:24,589 INFO  com.hotels.bdp.circustrain.CircusTrain:123 - Ant-Version=Apache Ant 1.8.4; Created-By=1.6.0_65-b14-466-11M4802 (Apple Inc.); Manifest-Version=1.0; 
2018-05-25 11:39:24,633 ERROR org.springframework.boot.bind.PropertiesConfigurationFactory:354 - Properties configuration failed validation
2018-05-25 11:39:24,633 ERROR org.springframework.boot.bind.PropertiesConfigurationFactory:357 - Field error in object 'replica-catalog' on field 'name': rejected value [null]; codes [NotBlank.replica-catalog.name,NotBlank.name,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.name,name]; arguments []; default message [name]]; default message [may not be empty]
2018-05-25 11:39:24,633 ERROR org.springframework.boot.bind.PropertiesConfigurationFactory:357 - Field error in object 'replica-catalog' on field 'hiveMetastoreUris': rejected value [null]; codes [NotBlank.replica-catalog.hiveMetastoreUris,NotBlank.hiveMetastoreUris,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.hiveMetastoreUris,hiveMetastoreUris]; arguments []; default message [hiveMetastoreUris]]; default message [may not be empty]
2018-05-25 11:39:24,634 WARN  org.springframework.context.annotation.AnnotationConfigApplicationContext:546 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'replicaCatalog': Could not bind properties to ReplicaCatalog (prefix=replica-catalog, ignoreInvalidFields=false, ignoreUnknownFields=true, ignoreNestedProperties=false); nested exception is org.springframework.validation.BindException: org.springframework.boot.bind.RelaxedDataBinder$RelaxedBeanPropertyBindingResult: 2 errors
Field error in object 'replica-catalog' on field 'name': rejected value [null]; codes [NotBlank.replica-catalog.name,NotBlank.name,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.name,name]; arguments []; default message [name]]; default message [may not be empty]
Field error in object 'replica-catalog' on field 'hiveMetastoreUris': rejected value [null]; codes [NotBlank.replica-catalog.hiveMetastoreUris,NotBlank.hiveMetastoreUris,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.hiveMetastoreUris,hiveMetastoreUris]; arguments []; default message [hiveMetastoreUris]]; default message [may not be empty]
2018-05-25 11:39:24,634 INFO  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean:481 - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-05-25 11:39:24.634  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000227: Running hbm2ddl schema export
2018-05-25 11:39:24.635  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000230: Schema export complete
2018-05-25 11:39:24,635 INFO  com.zaxxer.hikari.pool.HikariPool:202 - HikariPool-2 - Close initiated...
2018-05-25 11:39:24,638 INFO  com.zaxxer.hikari.pool.HikariPool:242 - HikariPool-2 - Closed.
2018-05-25 11:39:24,639 ERROR org.springframework.boot.SpringApplication:821 - Application startup failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'replicaCatalog': Could not bind properties to ReplicaCatalog (prefix=replica-catalog, ignoreInvalidFields=false, ignoreUnknownFields=true, ignoreNestedProperties=false); nested exception is org.springframework.validation.BindException: org.springframework.boot.bind.RelaxedDataBinder$RelaxedBeanPropertyBindingResult: 2 errors
Field error in object 'replica-catalog' on field 'name': rejected value [null]; codes [NotBlank.replica-catalog.name,NotBlank.name,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.name,name]; arguments []; default message [name]]; default message [may not be empty]
Field error in object 'replica-catalog' on field 'hiveMetastoreUris': rejected value [null]; codes [NotBlank.replica-catalog.hiveMetastoreUris,NotBlank.hiveMetastoreUris,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.hiveMetastoreUris,hiveMetastoreUris]; arguments []; default message [hiveMetastoreUris]]; default message [may not be empty]
	at org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor.postProcessBeforeInitialization(ConfigurationPropertiesBindingPostProcessor.java:339)
	at org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor.postProcessBeforeInitialization(ConfigurationPropertiesBindingPostProcessor.java:289)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:408)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1574)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:545)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:778)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:760)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:360)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:306)
	at com.hotels.bdp.circustrain.CircusTrain.main(CircusTrain.java:98)
	at com.hotels.bdp.circustrain.CircusTrainTest.emptyYmlFile(CircusTrainTest.java:204)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.contrib.java.lang.system.ExpectedSystemExit$1.evaluate(ExpectedSystemExit.java:130)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
Caused by: org.springframework.validation.BindException: org.springframework.boot.bind.RelaxedDataBinder$RelaxedBeanPropertyBindingResult: 2 errors
Field error in object 'replica-catalog' on field 'name': rejected value [null]; codes [NotBlank.replica-catalog.name,NotBlank.name,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.name,name]; arguments []; default message [name]]; default message [may not be empty]
Field error in object 'replica-catalog' on field 'hiveMetastoreUris': rejected value [null]; codes [NotBlank.replica-catalog.hiveMetastoreUris,NotBlank.hiveMetastoreUris,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.hiveMetastoreUris,hiveMetastoreUris]; arguments []; default message [hiveMetastoreUris]]; default message [may not be empty]
	at org.springframework.boot.bind.PropertiesConfigurationFactory.validate(PropertiesConfigurationFactory.java:363)
	at org.springframework.boot.bind.PropertiesConfigurationFactory.doBindPropertiesToTarget(PropertiesConfigurationFactory.java:272)
	at org.springframework.boot.bind.PropertiesConfigurationFactory.bindPropertiesToTarget(PropertiesConfigurationFactory.java:241)
	at org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor.postProcessBeforeInitialization(ConfigurationPropertiesBindingPostProcessor.java:334)
	... 52 more
2018-05-25 11:39:24,643 INFO  org.springframework.boot.logging.ClasspathLoggingApplicationListener:57 - Application failed to start with classpath: [file:/Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/surefire/surefirebooter8375855852412627105.jar]
2018-05-25 11:39:24,643 ERROR com.hotels.bdp.circustrain.CircusTrain:103 - Error creating bean with name 'replicaCatalog': Could not bind properties to ReplicaCatalog (prefix=replica-catalog, ignoreInvalidFields=false, ignoreUnknownFields=true, ignoreNestedProperties=false); nested exception is org.springframework.validation.BindException: org.springframework.boot.bind.RelaxedDataBinder$RelaxedBeanPropertyBindingResult: 2 errors
Field error in object 'replica-catalog' on field 'name': rejected value [null]; codes [NotBlank.replica-catalog.name,NotBlank.name,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.name,name]; arguments []; default message [name]]; default message [may not be empty]
Field error in object 'replica-catalog' on field 'hiveMetastoreUris': rejected value [null]; codes [NotBlank.replica-catalog.hiveMetastoreUris,NotBlank.hiveMetastoreUris,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.hiveMetastoreUris,hiveMetastoreUris]; arguments []; default message [hiveMetastoreUris]]; default message [may not be empty]
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'replicaCatalog': Could not bind properties to ReplicaCatalog (prefix=replica-catalog, ignoreInvalidFields=false, ignoreUnknownFields=true, ignoreNestedProperties=false); nested exception is org.springframework.validation.BindException: org.springframework.boot.bind.RelaxedDataBinder$RelaxedBeanPropertyBindingResult: 2 errors
Field error in object 'replica-catalog' on field 'name': rejected value [null]; codes [NotBlank.replica-catalog.name,NotBlank.name,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.name,name]; arguments []; default message [name]]; default message [may not be empty]
Field error in object 'replica-catalog' on field 'hiveMetastoreUris': rejected value [null]; codes [NotBlank.replica-catalog.hiveMetastoreUris,NotBlank.hiveMetastoreUris,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.hiveMetastoreUris,hiveMetastoreUris]; arguments []; default message [hiveMetastoreUris]]; default message [may not be empty]
	at org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor.postProcessBeforeInitialization(ConfigurationPropertiesBindingPostProcessor.java:339)
	at org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor.postProcessBeforeInitialization(ConfigurationPropertiesBindingPostProcessor.java:289)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:408)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1574)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:545)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:778)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:760)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:360)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:306)
	at com.hotels.bdp.circustrain.CircusTrain.main(CircusTrain.java:98)
	at com.hotels.bdp.circustrain.CircusTrainTest.emptyYmlFile(CircusTrainTest.java:204)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.contrib.java.lang.system.ExpectedSystemExit$1.evaluate(ExpectedSystemExit.java:130)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
Caused by: org.springframework.validation.BindException: org.springframework.boot.bind.RelaxedDataBinder$RelaxedBeanPropertyBindingResult: 2 errors
Field error in object 'replica-catalog' on field 'name': rejected value [null]; codes [NotBlank.replica-catalog.name,NotBlank.name,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.name,name]; arguments []; default message [name]]; default message [may not be empty]
Field error in object 'replica-catalog' on field 'hiveMetastoreUris': rejected value [null]; codes [NotBlank.replica-catalog.hiveMetastoreUris,NotBlank.hiveMetastoreUris,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [replica-catalog.hiveMetastoreUris,hiveMetastoreUris]; arguments []; default message [hiveMetastoreUris]]; default message [may not be empty]
	at org.springframework.boot.bind.PropertiesConfigurationFactory.validate(PropertiesConfigurationFactory.java:363)
	at org.springframework.boot.bind.PropertiesConfigurationFactory.doBindPropertiesToTarget(PropertiesConfigurationFactory.java:272)
	at org.springframework.boot.bind.PropertiesConfigurationFactory.bindPropertiesToTarget(PropertiesConfigurationFactory.java:241)
	at org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor.postProcessBeforeInitialization(ConfigurationPropertiesBindingPostProcessor.java:334)
	... 52 more
Usage: circus-train.sh --config=<config_file>[,<config_file>,...]
Errors found in the provided configuration file:
	may not be empty
	may not be empty
Configuration file help:
	For more information and help please refer to https://github.com/HotelsDotCom/circus-train/blob/master/README.md
2018-05-25 11:39:24,645 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:39:24,646 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:24,649 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:24,649 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:24,649 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 11: Cleaning up thread local RawStore...
2018-05-25 11:39:24,649 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:24,649 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 11: Done cleaning up thread local RawStore
2018-05-25 11:39:24,650 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:24,736 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 13: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:24,737 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:24,750 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:39:24,750 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:39:25,089 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:39:25,617 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:25,617 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:25,619 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:39:25,679 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:39:25,681 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:39:25,703 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:39:25,704 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:39:25,704 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58220]...
2018-05-25 11:39:25,704 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:39:25,704 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:39:25,704 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:39:26,735 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58220
2018-05-25 11:39:26,735 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:39:26,736 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:26,737 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58220
2018-05-25 11:39:26,738 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:26,739 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:26,739 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 15: source:127.0.0.1 create_database: Database(name:test_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7372887437185101848/test_database, parameters:null)
2018-05-25 11:39:26,739 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:test_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7372887437185101848/test_database, parameters:null)	
2018-05-25 11:39:26,763 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:26,763 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:26,770 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:26,771 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:26,771 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database test_database, returning NoSuchObjectException
2018-05-25 11:39:26,772 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7372887437185101848/test_database
2018-05-25 11:39:26,789 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:26,790 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 14: source:127.0.0.1 create_table: Table(tableName:source_test_table, dbName:test_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:null, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:null), partitionKeys:null, parameters:{EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:26,790 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:source_test_table, dbName:test_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:null, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:null), partitionKeys:null, parameters:{EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:26,790 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:26,792 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:26,793 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:26,793 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 15: Cleaning up thread local RawStore...
2018-05-25 11:39:26,793 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:26,793 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 15: Done cleaning up thread local RawStore
2018-05-25 11:39:26,793 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:26,819 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:26,820 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:26,822 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:26,822 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:26,834 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7372887437185101848/test_database/source_test_table
2018-05-25 11:39:26,920 INFO  com.hotels.bdp.circustrain.CircusTrain:123 - Ant-Version=Apache Ant 1.8.4; Created-By=1.6.0_65-b14-466-11M4802 (Apple Inc.); Manifest-Version=1.0; 
2018-05-25 11:39:26,967 ERROR org.springframework.boot.SpringApplication:821 - Application startup failed
com.hotels.bdp.circustrain.ConfigFileValidationException: Error reading config file(s).
	at com.hotels.bdp.circustrain.ConfigFileValidationApplicationListener.onApplicationEvent(ConfigFileValidationApplicationListener.java:49)
	at com.hotels.bdp.circustrain.ConfigFileValidationApplicationListener.onApplicationEvent(ConfigFileValidationApplicationListener.java:28)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:166)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:121)
	at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:111)
	at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:65)
	at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:54)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:329)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:306)
	at com.hotels.bdp.circustrain.CircusTrain.main(CircusTrain.java:98)
	at com.hotels.bdp.circustrain.CircusTrainTest.ymlFileDoesNotExist(CircusTrainTest.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.contrib.java.lang.system.ExpectedSystemExit$1.evaluate(ExpectedSystemExit.java:130)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:39:26,968 INFO  org.springframework.boot.logging.ClasspathLoggingApplicationListener:57 - Application failed to start with classpath: [file:/Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/surefire/surefirebooter8375855852412627105.jar]
2018-05-25 11:39:26,968 ERROR com.hotels.bdp.circustrain.CircusTrain:100 - Error reading config file(s).
com.hotels.bdp.circustrain.ConfigFileValidationException: Error reading config file(s).
	at com.hotels.bdp.circustrain.ConfigFileValidationApplicationListener.onApplicationEvent(ConfigFileValidationApplicationListener.java:49)
	at com.hotels.bdp.circustrain.ConfigFileValidationApplicationListener.onApplicationEvent(ConfigFileValidationApplicationListener.java:28)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:166)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:121)
	at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:111)
	at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:65)
	at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:54)
	at org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:329)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:306)
	at com.hotels.bdp.circustrain.CircusTrain.main(CircusTrain.java:98)
	at com.hotels.bdp.circustrain.CircusTrainTest.ymlFileDoesNotExist(CircusTrainTest.java:86)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.contrib.java.lang.system.ExpectedSystemExit$1.evaluate(ExpectedSystemExit.java:130)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
Usage: circus-train.sh --config=<config_file>[,<config_file>,...]
Errors found in the provided configuration file:
	Config file /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit191499869670839557/test-application.yml does not exist.
Configuration file help:
	For more information and help please refer to https://github.com/HotelsDotCom/circus-train/blob/master/README.md
2018-05-25 11:39:26,969 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:39:26,969 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:26,971 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:26,971 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:26,972 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 14: Cleaning up thread local RawStore...
2018-05-25 11:39:26,972 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:26,972 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 14: Done cleaning up thread local RawStore
2018-05-25 11:39:26,972 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:27,054 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:27,055 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:27,065 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:39:27,065 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:39:27,384 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:39:27,838 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:27,838 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:27,841 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:39:27,891 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:39:27,892 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:39:27,914 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:39:27,914 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:39:27,914 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58223]...
2018-05-25 11:39:27,914 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:39:27,915 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:39:27,915 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:39:28,945 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58223
2018-05-25 11:39:28,945 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:39:28,946 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:28,947 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58223
2018-05-25 11:39:28,948 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:28,948 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:28,949 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 18: source:127.0.0.1 create_database: Database(name:test_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2284608675427920398/test_database, parameters:null)
2018-05-25 11:39:28,949 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:test_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2284608675427920398/test_database, parameters:null)	
2018-05-25 11:39:28,973 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:28,973 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:28,980 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:28,980 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:28,981 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database test_database, returning NoSuchObjectException
2018-05-25 11:39:28,982 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2284608675427920398/test_database
2018-05-25 11:39:29,000 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:29,001 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 17: source:127.0.0.1 create_table: Table(tableName:source_test_table, dbName:test_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:null, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:null), partitionKeys:null, parameters:{EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:29,001 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:source_test_table, dbName:test_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:null, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:null), partitionKeys:null, parameters:{EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:29,001 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:29,003 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:29,003 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:29,003 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 18: Cleaning up thread local RawStore...
2018-05-25 11:39:29,003 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:29,003 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 18: Done cleaning up thread local RawStore
2018-05-25 11:39:29,003 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:29,029 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:29,030 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:29,033 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:29,033 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:29,043 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2284608675427920398/test_database/source_test_table
2018-05-25 11:39:29,133 INFO  com.hotels.bdp.circustrain.CircusTrain:123 - Ant-Version=Apache Ant 1.8.4; Created-By=1.6.0_65-b14-466-11M4802 (Apple Inc.); Manifest-Version=1.0; 
         ee@@@@@@@@@@@@@@@
       e@@@@@@@@@@@@@@@
      @@@"     .-.----.      ___ _                   ___ _                   _
     @@"___   / o )    \    / __\ |__   ___   ___   / __\ |__   ___   ___   / \
    II__[w]   ||  __  |'  / /  | '_ \ / _ \ / _ \ / /  | '_ \ / _ \ / _ \ /  /
   {======|_ '- |||  |||  / /___| | | | (_) | (_) / /___| | | | (_) | (_) /\_/
  /oO--000'"`--OO----OO-' \____/|_| |_|\___/ \___/\____/|_| |_|\___/ \___/\/
2018-05-25 11:39:29,191 INFO  com.hotels.bdp.circustrain.CircusTrain:48 - Starting CircusTrain on LONC02S91UPG8WL.sea.corp.expecn.com with PID 12851 (/Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/classes started by cedwards in /Users/cedwards/Documents/workspace/circus-train/circus-train-core)
2018-05-25 11:39:29,191 INFO  com.hotels.bdp.circustrain.CircusTrain:664 - The following profiles are active: replication,housekeeping
2018-05-25 11:39:29,193 INFO  org.springframework.context.annotation.AnnotationConfigApplicationContext:578 - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@1253b822: startup date [Fri May 25 11:39:29 BST 2018]; root of context hierarchy
2018-05-25 11:39:29,671 WARN  org.springframework.context.annotation.ConfigurationClassEnhancer:348 - @Bean method EnableEncryptablePropertySourcesConfiguration.enableEncryptablePropertySourcesPostProcessor is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2018-05-25 11:39:29,671 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:83 - Post-processing PropertySource instances
2018-05-25 11:39:29,673 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource commandLineArgs[org.springframework.core.env.SimpleCommandLinePropertySource] to EncryptableEnumerablePropertySourceWrapper
2018-05-25 11:39:29,673 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource systemProperties[org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:29,673 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource systemEnvironment[org.springframework.core.env.SystemEnvironmentPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:29,674 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource random[org.springframework.boot.context.config.RandomValuePropertySource] to EncryptablePropertySourceWrapper
2018-05-25 11:39:29,674 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource applicationConfig: [file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2063696425354518770/test-application.yml][org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:29,674 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource defaultProperties[org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:29,677 INFO  org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor:153 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-25 11:39:29,761 INFO  com.zaxxer.hikari.HikariDataSource:93 - HikariPool-3 - Started.
2018-05-25 11:39:29,793 INFO  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean:336 - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-25 11:39:29.793  INFO 12851 --- [           main] o.h.j.i.u.LogHelper                      : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-05-25 11:39:29.805  INFO 12851 --- [           main] o.h.d.Dialect                            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-05-25 11:39:29.807  INFO 12851 --- [           main] o.h.h.i.a.ASTQueryTranslatorFactory      : HHH000397: Using ASTQueryTranslatorFactory
2018-05-25 11:39:29.811  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000227: Running hbm2ddl schema export
2018-05-25 11:39:29.812  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000230: Schema export complete
2018-05-25 11:39:29,827 INFO  com.hotels.bdp.circustrain.CircusTrain:123 - Ant-Version=Apache Ant 1.8.4; Created-By=1.6.0_65-b14-466-11M4802 (Apple Inc.); Manifest-Version=1.0; 
2018-05-25 11:39:29,930 INFO  com.hotels.bdp.circustrain.context.CommonBeans:88 - No Hadoop site XML is defined for catalog source.
2018-05-25 11:39:29,989 INFO  com.hotels.bdp.circustrain.context.CommonBeans:88 - No Hadoop site XML is defined for catalog replica.
2018-05-25 11:39:30,172 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:431 - Registering beans for JMX exposure on startup
2018-05-25 11:39:30,172 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:912 - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-05-25 11:39:30,174 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:667 - Located MBean 'dataSource': registering with JMX server as MBean [com.zaxxer.hikari:name=dataSource,type=HikariDataSource]
2018-05-25 11:39:30,178 INFO  com.hotels.bdp.circustrain.core.Locomotive:106 - 1 tables to replicate.
2018-05-25 11:39:30,178 INFO  com.hotels.bdp.circustrain.core.Locomotive:109 - Replicating source:test_database.source_test_table to replica:test_database.replica_test_table replication mode 'FULL'.
2018-05-25 11:39:30,179 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58223
2018-05-25 11:39:30,179 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:30,181 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:30,181 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: source:127.0.0.1 get_database: test_database
2018-05-25 11:39:30,182 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: test_database	
2018-05-25 11:39:30,213 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 19: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:30,213 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,216 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,216 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,218 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:30,218 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58223
2018-05-25 11:39:30,218 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,219 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:30,220 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:30,220 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 20: source:127.0.0.1 get_database: test_database
2018-05-25 11:39:30,220 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: test_database	
2018-05-25 11:39:30,220 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,221 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,221 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: Cleaning up thread local RawStore...
2018-05-25 11:39:30,221 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:30,221 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 19: Done cleaning up thread local RawStore
2018-05-25 11:39:30,221 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:30,244 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:30,245 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,247 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,247 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,248 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:30,249 INFO  com.hotels.bdp.circustrain.core.source.Source:113 - Retrieving table metadata for 'test_database.source_test_table'
2018-05-25 11:39:30,249 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,249 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58223
2018-05-25 11:39:30,250 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:30,251 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:30,251 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 21: source:127.0.0.1 get_table : db=test_database tbl=source_test_table
2018-05-25 11:39:30,251 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=source_test_table	
2018-05-25 11:39:30,252 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,252 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,252 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 20: Cleaning up thread local RawStore...
2018-05-25 11:39:30,252 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:30,253 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 20: Done cleaning up thread local RawStore
2018-05-25 11:39:30,253 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:30,279 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:30,280 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,282 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,282 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,322 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,324 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,324 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,325 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 21: source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table
2018-05-25 11:39:30,325 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table	
2018-05-25 11:39:30,334 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:30,334 INFO  com.hotels.bdp.circustrain.core.source.Source:113 - Retrieving table metadata for 'test_database.source_test_table'
2018-05-25 11:39:30,335 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,335 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58223
2018-05-25 11:39:30,335 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:30,336 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:30,337 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 get_table : db=test_database tbl=source_test_table
2018-05-25 11:39:30,337 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=source_test_table	
2018-05-25 11:39:30,337 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,337 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,338 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 21: Cleaning up thread local RawStore...
2018-05-25 11:39:30,338 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:30,338 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 21: Done cleaning up thread local RawStore
2018-05-25 11:39:30,338 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:30,364 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 22: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:30,364 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,366 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,366 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,376 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,378 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,378 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,378 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table
2018-05-25 11:39:30,378 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table	
2018-05-25 11:39:30,385 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:30,386 INFO  com.hotels.bdp.circustrain.core.event.LoggingListener:REPLICATION_EVENTS:63 - [ctt-20180525t103930.385z-nhb2vwb1] Attempting to replicate 'source:test_database.source_test_table' to 'replica:test_database.replica_test_table'
2018-05-25 11:39:30,386 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,386 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58223
2018-05-25 11:39:30,387 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:30,388 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:30,388 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,388 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,388 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: Cleaning up thread local RawStore...
2018-05-25 11:39:30,388 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:30,388 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 22: Done cleaning up thread local RawStore
2018-05-25 11:39:30,388 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 23: source:127.0.0.1 get_table : db=test_database tbl=replica_test_table
2018-05-25 11:39:30,388 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:30,389 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=replica_test_table	
2018-05-25 11:39:30,414 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:30,414 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,416 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,416 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,417 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:30,417 INFO  com.hotels.bdp.circustrain.core.source.Source:113 - Retrieving table metadata for 'test_database.source_test_table'
2018-05-25 11:39:30,417 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58223
2018-05-25 11:39:30,417 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,418 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:30,419 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:30,419 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 24: source:127.0.0.1 get_table : db=test_database tbl=source_test_table
2018-05-25 11:39:30,419 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=source_test_table	
2018-05-25 11:39:30,420 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,420 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,420 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 23: Cleaning up thread local RawStore...
2018-05-25 11:39:30,420 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:30,420 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 23: Done cleaning up thread local RawStore
2018-05-25 11:39:30,421 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:30,446 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:30,447 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,449 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,449 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,457 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,459 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,459 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,460 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 24: source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table
2018-05-25 11:39:30,460 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table	
2018-05-25 11:39:30,467 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:30,467 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,468 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58223
2018-05-25 11:39:30,469 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:30,469 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,469 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:30,470 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,470 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:30,470 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 24: Cleaning up thread local RawStore...
2018-05-25 11:39:30,470 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:30,470 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 24: Done cleaning up thread local RawStore
2018-05-25 11:39:30,470 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 25: source:127.0.0.1 get_table : db=test_database tbl=replica_test_table
2018-05-25 11:39:30,470 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:30,471 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=replica_test_table	
2018-05-25 11:39:30,497 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 25: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:30,498 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,499 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,499 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,501 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,502 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,503 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,503 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 25: source:127.0.0.1 create_table: Table(tableName:replica_test_table, dbName:test_database, owner:null, createTime:1527244769, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2063696425354518770/replica/ctt-20180525t103930.385z-nhb2vwb1, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{com.hotels.bdp.circustrain.last.replicated=2018-05-25T10:39:30.470Z, transient_lastDdlTime=1527244769, STATS_GENERATED_VIA_STATS_TASK=true, DO_NOT_UPDATE_STATS=true, com.hotels.bdp.circustrain.source.metastore.uris=thrift://localhost:58223, EXTERNAL=TRUE, com.hotels.bdp.circustrain.replication.event=ctt-20180525t103930.385z-nhb2vwb1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2284608675427920398/test_database/source_test_table, com.hotels.bdp.circustrain.source.table=test_database.source_test_table, STATS_GENERATED=true, com.hotels.bdp.circustrain.replication.mode=FULL}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, rewriteEnabled:false)
2018-05-25 11:39:30,503 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:replica_test_table, dbName:test_database, owner:null, createTime:1527244769, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2063696425354518770/replica/ctt-20180525t103930.385z-nhb2vwb1, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{com.hotels.bdp.circustrain.last.replicated=2018-05-25T10:39:30.470Z, transient_lastDdlTime=1527244769, STATS_GENERATED_VIA_STATS_TASK=true, DO_NOT_UPDATE_STATS=true, com.hotels.bdp.circustrain.source.metastore.uris=thrift://localhost:58223, EXTERNAL=TRUE, com.hotels.bdp.circustrain.replication.event=ctt-20180525t103930.385z-nhb2vwb1, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2284608675427920398/test_database/source_test_table, com.hotels.bdp.circustrain.source.table=test_database.source_test_table, STATS_GENERATED=true, com.hotels.bdp.circustrain.replication.mode=FULL}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, rewriteEnabled:false)	
2018-05-25 11:39:30,504 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2063696425354518770/replica/ctt-20180525t103930.385z-nhb2vwb1
2018-05-25 11:39:30,528 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:30,528 INFO  com.hotels.bdp.circustrain.core.UnpartitionedTableReplication:108 - Replicated table test_database.source_test_table.
2018-05-25 11:39:30,528 INFO  com.hotels.bdp.circustrain.core.Locomotive:115 - Completed replicating: source:test_database.source_test_table to replica:test_database.replica_test_table.
2018-05-25 11:39:30,528 INFO  com.hotels.bdp.circustrain.core.event.LoggingListener:REPLICATION_EVENTS:71 - [ctt-20180525t103930.385z-nhb2vwb1] Successfully replicated all of 'source:test_database.source_test_table' to 'replica:test_database.replica_test_table' (0 bytes)
2018-05-25 11:39:30,529 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,529 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - test_database.replica_test_table.replication_time : 143
2018-05-25 11:39:30,529 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - test_database.replica_test_table.completion_code : 1
2018-05-25 11:39:30,529 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - test_database.replica_test_table.bytes_replicated : 0
2018-05-25 11:39:30,529 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - tables_replicated : 1
2018-05-25 11:39:30,529 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - completion_code : 1
2018-05-25 11:39:30,530 INFO  com.hotels.bdp.circustrain.CircusTrain:57 - Started CircusTrain in 1.393 seconds (JVM running for 20.478)
2018-05-25 11:39:30,530 INFO  org.springframework.context.annotation.AnnotationConfigApplicationContext:960 - Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@1253b822: startup date [Fri May 25 11:39:29 BST 2018]; root of context hierarchy
2018-05-25 11:39:30,530 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,531 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,531 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 25: Cleaning up thread local RawStore...
2018-05-25 11:39:30,531 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:30,531 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 25: Done cleaning up thread local RawStore
2018-05-25 11:39:30,531 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:30,532 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:449 - Unregistering JMX-exposed beans on shutdown
2018-05-25 11:39:30,532 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:241 - Unregistering JMX-exposed beans
2018-05-25 11:39:30,532 INFO  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean:481 - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-05-25 11:39:30.532  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000227: Running hbm2ddl schema export
2018-05-25 11:39:30.533  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000230: Schema export complete
2018-05-25 11:39:30,533 INFO  com.zaxxer.hikari.pool.HikariPool:202 - HikariPool-3 - Close initiated...
2018-05-25 11:39:30,536 INFO  com.zaxxer.hikari.pool.HikariPool:242 - HikariPool-3 - Closed.
2018-05-25 11:39:30,537 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,539 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,539 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,539 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 17: source:127.0.0.1 get_table : db=test_database tbl=replica_test_table
2018-05-25 11:39:30,539 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=replica_test_table	
2018-05-25 11:39:30,546 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:39:30,546 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,548 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:30,548 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:30,549 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 17: Cleaning up thread local RawStore...
2018-05-25 11:39:30,549 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:30,549 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 17: Done cleaning up thread local RawStore
2018-05-25 11:39:30,549 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:30,630 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 26: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:30,631 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:30,639 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:39:30,639 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:39:30,963 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:39:31,399 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:31,399 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:31,402 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:39:31,452 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:39:31,453 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:39:31,474 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:39:31,475 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:39:31,475 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58233]...
2018-05-25 11:39:31,475 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:39:31,475 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:39:31,475 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:39:32,505 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58233
2018-05-25 11:39:32,505 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:39:32,506 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:32,507 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58233
2018-05-25 11:39:32,508 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:32,508 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:32,509 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 28: source:127.0.0.1 create_database: Database(name:test_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2385866804027361771/test_database, parameters:null)
2018-05-25 11:39:32,509 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:test_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2385866804027361771/test_database, parameters:null)	
2018-05-25 11:39:32,530 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 28: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:32,531 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:32,538 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:32,538 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:32,539 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database test_database, returning NoSuchObjectException
2018-05-25 11:39:32,539 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2385866804027361771/test_database
2018-05-25 11:39:32,557 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:32,558 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 27: source:127.0.0.1 create_table: Table(tableName:source_test_table, dbName:test_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:null, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:null), partitionKeys:null, parameters:{EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
2018-05-25 11:39:32,558 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:32,558 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:source_test_table, dbName:test_database, owner:null, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:null, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:null), bucketCols:null, sortCols:null, parameters:null), partitionKeys:null, parameters:{EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)	
2018-05-25 11:39:32,559 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:32,559 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:32,560 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 28: Cleaning up thread local RawStore...
2018-05-25 11:39:32,560 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:32,560 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 28: Done cleaning up thread local RawStore
2018-05-25 11:39:32,560 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:32,588 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 27: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:32,589 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:32,591 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:32,591 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:32,602 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2385866804027361771/test_database/source_test_table
2018-05-25 11:39:32,728 INFO  com.hotels.bdp.circustrain.CircusTrain:123 - Ant-Version=Apache Ant 1.8.4; Created-By=1.6.0_65-b14-466-11M4802 (Apple Inc.); Manifest-Version=1.0; 
         ee@@@@@@@@@@@@@@@
       e@@@@@@@@@@@@@@@
      @@@"     .-.----.      ___ _                   ___ _                   _
     @@"___   / o )    \    / __\ |__   ___   ___   / __\ |__   ___   ___   / \
    II__[w]   ||  __  |'  / /  | '_ \ / _ \ / _ \ / /  | '_ \ / _ \ / _ \ /  /
   {======|_ '- |||  |||  / /___| | | | (_) | (_) / /___| | | | (_) | (_) /\_/
  /oO--000'"`--OO----OO-' \____/|_| |_|\___/ \___/\____/|_| |_|\___/ \___/\/
2018-05-25 11:39:32,794 INFO  com.hotels.bdp.circustrain.extension.ExtensionInitializer:45 - Adding packageNames '[com.hotels.test.extension]' to component scan.
2018-05-25 11:39:32,796 INFO  com.hotels.bdp.circustrain.CircusTrain:48 - Starting CircusTrain on LONC02S91UPG8WL.sea.corp.expecn.com with PID 12851 (/Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/classes started by cedwards in /Users/cedwards/Documents/workspace/circus-train/circus-train-core)
2018-05-25 11:39:32,796 INFO  com.hotels.bdp.circustrain.CircusTrain:664 - The following profiles are active: replication,housekeeping
2018-05-25 11:39:32,797 INFO  org.springframework.context.annotation.AnnotationConfigApplicationContext:578 - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@70dd79f7: startup date [Fri May 25 11:39:32 BST 2018]; root of context hierarchy
2018-05-25 11:39:33,157 WARN  org.springframework.context.annotation.ConfigurationClassEnhancer:348 - @Bean method EnableEncryptablePropertySourcesConfiguration.enableEncryptablePropertySourcesPostProcessor is non-static and returns an object assignable to Spring's BeanFactoryPostProcessor interface. This will result in a failure to process annotations such as @Autowired, @Resource and @PostConstruct within the method's declaring @Configuration class. Add the 'static' modifier to this method to avoid these container lifecycle issues; see @Bean javadoc for complete details.
2018-05-25 11:39:33,157 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:83 - Post-processing PropertySource instances
2018-05-25 11:39:33,159 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource commandLineArgs[org.springframework.core.env.SimpleCommandLinePropertySource] to EncryptableEnumerablePropertySourceWrapper
2018-05-25 11:39:33,159 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource systemProperties[org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:33,159 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource systemEnvironment[org.springframework.core.env.SystemEnvironmentPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:33,159 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource random[org.springframework.boot.context.config.RandomValuePropertySource] to EncryptablePropertySourceWrapper
2018-05-25 11:39:33,160 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource applicationConfig: [file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5056597625805426675/test-application.yml][org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:33,160 INFO  com.ulisesbocchio.jasyptspringboot.EnableEncryptablePropertySourcesPostProcessor:48 - Converting PropertySource defaultProperties[org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper
2018-05-25 11:39:33,162 INFO  org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor:153 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-25 11:39:33,237 INFO  com.zaxxer.hikari.HikariDataSource:93 - HikariPool-4 - Started.
2018-05-25 11:39:33,266 INFO  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean:336 - Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-25 11:39:33.267  INFO 12851 --- [           main] o.h.j.i.u.LogHelper                      : HHH000204: Processing PersistenceUnitInfo [
	name: default
	...]
2018-05-25 11:39:33.280  INFO 12851 --- [           main] o.h.d.Dialect                            : HHH000400: Using dialect: org.hibernate.dialect.H2Dialect
2018-05-25 11:39:33.282  INFO 12851 --- [           main] o.h.h.i.a.ASTQueryTranslatorFactory      : HHH000397: Using ASTQueryTranslatorFactory
2018-05-25 11:39:33.286  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000227: Running hbm2ddl schema export
2018-05-25 11:39:33.287  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000230: Schema export complete
2018-05-25 11:39:33,309 INFO  com.hotels.bdp.circustrain.CircusTrain:123 - Ant-Version=Apache Ant 1.8.4; Created-By=1.6.0_65-b14-466-11M4802 (Apple Inc.); Manifest-Version=1.0; 
2018-05-25 11:39:33,402 INFO  com.hotels.bdp.circustrain.context.CommonBeans:88 - No Hadoop site XML is defined for catalog source.
2018-05-25 11:39:33,455 INFO  com.hotels.bdp.circustrain.context.CommonBeans:88 - No Hadoop site XML is defined for catalog replica.
2018-05-25 11:39:33,621 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:431 - Registering beans for JMX exposure on startup
2018-05-25 11:39:33,622 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:912 - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-05-25 11:39:33,623 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:667 - Located MBean 'dataSource': registering with JMX server as MBean [com.zaxxer.hikari:name=dataSource,type=HikariDataSource]
2018-05-25 11:39:33,626 INFO  com.hotels.bdp.circustrain.core.Locomotive:106 - 1 tables to replicate.
2018-05-25 11:39:33,626 INFO  com.hotels.bdp.circustrain.core.Locomotive:109 - Replicating source:test_database.source_test_table to replica:test_database.replica_test_table replication mode 'FULL'.
2018-05-25 11:39:33,627 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58233
2018-05-25 11:39:33,627 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:33,628 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:33,628 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 29: source:127.0.0.1 get_database: test_database
2018-05-25 11:39:33,629 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: test_database	
2018-05-25 11:39:33,656 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 29: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:33,657 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,658 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,659 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,660 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:33,661 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,662 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58233
2018-05-25 11:39:33,662 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:33,663 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,663 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:33,663 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,664 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 29: Cleaning up thread local RawStore...
2018-05-25 11:39:33,664 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:33,664 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 29: Done cleaning up thread local RawStore
2018-05-25 11:39:33,664 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 30: source:127.0.0.1 get_database: test_database
2018-05-25 11:39:33,664 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:33,664 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: test_database	
2018-05-25 11:39:33,690 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 30: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:33,691 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,692 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,692 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,693 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:33,693 INFO  com.hotels.bdp.circustrain.core.source.Source:113 - Retrieving table metadata for 'test_database.source_test_table'
2018-05-25 11:39:33,694 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,694 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58233
2018-05-25 11:39:33,694 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:33,695 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:33,696 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,696 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 31: source:127.0.0.1 get_table : db=test_database tbl=source_test_table
2018-05-25 11:39:33,696 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,696 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=source_test_table	
2018-05-25 11:39:33,696 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 30: Cleaning up thread local RawStore...
2018-05-25 11:39:33,696 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:33,696 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 30: Done cleaning up thread local RawStore
2018-05-25 11:39:33,697 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:33,720 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 31: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:33,720 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,722 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,722 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,758 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,759 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,759 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,759 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 31: source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table
2018-05-25 11:39:33,760 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table	
2018-05-25 11:39:33,768 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:33,769 INFO  com.hotels.bdp.circustrain.core.source.Source:113 - Retrieving table metadata for 'test_database.source_test_table'
2018-05-25 11:39:33,769 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,769 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58233
2018-05-25 11:39:33,770 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:33,771 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:33,771 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,771 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,771 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 31: Cleaning up thread local RawStore...
2018-05-25 11:39:33,771 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 32: source:127.0.0.1 get_table : db=test_database tbl=source_test_table
2018-05-25 11:39:33,772 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=source_test_table	
2018-05-25 11:39:33,771 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:33,772 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 31: Done cleaning up thread local RawStore
2018-05-25 11:39:33,772 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:33,803 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 32: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:33,804 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,806 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,807 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,818 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,820 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,820 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,820 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 32: source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table
2018-05-25 11:39:33,820 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table	
2018-05-25 11:39:33,829 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:33,829 INFO  com.hotels.bdp.circustrain.core.event.LoggingListener:REPLICATION_EVENTS:63 - [ctt-20180525t103933.829z-93prm5up] Attempting to replicate 'source:test_database.source_test_table' to 'replica:test_database.replica_test_table'
2018-05-25 11:39:33,830 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,830 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58233
2018-05-25 11:39:33,830 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:33,831 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:33,832 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,832 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 33: source:127.0.0.1 get_table : db=test_database tbl=replica_test_table
2018-05-25 11:39:33,832 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,833 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=replica_test_table	
2018-05-25 11:39:33,833 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 32: Cleaning up thread local RawStore...
2018-05-25 11:39:33,833 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:33,834 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 32: Done cleaning up thread local RawStore
2018-05-25 11:39:33,834 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:33,860 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 33: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:33,861 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,862 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,862 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,863 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:33,863 INFO  com.hotels.bdp.circustrain.core.source.Source:113 - Retrieving table metadata for 'test_database.source_test_table'
2018-05-25 11:39:33,864 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,864 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58233
2018-05-25 11:39:33,865 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:33,866 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:33,867 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 34: source:127.0.0.1 get_table : db=test_database tbl=source_test_table
2018-05-25 11:39:33,867 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=source_test_table	
2018-05-25 11:39:33,867 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,867 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,868 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 33: Cleaning up thread local RawStore...
2018-05-25 11:39:33,868 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:33,868 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 33: Done cleaning up thread local RawStore
2018-05-25 11:39:33,868 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:33,893 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 34: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:33,893 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,895 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,895 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,904 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,905 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,905 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,905 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 34: source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table
2018-05-25 11:39:33,905 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table_statistics_req: db=test_database table=source_test_table	
2018-05-25 11:39:33,913 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:33,914 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,914 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58233
2018-05-25 11:39:33,914 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:39:33,915 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,915 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:39:33,915 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,916 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:33,916 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 34: Cleaning up thread local RawStore...
2018-05-25 11:39:33,916 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:33,916 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 35: source:127.0.0.1 get_table : db=test_database tbl=replica_test_table
2018-05-25 11:39:33,916 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 34: Done cleaning up thread local RawStore
2018-05-25 11:39:33,916 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : db=test_database tbl=replica_test_table	
2018-05-25 11:39:33,917 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:33,940 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 35: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:39:33,940 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,942 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,942 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,943 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,944 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,944 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,945 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 35: source:127.0.0.1 create_table: Table(tableName:replica_test_table, dbName:test_database, owner:null, createTime:1527244772, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5056597625805426675/replica/ctt-20180525t103933.829z-93prm5up, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{com.hotels.bdp.circustrain.last.replicated=2018-05-25T10:39:33.916Z, transient_lastDdlTime=1527244772, STATS_GENERATED_VIA_STATS_TASK=true, DO_NOT_UPDATE_STATS=true, com.hotels.bdp.circustrain.source.metastore.uris=thrift://localhost:58233, EXTERNAL=TRUE, com.hotels.bdp.circustrain.replication.event=ctt-20180525t103933.829z-93prm5up, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2385866804027361771/test_database/source_test_table, com.hotels.bdp.circustrain.source.table=test_database.source_test_table, STATS_GENERATED=true, com.hotels.bdp.circustrain.replication.mode=FULL}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, rewriteEnabled:false)
2018-05-25 11:39:33,945 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_table: Table(tableName:replica_test_table, dbName:test_database, owner:null, createTime:1527244772, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col1, type:string, comment:null)], location:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5056597625805426675/replica/ctt-20180525t103933.829z-93prm5up, inputFormat:null, outputFormat:null, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:null, parameters:{}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{com.hotels.bdp.circustrain.last.replicated=2018-05-25T10:39:33.916Z, transient_lastDdlTime=1527244772, STATS_GENERATED_VIA_STATS_TASK=true, DO_NOT_UPDATE_STATS=true, com.hotels.bdp.circustrain.source.metastore.uris=thrift://localhost:58233, EXTERNAL=TRUE, com.hotels.bdp.circustrain.replication.event=ctt-20180525t103933.829z-93prm5up, com.hotels.bdp.circustrain.source.location=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2385866804027361771/test_database/source_test_table, com.hotels.bdp.circustrain.source.table=test_database.source_test_table, STATS_GENERATED=true, com.hotels.bdp.circustrain.replication.mode=FULL}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, rewriteEnabled:false)	
2018-05-25 11:39:33,946 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5056597625805426675/replica/ctt-20180525t103933.829z-93prm5up
2018-05-25 11:39:33,969 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:39:33,969 INFO  com.hotels.bdp.circustrain.core.UnpartitionedTableReplication:108 - Replicated table test_database.source_test_table.
2018-05-25 11:39:33,970 INFO  com.hotels.bdp.circustrain.core.Locomotive:115 - Completed replicating: source:test_database.source_test_table to replica:test_database.replica_test_table.
2018-05-25 11:39:33,970 INFO  com.hotels.bdp.circustrain.core.event.LoggingListener:REPLICATION_EVENTS:71 - [ctt-20180525t103933.829z-93prm5up] Successfully replicated all of 'source:test_database.source_test_table' to 'replica:test_database.replica_test_table' (0 bytes)
2018-05-25 11:39:33,970 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:39:33,970 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - test_database.replica_test_table.replication_time : 141
2018-05-25 11:39:33,970 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - test_database.replica_test_table.completion_code : 1
2018-05-25 11:39:33,970 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - test_database.replica_test_table.bytes_replicated : 0
2018-05-25 11:39:33,970 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - tables_replicated : 1
2018-05-25 11:39:33,970 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - completion_code : 1
2018-05-25 11:39:33,971 INFO  com.hotels.bdp.circustrain.CircusTrain:57 - Started CircusTrain in 1.24 seconds (JVM running for 23.92)
2018-05-25 11:39:33,971 INFO  org.springframework.context.annotation.AnnotationConfigApplicationContext:960 - Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@70dd79f7: startup date [Fri May 25 11:39:32 BST 2018]; root of context hierarchy
2018-05-25 11:39:33,972 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,972 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,972 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 35: Cleaning up thread local RawStore...
2018-05-25 11:39:33,972 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:33,972 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 35: Done cleaning up thread local RawStore
2018-05-25 11:39:33,972 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:449 - Unregistering JMX-exposed beans on shutdown
2018-05-25 11:39:33,972 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:39:33,972 INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter:241 - Unregistering JMX-exposed beans
2018-05-25 11:39:33,973 INFO  org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean:481 - Closing JPA EntityManagerFactory for persistence unit 'default'
2018-05-25 11:39:33.974  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000227: Running hbm2ddl schema export
2018-05-25 11:39:33.974  INFO 12851 --- [           main] o.h.t.h.SchemaExport                     : HHH000230: Schema export complete
2018-05-25 11:39:33,975 INFO  com.zaxxer.hikari.pool.HikariPool:202 - HikariPool-4 - Close initiated...
2018-05-25 11:39:33,978 INFO  com.zaxxer.hikari.pool.HikariPool:242 - HikariPool-4 - Closed.
2018-05-25 11:39:33,979 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 0
2018-05-25 11:39:33,980 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.526 sec
Running com.hotels.bdp.circustrain.ConfigFileValidationApplicationListenerTest
2018-05-25 11:39:33,981 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:39:33,981 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:39:33,981 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 27: Cleaning up thread local RawStore...
2018-05-25 11:39:33,981 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:39:33,982 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 27: Done cleaning up thread local RawStore
2018-05-25 11:39:33,982 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.167 sec
Running com.hotels.bdp.circustrain.core.conf.ConfigurationPojosTest
2018-05-25 11:39:34,215 INFO  com.openpojo.log.LoggerFactory:87 - Logging subsystem initialized to [com.openpojo.log.impl.SLF4JLogger]
2018-05-25 11:39:34,226 INFO  com.openpojo.validation.affirm.Affirmation:87 - Dynamically setting affirmation implementation = [com.openpojo.validation.affirm.JUnitAssertAffirmation [@20711b02: ]]
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.091 sec
Running com.hotels.bdp.circustrain.core.conf.ExpressionParserFunctionsTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.core.conf.MetastoreTunnelTest
Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.111 sec
Running com.hotels.bdp.circustrain.core.conf.ReplicaCatalogIntegrationTest
         ee@@@@@@@@@@@@@@@
       e@@@@@@@@@@@@@@@
      @@@"     .-.----.      ___ _                   ___ _                   _
     @@"___   / o )    \    / __\ |__   ___   ___   / __\ |__   ___   ___   / \
    II__[w]   ||  __  |'  / /  | '_ \ / _ \ / _ \ / /  | '_ \ / _ \ / _ \ /  /
   {======|_ '- |||  |||  / /___| | | | (_) | (_) / /___| | | | (_) | (_) /\_/
  /oO--000'"`--OO----OO-' \____/|_| |_|\___/ \___/\____/|_| |_|\___/ \___/\/
2018-05-25 11:39:34,393 INFO  org.apache.maven.surefire.booter.ForkedBooter:48 - Starting ForkedBooter v2.12.4 on LONC02S91UPG8WL.sea.corp.expecn.com with PID 12851 (/Users/cedwards/.m2/repository/org/apache/maven/surefire/surefire-booter/2.12.4/surefire-booter-2.12.4.jar started by cedwards in /Users/cedwards/Documents/workspace/circus-train/circus-train-core)
2018-05-25 11:39:34,393 INFO  org.apache.maven.surefire.booter.ForkedBooter:660 - No active profile set, falling back to default profiles: default
2018-05-25 11:39:34,394 INFO  org.springframework.context.annotation.AnnotationConfigApplicationContext:578 - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@7c8537e9: startup date [Fri May 25 11:39:34 BST 2018]; root of context hierarchy
2018-05-25 11:39:34,396 INFO  org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor:153 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-25 11:39:34,417 INFO  org.apache.maven.surefire.booter.ForkedBooter:57 - Started ForkedBooter in 0.057 seconds (JVM running for 24.366)
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.06 sec
Running com.hotels.bdp.circustrain.core.conf.ReplicaCatalogTest
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.025 sec
Running com.hotels.bdp.circustrain.core.conf.SourceCatalogIntegrationTest
         ee@@@@@@@@@@@@@@@
       e@@@@@@@@@@@@@@@
      @@@"     .-.----.      ___ _                   ___ _                   _
     @@"___   / o )    \    / __\ |__   ___   ___   / __\ |__   ___   ___   / \
    II__[w]   ||  __  |'  / /  | '_ \ / _ \ / _ \ / /  | '_ \ / _ \ / _ \ /  /
   {======|_ '- |||  |||  / /___| | | | (_) | (_) / /___| | | | (_) | (_) /\_/
  /oO--000'"`--OO----OO-' \____/|_| |_|\___/ \___/\____/|_| |_|\___/ \___/\/
2018-05-25 11:39:34,479 INFO  org.apache.maven.surefire.booter.ForkedBooter:48 - Starting ForkedBooter v2.12.4 on LONC02S91UPG8WL.sea.corp.expecn.com with PID 12851 (/Users/cedwards/.m2/repository/org/apache/maven/surefire/surefire-booter/2.12.4/surefire-booter-2.12.4.jar started by cedwards in /Users/cedwards/Documents/workspace/circus-train/circus-train-core)
2018-05-25 11:39:34,479 INFO  org.apache.maven.surefire.booter.ForkedBooter:660 - No active profile set, falling back to default profiles: default
2018-05-25 11:39:34,480 INFO  org.springframework.context.annotation.AnnotationConfigApplicationContext:578 - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@19070326: startup date [Fri May 25 11:39:34 BST 2018]; root of context hierarchy
2018-05-25 11:39:34,481 INFO  org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor:153 - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-25 11:39:34,502 INFO  org.apache.maven.surefire.booter.ForkedBooter:57 - Started ForkedBooter in 0.056 seconds (JVM running for 24.451)
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.06 sec
Running com.hotels.bdp.circustrain.core.conf.SourceCatalogTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.011 sec
Running com.hotels.bdp.circustrain.core.conf.SourceTableTest
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.024 sec
Running com.hotels.bdp.circustrain.core.conf.SpringExpressionParserTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.027 sec
Running com.hotels.bdp.circustrain.core.conf.TableReplicationTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.015 sec
Running com.hotels.bdp.circustrain.core.CopierFactoryManagerTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.006 sec
Running com.hotels.bdp.circustrain.core.DiffGeneratedPartitionPredicateTest
2018-05-25 11:39:34,730 INFO  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:87 - Creating partition spec from '2' detected partitions.
2018-05-25 11:39:34,764 INFO  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:87 - Creating partition spec from '2' detected partitions.
2018-05-25 11:39:34,797 INFO  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:87 - Creating partition spec from '2' detected partitions.
2018-05-25 11:39:34,832 INFO  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:87 - Creating partition spec from '0' detected partitions.
2018-05-25 11:39:34,866 INFO  com.hotels.bdp.circustrain.comparator.listener.PartitionSpecCreatingDiffListener:87 - Creating partition spec from '2' detected partitions.
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.275 sec
Running com.hotels.bdp.circustrain.core.event.EventUtilsTest
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.04 sec
Running com.hotels.bdp.circustrain.core.event.LoggingListenerTest
2018-05-25 11:39:35,120 INFO  com.hotels.bdp.circustrain.core.event.LoggingListener:REPLICATION_EVENTS:63 - [event-id] Attempting to replicate 'null:null' to 'null:null'
2018-05-25 11:39:35,120 INFO  com.hotels.bdp.circustrain.core.event.LoggingListener:REPLICATION_EVENTS:63 - [event-id] Attempting to replicate 'null:null' to 'null:null'
2018-05-25 11:39:35,121 INFO  com.hotels.bdp.circustrain.core.event.LoggingListener:REPLICATION_EVENTS:63 - [event-id] Attempting to replicate 'null:null' to 'null:null'
2018-05-25 11:39:35,121 ERROR com.hotels.bdp.circustrain.core.event.LoggingListener:REPLICATION_EVENTS:78 - [event-id] Failed to replicate 'null:null' to 'null:null' with error 'Test'
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.214 sec
Running com.hotels.bdp.circustrain.core.event.MetricsListenerTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.021 sec
Running com.hotels.bdp.circustrain.core.EventIdFactoryTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec
Running com.hotels.bdp.circustrain.core.HiveEndpointTest
2018-05-25 11:39:35,229 INFO  com.hotels.bdp.circustrain.core.HiveEndpointTest$1:113 - Retrieving table metadata for 'database.table'
2018-05-25 11:39:35,257 INFO  com.hotels.bdp.circustrain.core.HiveEndpointTest$1:113 - Retrieving table metadata for 'database.table'
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.112 sec
Running com.hotels.bdp.circustrain.core.LocomotiveTest
2018-05-25 11:39:35,276 INFO  com.hotels.bdp.circustrain.core.Locomotive:106 - 2 tables to replicate.
2018-05-25 11:39:35,276 INFO  com.hotels.bdp.circustrain.core.Locomotive:109 - Replicating source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table1 replication mode 'null'.
2018-05-25 11:39:35,277 INFO  com.hotels.bdp.circustrain.core.Locomotive:115 - Completed replicating: source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table1.
2018-05-25 11:39:35,277 INFO  com.hotels.bdp.circustrain.core.Locomotive:109 - Replicating source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table2 replication mode 'null'.
2018-05-25 11:39:35,278 INFO  com.hotels.bdp.circustrain.core.Locomotive:115 - Completed replicating: source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table2.
2018-05-25 11:39:35,278 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - tables_replicated : 2
2018-05-25 11:39:35,278 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - completion_code : 1
2018-05-25 11:39:35,281 INFO  com.hotels.bdp.circustrain.core.Locomotive:106 - 2 tables to replicate.
2018-05-25 11:39:35,281 INFO  com.hotels.bdp.circustrain.core.Locomotive:109 - Replicating source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table1 replication mode 'null'.
2018-05-25 11:39:35,282 ERROR com.hotels.bdp.circustrain.core.Locomotive:121 - Failed to replicate: source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table1.
java.lang.RuntimeException
	at com.hotels.bdp.circustrain.core.Locomotive.run(Locomotive.java:114)
	at com.hotels.bdp.circustrain.core.LocomotiveTest.exitCodeIsMinusOneWhenAllReplicationsFail(LocomotiveTest.java:126)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.mockito.internal.runners.JUnit45AndHigherRunnerImpl.run(JUnit45AndHigherRunnerImpl.java:37)
	at org.mockito.runners.MockitoJUnitRunner.run(MockitoJUnitRunner.java:62)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:39:35,282 INFO  com.hotels.bdp.circustrain.core.Locomotive:109 - Replicating source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table2 replication mode 'null'.
2018-05-25 11:39:35,283 ERROR com.hotels.bdp.circustrain.core.Locomotive:121 - Failed to replicate: source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table2.
java.lang.RuntimeException
	at com.hotels.bdp.circustrain.core.Locomotive.run(Locomotive.java:114)
	at com.hotels.bdp.circustrain.core.LocomotiveTest.exitCodeIsMinusOneWhenAllReplicationsFail(LocomotiveTest.java:126)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.mockito.internal.runners.JUnit45AndHigherRunnerImpl.run(JUnit45AndHigherRunnerImpl.java:37)
	at org.mockito.runners.MockitoJUnitRunner.run(MockitoJUnitRunner.java:62)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:39:35,284 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - tables_replicated : 2
2018-05-25 11:39:35,284 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - completion_code : -1
2018-05-25 11:39:35,286 INFO  com.hotels.bdp.circustrain.core.Locomotive:106 - 2 tables to replicate.
2018-05-25 11:39:35,286 INFO  com.hotels.bdp.circustrain.core.Locomotive:109 - Replicating source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table1 replication mode 'null'.
2018-05-25 11:39:35,286 INFO  com.hotels.bdp.circustrain.core.Locomotive:115 - Completed replicating: source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table1.
2018-05-25 11:39:35,287 INFO  com.hotels.bdp.circustrain.core.Locomotive:109 - Replicating source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table2 replication mode 'null'.
2018-05-25 11:39:35,287 ERROR com.hotels.bdp.circustrain.core.Locomotive:121 - Failed to replicate: source-catalog:source-database.source-table to replica-catalog:replica-database.replica-table2.
java.lang.RuntimeException
	at com.hotels.bdp.circustrain.core.Locomotive.run(Locomotive.java:114)
	at com.hotels.bdp.circustrain.core.LocomotiveTest.exitCodeIsMinusTwoWhenOneReplicationFails(LocomotiveTest.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.mockito.internal.runners.JUnit45AndHigherRunnerImpl.run(JUnit45AndHigherRunnerImpl.java:37)
	at org.mockito.runners.MockitoJUnitRunner.run(MockitoJUnitRunner.java:62)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:39:35,288 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - tables_replicated : 2
2018-05-25 11:39:35,288 INFO  com.hotels.bdp.circustrain.api.metrics.MetricSender:32 - completion_code : -1
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.03 sec
Running com.hotels.bdp.circustrain.core.metastore.MetaStoreClientFactoryManagerTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.037 sec
Running com.hotels.bdp.circustrain.core.metastore.ThriftHiveMetaStoreClientFactoryTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.036 sec
Running com.hotels.bdp.circustrain.core.PartitionedTableMetadataMirrorReplicationTest
2018-05-25 11:39:35,377 INFO  com.hotels.bdp.circustrain.core.PartitionedTableReplication:90 - No matching partitions found on table database.table with predicate partitionPredicate. Table metadata updated, no partitions were updated.
2018-05-25 11:39:35,379 INFO  com.hotels.bdp.circustrain.core.PartitionedTableReplication:97 - Metadata mirrored for 2 partitions of table database.table (no data copied).
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.021 sec
Running com.hotels.bdp.circustrain.core.PartitionedTableMetadataUpdateReplicationTest
2018-05-25 11:39:35,391 INFO  com.hotels.bdp.circustrain.core.PartitionedTableMetadataUpdateReplication:102 - No matching partitions found on table database.table with predicate partitionPredicate. Table metadata updated, no partitions were updated.
2018-05-25 11:39:35,394 INFO  com.hotels.bdp.circustrain.core.PartitionedTableMetadataUpdateReplication:119 - Metadata updated for 2 partitions of table database.table. (no data copied)
2018-05-25 11:39:35,396 INFO  com.hotels.bdp.circustrain.core.PartitionedTableMetadataUpdateReplication:119 - Metadata updated for 2 partitions of table database.table. (no data copied)
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.017 sec
Running com.hotels.bdp.circustrain.core.PartitionedTableReplicationTest
2018-05-25 11:39:35,415 INFO  com.hotels.bdp.circustrain.core.PartitionedTableReplication:111 - No matching partitions found on table database.table with predicate partitionPredicate. Table metadata updated, no partitions were updated.
2018-05-25 11:39:35,419 INFO  com.hotels.bdp.circustrain.core.PartitionedTableReplication:133 - Replicated 2 partitions of table database.table.
2018-05-25 11:39:35,421 INFO  com.hotels.bdp.circustrain.core.PartitionedTableReplication:133 - Replicated 2 partitions of table database.table.
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.021 sec
Running com.hotels.bdp.circustrain.core.PartitionPredicateFactoryTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.005 sec
Running com.hotels.bdp.circustrain.core.PartitionsAndStatisticsTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running com.hotels.bdp.circustrain.core.replica.AddCheckSumReplicaTableFactoryTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.017 sec
Running com.hotels.bdp.circustrain.core.replica.FullReplicationReplicaLocationManagerTest
2018-05-25 11:39:35,459 INFO  com.hotels.bdp.circustrain.core.replica.FullReplicationReplicaLocationManager:97 - Scheduling old replica data for deletion for event eventId: path1
2018-05-25 11:39:35,459 INFO  com.hotels.bdp.circustrain.core.replica.FullReplicationReplicaLocationManager:97 - Scheduling old replica data for deletion for event eventId: path2
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.008 sec
Running com.hotels.bdp.circustrain.core.replica.MetadataMirrorReplicaLocationManagerTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.core.replica.MetadataUpdateReplicaLocationManagerTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.core.replica.ReplicaFactoryTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.core.replica.ReplicaTableFactoryProviderTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.005 sec
Running com.hotels.bdp.circustrain.core.replica.ReplicaTableFactoryTest
Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 sec
Running com.hotels.bdp.circustrain.core.replica.ReplicaTest
2018-05-25 11:39:35,569 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:35,612 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:35,649 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:35,761 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:35,796 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:35,908 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:35,944 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:35,979 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:35,979 INFO  com.hotels.bdp.circustrain.core.replica.Replica:166 - Creating 1 new partitions.
2018-05-25 11:39:35,980 INFO  com.hotels.bdp.circustrain.core.replica.Replica:180 - Altering 1 existing partitions.
2018-05-25 11:39:35,980 INFO  com.hotels.bdp.circustrain.core.replica.Replica:194 - Setting column statistics for 2 partitions.
2018-05-25 11:39:36,087 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:36,124 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
2018-05-25 11:39:36,125 INFO  com.hotels.bdp.circustrain.core.replica.Replica:166 - Creating 1 new partitions.
2018-05-25 11:39:36,125 INFO  com.hotels.bdp.circustrain.core.replica.Replica:180 - Altering 1 existing partitions.
2018-05-25 11:39:36,125 INFO  com.hotels.bdp.circustrain.core.replica.Replica:194 - Setting column statistics for 2 partitions.
2018-05-25 11:39:36,192 INFO  com.hotels.bdp.circustrain.core.replica.Replica:244 - Updating replica table metadata.
Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.713 sec
Running com.hotels.bdp.circustrain.core.ReplicationFactoryImplTest
Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.019 sec
Running com.hotels.bdp.circustrain.core.source.FilterMissingPartitionsLocationManagerTest
2018-05-25 11:39:36,234 WARN  com.hotels.bdp.circustrain.core.source.FilterMissingPartitionsLocationManager:66 - Exception while checking path, skipping path 'exceptionThrowingPath',  error {}
java.io.IOException
	at com.hotels.bdp.circustrain.core.source.FilterMissingPartitionsLocationManager.getPartitionLocations(FilterMissingPartitionsLocationManager.java:58)
	at com.hotels.bdp.circustrain.core.source.FilterMissingPartitionsLocationManagerTest.getPartitionLocationsExceptionThrowingPathIsSkipped(FilterMissingPartitionsLocationManagerTest.java:81)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.mockito.internal.runners.JUnit45AndHigherRunnerImpl.run(JUnit45AndHigherRunnerImpl.java:37)
	at org.mockito.runners.MockitoJUnitRunner.run(MockitoJUnitRunner.java:62)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:39:36,234 WARN  com.hotels.bdp.circustrain.core.source.FilterMissingPartitionsLocationManager:61 - Source path 'missingPath' does not exist skipping it for replication. WARNING: this means there is a partition in Hive that does not have a corresponding folder in source file store, check your table and data.
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.021 sec
Running com.hotels.bdp.circustrain.core.source.HdfsSnapshotLocationManagerTest
Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.581 sec
Running com.hotels.bdp.circustrain.core.source.SourceFactoryTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running com.hotels.bdp.circustrain.core.source.SourceTest
2018-05-25 11:39:37,049 INFO  com.hotels.bdp.circustrain.core.source.Source:113 - Retrieving table metadata for 'database.table'
2018-05-25 11:39:37,129 INFO  com.hotels.bdp.circustrain.core.source.Source:113 - Retrieving table metadata for 'database.table'
Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.369 sec
Running com.hotels.bdp.circustrain.core.source.ViewLocationManagerTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec
Running com.hotels.bdp.circustrain.core.SpelParsedPartitionPredicateTest
2018-05-25 11:39:37,192 INFO  com.hotels.bdp.circustrain.core.SpelParsedPartitionPredicate:43 - Parsed partitionFilter: filter2
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec
Running com.hotels.bdp.circustrain.core.transformation.CompositePartitionTransformationTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec
Running com.hotels.bdp.circustrain.core.transformation.CompositeTableTransformationTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec
Running com.hotels.bdp.circustrain.core.UnpartitionedTableMetadataMirrorReplicationTest
2018-05-25 11:39:37,195 INFO  com.hotels.bdp.circustrain.core.UnpartitionedTableMetadataMirrorReplication:74 - Metadata mirrored for table database.table (no data copied).
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running com.hotels.bdp.circustrain.core.UnpartitionedTableMetadataUpdateReplicationTest
2018-05-25 11:39:37,198 INFO  com.hotels.bdp.circustrain.core.UnpartitionedTableReplication:78 - Metadata updated for table database.table (no data copied).
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.core.UnpartitionedTableReplicationTest
2018-05-25 11:39:37,200 INFO  com.hotels.bdp.circustrain.core.UnpartitionedTableReplication:108 - Replicated table database.table.
2018-05-25 11:39:37,202 INFO  com.hotels.bdp.circustrain.core.UnpartitionedTableReplication:108 - Replicated table database.table.
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.005 sec
Running com.hotels.bdp.circustrain.core.util.MoreMapUtilsTest
Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.extension.ExtensionInitializerTest
2018-05-25 11:39:37,221 INFO  com.hotels.bdp.circustrain.extension.ExtensionInitializer:45 - Adding packageNames '[com.foo.bar]' to component scan.
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.015 sec
Running com.hotels.bdp.circustrain.extension.PropertyExtensionPackageProviderTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running com.hotels.bdp.circustrain.manifest.ManifestAttributesTest
2018-05-25 11:39:38,013 WARN  com.hotels.bdp.circustrain.manifest.ManifestAttributes:102 - Manifest not found!
2018-05-25 11:39:38,063 WARN  com.hotels.bdp.circustrain.manifest.ManifestAttributes:102 - Manifest not found!
2018-05-25 11:39:38,073 WARN  com.hotels.bdp.circustrain.manifest.ManifestAttributes:69 - Error getting manifest
java.lang.IllegalStateException
	at org.powermock.core.MockGateway.doMethodCall(MockGateway.java:124)
	at org.powermock.core.MockGateway.methodCall(MockGateway.java:185)
	at com.hotels.bdp.circustrain.manifest.ManifestAttributes.openManifestStream(ManifestAttributes.java:97)
	at com.hotels.bdp.circustrain.manifest.ManifestAttributes.<init>(ManifestAttributes.java:56)
	at com.hotels.bdp.circustrain.manifest.ManifestAttributesTest.exceptionWhileReadingManifest(ManifestAttributesTest.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.internal.runners.TestMethod.invoke(TestMethod.java:68)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.runTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:310)
	at org.junit.internal.runners.MethodRoadie$2.run(MethodRoadie.java:89)
	at org.junit.internal.runners.MethodRoadie.runBeforesThenTestThenAfters(MethodRoadie.java:97)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.executeTest(PowerMockJUnit44RunnerDelegateImpl.java:294)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit47RunnerDelegateImpl$PowerMockJUnit47MethodRunner.executeTestInSuper(PowerMockJUnit47RunnerDelegateImpl.java:127)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit47RunnerDelegateImpl$PowerMockJUnit47MethodRunner.access$100(PowerMockJUnit47RunnerDelegateImpl.java:59)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit47RunnerDelegateImpl$PowerMockJUnit47MethodRunner$LastRuleTestExecutorStatement.evaluate(PowerMockJUnit47RunnerDelegateImpl.java:148)
	at fm.last.commons.test.file.ClassDataFolder$1.evaluate(ClassDataFolder.java:46)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit47RunnerDelegateImpl$PowerMockJUnit47MethodRunner.executeTest(PowerMockJUnit47RunnerDelegateImpl.java:91)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.runBeforesThenTestThenAfters(PowerMockJUnit44RunnerDelegateImpl.java:282)
	at org.junit.internal.runners.MethodRoadie.runTest(MethodRoadie.java:87)
	at org.junit.internal.runners.MethodRoadie.run(MethodRoadie.java:50)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.invokeTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:207)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.runMethods(PowerMockJUnit44RunnerDelegateImpl.java:146)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$1.run(PowerMockJUnit44RunnerDelegateImpl.java:120)
	at org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:34)
	at org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:44)
	at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.run(PowerMockJUnit44RunnerDelegateImpl.java:122)
	at org.powermock.modules.junit4.common.internal.impl.JUnit4TestSuiteChunkerImpl.run(JUnit4TestSuiteChunkerImpl.java:106)
	at org.powermock.modules.junit4.common.internal.impl.AbstractCommonPowerMockRunner.run(AbstractCommonPowerMockRunner.java:53)
	at org.powermock.modules.junit4.PowerMockRunner.run(PowerMockRunner.java:59)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.929 sec
Running com.hotels.bdp.circustrain.validation.constraintvalidators.TunnelRouteValidatorTest
Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.009 sec
2018-05-25 11:39:38,165 INFO  org.springframework.context.annotation.AnnotationConfigApplicationContext:960 - Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@7c8537e9: startup date [Fri May 25 11:39:34 BST 2018]; root of context hierarchy
2018-05-25 11:39:38,166 INFO  org.springframework.context.annotation.AnnotationConfigApplicationContext:960 - Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@19070326: startup date [Fri May 25 11:39:34 BST 2018]; root of context hierarchy

Results :

Tests run: 292, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-core ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/circus-train-core-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-core ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-core/target/circus-train-core-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-core/11.5.1-SNAPSHOT/circus-train-core-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-core/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-core/11.5.1-SNAPSHOT/circus-train-core-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building AWS utils 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-aws ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-aws/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-aws ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-aws ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-aws ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-aws/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-aws ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-aws ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-aws ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-aws/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-aws ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 8 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-aws/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-aws ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-aws/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-aws ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 5 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-aws/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-aws ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-aws/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.aws.AWSCredentialUtilsTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.415 sec
Running com.hotels.bdp.circustrain.aws.context.AWSBeanPostProcessorTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.054 sec
Running com.hotels.bdp.circustrain.aws.HadoopAWSCredentialProviderChainTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.006 sec
Running com.hotels.bdp.circustrain.aws.JceksAWSCredentialProviderTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.35 sec
Running com.hotels.bdp.circustrain.aws.S3SchemesTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.005 sec

Results :

Tests run: 17, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-aws ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-aws/target/circus-train-aws-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-aws ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-aws/target/circus-train-aws-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-aws/11.5.1-SNAPSHOT/circus-train-aws-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-aws/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-aws/11.5.1-SNAPSHOT/circus-train-aws-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Metrics 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-metrics ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-metrics ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-metrics ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-metrics ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-metrics ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-metrics ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-metrics ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-metrics ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 9 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-metrics ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-metrics ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 8 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-metrics ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.metrics.conf.GraphiteLoaderTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.6 sec
Running com.hotels.bdp.circustrain.metrics.conf.GraphiteTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.205 sec
Running com.hotels.bdp.circustrain.metrics.conf.GraphiteValidatorIntegrationTest

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.3.8.RELEASE)

[2018-05-25 11:39:41.845] boot - 13128  INFO [main] --- ForkedBooter: Starting ForkedBooter v2.12.4 on LONC02S91UPG8WL.sea.corp.expecn.com with PID 13128 (/Users/cedwards/.m2/repository/org/apache/maven/surefire/surefire-booter/2.12.4/surefire-booter-2.12.4.jar started by cedwards in /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics)
[2018-05-25 11:39:41.846] boot - 13128  INFO [main] --- ForkedBooter: No active profile set, falling back to default profiles: default
[2018-05-25 11:39:41.866] boot - 13128  INFO [main] --- AnnotationConfigApplicationContext: Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@24ba9639: startup date [Fri May 25 11:39:41 BST 2018]; root of context hierarchy
[2018-05-25 11:39:41.954] boot - 13128  INFO [main] --- AutowiredAnnotationBeanPostProcessor: JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[2018-05-25 11:39:42.045] boot - 13128  INFO [main] --- ForkedBooter: Started ForkedBooter in 0.391 seconds (JVM running for 1.455)

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.3.8.RELEASE)

[2018-05-25 11:39:42.085] boot - 13128  INFO [main] --- ForkedBooter: Starting ForkedBooter v2.12.4 on LONC02S91UPG8WL.sea.corp.expecn.com with PID 13128 (/Users/cedwards/.m2/repository/org/apache/maven/surefire/surefire-booter/2.12.4/surefire-booter-2.12.4.jar started by cedwards in /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics)
[2018-05-25 11:39:42.086] boot - 13128  INFO [main] --- ForkedBooter: No active profile set, falling back to default profiles: default
[2018-05-25 11:39:42.088] boot - 13128  INFO [main] --- AnnotationConfigApplicationContext: Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5536379e: startup date [Fri May 25 11:39:42 BST 2018]; root of context hierarchy
[2018-05-25 11:39:42.093] boot - 13128  INFO [main] --- AutowiredAnnotationBeanPostProcessor: JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[2018-05-25 11:39:42.122] boot - 13128  INFO [main] --- ForkedBooter: Started ForkedBooter in 0.06 seconds (JVM running for 1.532)

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.3.8.RELEASE)

[2018-05-25 11:39:42.147] boot - 13128  INFO [main] --- ForkedBooter: Starting ForkedBooter v2.12.4 on LONC02S91UPG8WL.sea.corp.expecn.com with PID 13128 (/Users/cedwards/.m2/repository/org/apache/maven/surefire/surefire-booter/2.12.4/surefire-booter-2.12.4.jar started by cedwards in /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics)
[2018-05-25 11:39:42.147] boot - 13128  INFO [main] --- ForkedBooter: No active profile set, falling back to default profiles: default
[2018-05-25 11:39:42.149] boot - 13128  INFO [main] --- AnnotationConfigApplicationContext: Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@6d366c9b: startup date [Fri May 25 11:39:42 BST 2018]; root of context hierarchy
[2018-05-25 11:39:42.153] boot - 13128  INFO [main] --- AutowiredAnnotationBeanPostProcessor: JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[2018-05-25 11:39:42.178] boot - 13128  INFO [main] --- ForkedBooter: Started ForkedBooter in 0.052 seconds (JVM running for 1.588)

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.3.8.RELEASE)

[2018-05-25 11:39:42.201] boot - 13128  INFO [main] --- ForkedBooter: Starting ForkedBooter v2.12.4 on LONC02S91UPG8WL.sea.corp.expecn.com with PID 13128 (/Users/cedwards/.m2/repository/org/apache/maven/surefire/surefire-booter/2.12.4/surefire-booter-2.12.4.jar started by cedwards in /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics)
[2018-05-25 11:39:42.202] boot - 13128  INFO [main] --- ForkedBooter: No active profile set, falling back to default profiles: default
[2018-05-25 11:39:42.203] boot - 13128  INFO [main] --- AnnotationConfigApplicationContext: Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@29a60c27: startup date [Fri May 25 11:39:42 BST 2018]; root of context hierarchy
[2018-05-25 11:39:42.206] boot - 13128  INFO [main] --- AutowiredAnnotationBeanPostProcessor: JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[2018-05-25 11:39:42.229] boot - 13128  INFO [main] --- ForkedBooter: Started ForkedBooter in 0.046 seconds (JVM running for 1.638)

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.3.8.RELEASE)

[2018-05-25 11:39:42.262] boot - 13128  INFO [main] --- ForkedBooter: Starting ForkedBooter v2.12.4 on LONC02S91UPG8WL.sea.corp.expecn.com with PID 13128 (/Users/cedwards/.m2/repository/org/apache/maven/surefire/surefire-booter/2.12.4/surefire-booter-2.12.4.jar started by cedwards in /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics)
[2018-05-25 11:39:42.262] boot - 13128  INFO [main] --- ForkedBooter: No active profile set, falling back to default profiles: default
[2018-05-25 11:39:42.264] boot - 13128  INFO [main] --- AnnotationConfigApplicationContext: Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@f9b7332: startup date [Fri May 25 11:39:42 BST 2018]; root of context hierarchy
[2018-05-25 11:39:42.268] boot - 13128  INFO [main] --- AutowiredAnnotationBeanPostProcessor: JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
[2018-05-25 11:39:42.292] boot - 13128  INFO [main] --- ForkedBooter: Started ForkedBooter in 0.05 seconds (JVM running for 1.702)
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.706 sec
Running com.hotels.bdp.circustrain.metrics.conf.GraphiteValidatorTest
Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.024 sec
Running com.hotels.bdp.circustrain.metrics.conf.MetricsConfTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.011 sec
Running com.hotels.bdp.circustrain.metrics.GraphiteMetricSenderTest
[2018-05-25 11:39:42.352] boot - 13128  INFO [main] --- MetricSender: name : 2
[2018-05-25 11:39:42.353] boot - 13128  WARN [main] --- GraphiteMetricSender: Unable to report to Graphite
java.io.IOException
[2018-05-25 11:39:42.360] boot - 13128  INFO [main] --- MetricSender: name : 2
[2018-05-25 11:39:42.361] boot - 13128  WARN [main] --- GraphiteMetricSender: Error closing Graphite
java.io.IOException
[2018-05-25 11:39:42.362] boot - 13128  INFO [main] --- MetricSender: name : 2
[2018-05-25 11:39:42.362] boot - 13128  WARN [main] --- GraphiteMetricSender: Unable to report to Graphite
java.io.IOException
[2018-05-25 11:39:42.363] boot - 13128  INFO [main] --- MetricSender: name : 2
[2018-05-25 11:39:42.363] boot - 13128  WARN [main] --- GraphiteMetricSender: Unable to report to Graphite
java.io.IOException
[2018-05-25 11:39:42.364] boot - 13128  INFO [main] --- MetricSender: name : 2
[2018-05-25 11:39:42.365] boot - 13128  INFO [main] --- MetricSender: name : 2
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.024 sec
Running com.hotels.bdp.circustrain.metrics.InetSocketAddressFactoryTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec
Running com.hotels.bdp.circustrain.metrics.JobMetricsTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.103 sec
[2018-05-25 11:39:42.472] boot - 13128  INFO [Thread-4] --- AnnotationConfigApplicationContext: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@6d366c9b: startup date [Fri May 25 11:39:42 BST 2018]; root of context hierarchy
[2018-05-25 11:39:42.472] boot - 13128  INFO [Thread-2] --- AnnotationConfigApplicationContext: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@24ba9639: startup date [Fri May 25 11:39:41 BST 2018]; root of context hierarchy
[2018-05-25 11:39:42.472] boot - 13128  INFO [Thread-5] --- AnnotationConfigApplicationContext: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@29a60c27: startup date [Fri May 25 11:39:42 BST 2018]; root of context hierarchy
[2018-05-25 11:39:42.473] boot - 13128  INFO [Thread-6] --- AnnotationConfigApplicationContext: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@f9b7332: startup date [Fri May 25 11:39:42 BST 2018]; root of context hierarchy
[2018-05-25 11:39:42.473] boot - 13128  INFO [Thread-3] --- AnnotationConfigApplicationContext: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@5536379e: startup date [Fri May 25 11:39:42 BST 2018]; root of context hierarchy

Results :

Tests run: 37, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-metrics ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics/target/circus-train-metrics-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-metrics ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics/target/circus-train-metrics-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-metrics/11.5.1-SNAPSHOT/circus-train-metrics-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-metrics/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-metrics/11.5.1-SNAPSHOT/circus-train-metrics-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building DistCp Copier 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-distcp-copier ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-distcp-copier/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-distcp-copier ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-distcp-copier ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-distcp-copier ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-distcp-copier/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-distcp-copier ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-distcp-copier ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-distcp-copier ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-distcp-copier/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-distcp-copier ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 9 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-distcp-copier/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-distcp-copier ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-distcp-copier ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 6 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-distcp-copier/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-distcp-copier ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-distcp-copier/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.distcpcopier.CircusTrainCopyListingTest
2018-05-25 11:39:43,732 WARN  org.apache.hadoop.util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-25 11:39:43,957 DEBUG com.hotels.bdp.circustrain.distcpcopier.CircusTrainCopyListing:111 - Adding 'file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6015452084112897832/input/sub1/sub2' with relative path '/sub1/sub2'
2018-05-25 11:39:43,957 DEBUG com.hotels.bdp.circustrain.distcpcopier.CircusTrainCopyListing:111 - Adding 'file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6015452084112897832/input/sub1/sub2/data' with relative path '/sub1/sub2/data'
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.731 sec
Running com.hotels.bdp.circustrain.distcpcopier.DistCpCopierFactoryTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.005 sec
Running com.hotels.bdp.circustrain.distcpcopier.DistCpCopierTest
2018-05-25 11:39:44,041 INFO  com.hotels.bdp.circustrain.distcpcopier.DistCpCopier:110 - Copying table data.
2018-05-25 11:39:44,041 DEBUG com.hotels.bdp.circustrain.distcpcopier.DistCpCopier:111 - Invoking DistCp: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8032213555995959871/input/ -> file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8032213555995959871/output/
2018-05-25 11:39:44,042 DEBUG com.hotels.bdp.circustrain.distcpcopier.DistCpCopier:102 - Will copy 2 sub-paths.
2018-05-25 11:39:44,063 DEBUG com.hotels.bdp.circustrain.distcpcopier.DistCpCopier:114 - Invoking DistCp with options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=false, maxMaps=20, sslConfigurationFile='null', copyStrategy='uniformsize', sourceFileListing=null, sourcePaths=[file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8032213555995959871/input/sub1/sub2/, file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8032213555995959871/input/sub3/sub4/], targetPath=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8032213555995959871/output/, targetPathExists=true, preserveRawXattrs=false}
2018-05-25 11:39:44,108 INFO  org.apache.hadoop.metrics.jvm.JvmMetrics:76 - Initializing JVM Metrics with processName=JobTracker, sessionId=
2018-05-25 11:39:44,129 DEBUG org.apache.hadoop.tools.DistCp:412 - Meta folder location: file:/tmp/hadoop-cedwards/mapred/staging/cedwards1390000468/.staging/_distcp1468277085
2018-05-25 11:39:44,130 INFO  org.apache.hadoop.metrics.jvm.JvmMetrics:71 - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2018-05-25 11:39:44,137 DEBUG org.apache.hadoop.tools.DistCp:412 - Meta folder location: file:/tmp/hadoop-cedwards/mapred/staging/cedwards1520142086/.staging/_distcp-161493592
2018-05-25 11:39:44,150 INFO  com.hotels.bdp.circustrain.distcpcopier.DistCpCopier:110 - Copying table data.
2018-05-25 11:39:44,151 DEBUG com.hotels.bdp.circustrain.distcpcopier.DistCpCopier:111 - Invoking DistCp: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/ -> file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/
2018-05-25 11:39:44,151 DEBUG com.hotels.bdp.circustrain.distcpcopier.DistCpCopier:102 - Will copy 2 sub-paths.
2018-05-25 11:39:44,151 DEBUG com.hotels.bdp.circustrain.distcpcopier.DistCpOptionsParser:55 - Null copier options: nothing to parse
2018-05-25 11:39:44,151 DEBUG com.hotels.bdp.circustrain.distcpcopier.DistCpCopier:114 - Invoking DistCp with options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=false, maxMaps=20, sslConfigurationFile='null', copyStrategy='uniformsize', sourceFileListing=null, sourcePaths=[file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub1/sub2/, file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub3/sub4/], targetPath=file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/, targetPathExists=true, preserveRawXattrs=false}
2018-05-25 11:39:44,196 INFO  org.apache.hadoop.metrics.jvm.JvmMetrics:71 - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2018-05-25 11:39:44,210 DEBUG org.apache.hadoop.tools.DistCp:412 - Meta folder location: file:/tmp/hadoop-cedwards/mapred/staging/cedwards356072396/.staging/_distcp34055521
2018-05-25 11:39:44,212 INFO  org.apache.hadoop.metrics.jvm.JvmMetrics:71 - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2018-05-25 11:39:44,218 DEBUG org.apache.hadoop.tools.DistCp:412 - Meta folder location: file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702
2018-05-25 11:39:44,245 DEBUG com.hotels.bdp.circustrain.distcpcopier.CircusTrainCopyListing:111 - Adding 'file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub1/sub2' with relative path '/sub1/sub2'
2018-05-25 11:39:44,246 DEBUG com.hotels.bdp.circustrain.distcpcopier.CircusTrainCopyListing:111 - Adding 'file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub1/sub2/data' with relative path '/sub1/sub2/data'
2018-05-25 11:39:44,264 DEBUG com.hotels.bdp.circustrain.distcpcopier.CircusTrainCopyListing:111 - Adding 'file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub3/sub4' with relative path '/sub3/sub4'
2018-05-25 11:39:44,264 DEBUG com.hotels.bdp.circustrain.distcpcopier.CircusTrainCopyListing:111 - Adding 'file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub3/sub4/data' with relative path '/sub3/sub4/data'
2018-05-25 11:39:44,267 INFO  org.apache.hadoop.conf.Configuration.deprecation:1173 - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2018-05-25 11:39:44,267 INFO  org.apache.hadoop.conf.Configuration.deprecation:1173 - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2018-05-25 11:39:44,294 INFO  org.apache.hadoop.metrics.jvm.JvmMetrics:71 - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2018-05-25 11:39:44,496 WARN  org.apache.hadoop.mapreduce.JobResourceUploader:64 - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-05-25 11:39:44,636 DEBUG org.apache.hadoop.tools.mapred.UniformSizeInputFormat:89 - Average bytes per map: 0, Number of maps: 1, total size: 0
2018-05-25 11:39:44,640 DEBUG org.apache.hadoop.tools.mapred.UniformSizeInputFormat:102 - Creating split : file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/fileList.seq:0+275, bytes in split: 102
2018-05-25 11:39:44,640 DEBUG org.apache.hadoop.tools.mapred.UniformSizeInputFormat:102 - Creating split : file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/fileList.seq:275+207, bytes in split: 5
2018-05-25 11:39:44,641 DEBUG org.apache.hadoop.tools.mapred.UniformSizeInputFormat:102 - Creating split : file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/fileList.seq:482+197, bytes in split: 102
2018-05-25 11:39:44,641 INFO  org.apache.hadoop.tools.mapred.UniformSizeInputFormat:115 - Creating split : file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/fileList.seq:679+207, bytes in split: 5
2018-05-25 11:39:44,699 INFO  org.apache.hadoop.mapreduce.JobSubmitter:198 - number of splits:4
2018-05-25 11:39:44,816 INFO  org.apache.hadoop.mapreduce.JobSubmitter:287 - Submitting tokens for job: job_local376365827_0001
2018-05-25 11:39:44,974 INFO  org.apache.hadoop.mapreduce.Job:1294 - The url to track the job: http://localhost:8080/
2018-05-25 11:39:44,975 INFO  org.apache.hadoop.tools.DistCp:193 - DistCp job-id: job_local376365827_0001
2018-05-25 11:39:44,976 INFO  org.apache.hadoop.mapred.LocalJobRunner:471 - OutputCommitter set in config null
2018-05-25 11:39:44,979 INFO  org.apache.hadoop.mapreduce.Job:1339 - Running job: job_local376365827_0001
2018-05-25 11:39:44,980 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2018-05-25 11:39:44,982 INFO  org.apache.hadoop.mapred.LocalJobRunner:489 - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2018-05-25 11:39:45,005 INFO  org.apache.hadoop.mapred.LocalJobRunner:224 - Starting task: attempt_local376365827_0001_m_000000_0
2018-05-25 11:39:45,005 INFO  org.apache.hadoop.mapred.LocalJobRunner:448 - Waiting for map tasks
2018-05-25 11:39:45,026 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2018-05-25 11:39:45,033 INFO  org.apache.hadoop.yarn.util.ProcfsBasedProcessTree:192 - ProcfsBasedProcessTree currently is supported only on Linux.
2018-05-25 11:39:45,033 INFO  org.apache.hadoop.mapred.Task:612 -  Using ResourceCalculatorProcessTree : null
2018-05-25 11:39:45,035 INFO  org.apache.hadoop.mapred.MapTask:756 - Processing split: file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/fileList.seq:0+275
2018-05-25 11:39:45,042 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2018-05-25 11:39:45,058 DEBUG org.apache.hadoop.tools.mapred.CopyMapper:197 - DistCpMapper::map(): Received file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub1/sub2, /sub1/sub2
2018-05-25 11:39:45,059 INFO  org.apache.hadoop.tools.mapred.CopyMapper:210 - Copying file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub1/sub2 to file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub1/sub2
2018-05-25 11:39:45,066 DEBUG org.apache.hadoop.tools.mapred.CopyMapper:233 - Path could not be found: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub1/sub2
java.io.FileNotFoundException: File file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub1/sub2 does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:606)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:819)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:596)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:230)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:50)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-05-25 11:39:45,075 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - 
2018-05-25 11:39:45,076 INFO  org.apache.hadoop.mapred.Task:1038 - Task:attempt_local376365827_0001_m_000000_0 is done. And is in the process of committing
2018-05-25 11:39:45,080 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - 
2018-05-25 11:39:45,081 INFO  org.apache.hadoop.mapred.Task:1199 - Task attempt_local376365827_0001_m_000000_0 is allowed to commit now
2018-05-25 11:39:45,082 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:482 - Saved output of task 'attempt_local376365827_0001_m_000000_0' to file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/_logs/_temporary/0/task_local376365827_0001_m_000000
2018-05-25 11:39:45,082 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - Copying file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub1/sub2 to file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub1/sub2
2018-05-25 11:39:45,082 INFO  org.apache.hadoop.mapred.Task:1158 - Task 'attempt_local376365827_0001_m_000000_0' done.
2018-05-25 11:39:45,082 INFO  org.apache.hadoop.mapred.LocalJobRunner:249 - Finishing task: attempt_local376365827_0001_m_000000_0
2018-05-25 11:39:45,083 INFO  org.apache.hadoop.mapred.LocalJobRunner:224 - Starting task: attempt_local376365827_0001_m_000001_0
2018-05-25 11:39:45,083 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2018-05-25 11:39:45,084 INFO  org.apache.hadoop.yarn.util.ProcfsBasedProcessTree:192 - ProcfsBasedProcessTree currently is supported only on Linux.
2018-05-25 11:39:45,084 INFO  org.apache.hadoop.mapred.Task:612 -  Using ResourceCalculatorProcessTree : null
2018-05-25 11:39:45,085 INFO  org.apache.hadoop.mapred.MapTask:756 - Processing split: file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/fileList.seq:275+207
2018-05-25 11:39:45,085 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2018-05-25 11:39:45,096 DEBUG org.apache.hadoop.tools.mapred.CopyMapper:197 - DistCpMapper::map(): Received file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub1/sub2/data, /sub1/sub2/data
2018-05-25 11:39:45,096 INFO  org.apache.hadoop.tools.mapred.CopyMapper:210 - Copying file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub1/sub2/data to file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub1/sub2/data
2018-05-25 11:39:45,102 DEBUG org.apache.hadoop.tools.mapred.CopyMapper:233 - Path could not be found: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub1/sub2/data
java.io.FileNotFoundException: File file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub1/sub2/data does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:606)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:819)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:596)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:230)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:50)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-05-25 11:39:45,104 INFO  org.apache.hadoop.tools.mapred.RetriableFileCopyCommand:232 - Creating temp file: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/.distcp.tmp.attempt_local376365827_0001_m_000001_0
2018-05-25 11:39:45,105 DEBUG org.apache.hadoop.tools.mapred.RetriableFileCopyCommand:112 - Copying file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub1/sub2/data to file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub1/sub2/data
2018-05-25 11:39:45,105 DEBUG org.apache.hadoop.tools.mapred.RetriableFileCopyCommand:113 - Target file path: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/.distcp.tmp.attempt_local376365827_0001_m_000001_0
2018-05-25 11:39:45,119 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - 
2018-05-25 11:39:45,120 INFO  org.apache.hadoop.mapred.Task:1038 - Task:attempt_local376365827_0001_m_000001_0 is done. And is in the process of committing
2018-05-25 11:39:45,120 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - 
2018-05-25 11:39:45,121 INFO  org.apache.hadoop.mapred.Task:1199 - Task attempt_local376365827_0001_m_000001_0 is allowed to commit now
2018-05-25 11:39:45,121 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:482 - Saved output of task 'attempt_local376365827_0001_m_000001_0' to file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/_logs/_temporary/0/task_local376365827_0001_m_000001
2018-05-25 11:39:45,122 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - 100.0% Copying file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub1/sub2/data to file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub1/sub2/data [5.0B/5.0B]
2018-05-25 11:39:45,122 INFO  org.apache.hadoop.mapred.Task:1158 - Task 'attempt_local376365827_0001_m_000001_0' done.
2018-05-25 11:39:45,122 INFO  org.apache.hadoop.mapred.LocalJobRunner:249 - Finishing task: attempt_local376365827_0001_m_000001_0
2018-05-25 11:39:45,122 INFO  org.apache.hadoop.mapred.LocalJobRunner:224 - Starting task: attempt_local376365827_0001_m_000002_0
2018-05-25 11:39:45,123 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2018-05-25 11:39:45,123 INFO  org.apache.hadoop.yarn.util.ProcfsBasedProcessTree:192 - ProcfsBasedProcessTree currently is supported only on Linux.
2018-05-25 11:39:45,123 INFO  org.apache.hadoop.mapred.Task:612 -  Using ResourceCalculatorProcessTree : null
2018-05-25 11:39:45,124 INFO  org.apache.hadoop.mapred.MapTask:756 - Processing split: file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/fileList.seq:679+207
2018-05-25 11:39:45,125 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2018-05-25 11:39:45,135 DEBUG org.apache.hadoop.tools.mapred.CopyMapper:197 - DistCpMapper::map(): Received file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub3/sub4/data, /sub3/sub4/data
2018-05-25 11:39:45,135 INFO  org.apache.hadoop.tools.mapred.CopyMapper:210 - Copying file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub3/sub4/data to file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub3/sub4/data
2018-05-25 11:39:45,141 DEBUG org.apache.hadoop.tools.mapred.CopyMapper:233 - Path could not be found: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub3/sub4/data
java.io.FileNotFoundException: File file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub3/sub4/data does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:606)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:819)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:596)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:230)
	at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:50)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2018-05-25 11:39:45,142 INFO  org.apache.hadoop.tools.mapred.RetriableFileCopyCommand:232 - Creating temp file: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/.distcp.tmp.attempt_local376365827_0001_m_000002_0
2018-05-25 11:39:45,142 DEBUG org.apache.hadoop.tools.mapred.RetriableFileCopyCommand:112 - Copying file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub3/sub4/data to file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub3/sub4/data
2018-05-25 11:39:45,142 DEBUG org.apache.hadoop.tools.mapred.RetriableFileCopyCommand:113 - Target file path: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/.distcp.tmp.attempt_local376365827_0001_m_000002_0
2018-05-25 11:39:45,154 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - 
2018-05-25 11:39:45,154 INFO  org.apache.hadoop.mapred.Task:1038 - Task:attempt_local376365827_0001_m_000002_0 is done. And is in the process of committing
2018-05-25 11:39:45,155 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - 
2018-05-25 11:39:45,155 INFO  org.apache.hadoop.mapred.Task:1199 - Task attempt_local376365827_0001_m_000002_0 is allowed to commit now
2018-05-25 11:39:45,156 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:482 - Saved output of task 'attempt_local376365827_0001_m_000002_0' to file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/_logs/_temporary/0/task_local376365827_0001_m_000002
2018-05-25 11:39:45,156 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - 100.0% Copying file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub3/sub4/data to file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub3/sub4/data [5.0B/5.0B]
2018-05-25 11:39:45,156 INFO  org.apache.hadoop.mapred.Task:1158 - Task 'attempt_local376365827_0001_m_000002_0' done.
2018-05-25 11:39:45,157 INFO  org.apache.hadoop.mapred.LocalJobRunner:249 - Finishing task: attempt_local376365827_0001_m_000002_0
2018-05-25 11:39:45,157 INFO  org.apache.hadoop.mapred.LocalJobRunner:224 - Starting task: attempt_local376365827_0001_m_000003_0
2018-05-25 11:39:45,157 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2018-05-25 11:39:45,158 INFO  org.apache.hadoop.yarn.util.ProcfsBasedProcessTree:192 - ProcfsBasedProcessTree currently is supported only on Linux.
2018-05-25 11:39:45,158 INFO  org.apache.hadoop.mapred.Task:612 -  Using ResourceCalculatorProcessTree : null
2018-05-25 11:39:45,159 INFO  org.apache.hadoop.mapred.MapTask:756 - Processing split: file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/fileList.seq:482+197
2018-05-25 11:39:45,159 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:100 - File Output Committer Algorithm version is 1
2018-05-25 11:39:45,169 DEBUG org.apache.hadoop.tools.mapred.CopyMapper:197 - DistCpMapper::map(): Received file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub3/sub4, /sub3/sub4
2018-05-25 11:39:45,169 INFO  org.apache.hadoop.tools.mapred.CopyMapper:210 - Copying file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub3/sub4 to file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub3/sub4
2018-05-25 11:39:45,176 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - 
2018-05-25 11:39:45,176 INFO  org.apache.hadoop.mapred.Task:1038 - Task:attempt_local376365827_0001_m_000003_0 is done. And is in the process of committing
2018-05-25 11:39:45,177 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - 
2018-05-25 11:39:45,177 INFO  org.apache.hadoop.mapred.Task:1199 - Task attempt_local376365827_0001_m_000003_0 is allowed to commit now
2018-05-25 11:39:45,178 INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter:482 - Saved output of task 'attempt_local376365827_0001_m_000003_0' to file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702/_logs/_temporary/0/task_local376365827_0001_m_000003
2018-05-25 11:39:45,178 INFO  org.apache.hadoop.mapred.LocalJobRunner:591 - Copying file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/input/sub3/sub4 to file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3873899550929710661/output/sub3/sub4
2018-05-25 11:39:45,178 INFO  org.apache.hadoop.mapred.Task:1158 - Task 'attempt_local376365827_0001_m_000003_0' done.
2018-05-25 11:39:45,178 INFO  org.apache.hadoop.mapred.LocalJobRunner:249 - Finishing task: attempt_local376365827_0001_m_000003_0
2018-05-25 11:39:45,178 INFO  org.apache.hadoop.mapred.LocalJobRunner:456 - map task executor complete.
2018-05-25 11:39:45,196 INFO  org.apache.hadoop.tools.mapred.CopyCommitter:156 - Cleaning up temporary work folder: file:/tmp/hadoop-cedwards/mapred/staging/cedwards175576675/.staging/_distcp-695247702
2018-05-25 11:39:45,983 INFO  org.apache.hadoop.mapreduce.Job:1360 - Job job_local376365827_0001 running in uber mode : false
2018-05-25 11:39:45,984 INFO  org.apache.hadoop.mapreduce.Job:1367 -  map 100% reduce 0%
2018-05-25 11:39:45,987 INFO  org.apache.hadoop.mapreduce.Job:1378 - Job job_local376365827_0001 completed successfully
2018-05-25 11:39:45,997 INFO  org.apache.hadoop.mapreduce.Job:1385 - Counters: 18
	File System Counters
		FILE: Number of bytes read=440771
		FILE: Number of bytes written=1291465
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=652
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1298137088
	File Input Format Counters 
		Bytes Read=3688
	File Output Format Counters 
		Bytes Written=32
	org.apache.hadoop.tools.mapred.CopyMapper$Counter
		BYTESCOPIED=10
		BYTESEXPECTED=10
		COPY=4
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.969 sec
Running com.hotels.bdp.circustrain.distcpcopier.DistCpOptionsParserTest
2018-05-25 11:39:46,013 DEBUG com.hotels.bdp.circustrain.distcpcopier.DistCpOptionsParser:55 - Null copier options: nothing to parse
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.005 sec
Running com.hotels.bdp.circustrain.distcpcopier.FileStatusTreeTraverserTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.198 sec
Running com.hotels.bdp.circustrain.distcpcopier.RelativePathFunctionTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec

Results :

Tests run: 26, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-distcp-copier ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-distcp-copier/target/circus-train-distcp-copier-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-distcp-copier ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-distcp-copier/target/circus-train-distcp-copier-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-distcp-copier/11.5.1-SNAPSHOT/circus-train-distcp-copier-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-distcp-copier/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-distcp-copier/11.5.1-SNAPSHOT/circus-train-distcp-copier-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Google Cloud Platform Utils 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-gcp ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-gcp ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-gcp ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-gcp ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-gcp ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-gcp ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-gcp ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-gcp ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 6 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[WARNING] /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/src/main/java/com/hotels/bdp/circustrain/gcp/GCPCredentialCopier.java:[28,35] org.apache.hadoop.filecache.DistributedCache in org.apache.hadoop.filecache has been deprecated
[WARNING] /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/src/main/java/com/hotels/bdp/circustrain/gcp/GCPCredentialCopier.java:[87,5] org.apache.hadoop.filecache.DistributedCache in org.apache.hadoop.filecache has been deprecated
[WARNING] /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/src/main/java/com/hotels/bdp/circustrain/gcp/GCPCredentialCopier.java:[87,21] addCacheFile(java.net.URI,org.apache.hadoop.conf.Configuration) in org.apache.hadoop.mapreduce.filecache.DistributedCache has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-gcp ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-gcp ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 4 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/src/test/java/com/hotels/bdp/circustrain/gcp/GCPCredentialConfigurerTest.java: /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/src/test/java/com/hotels/bdp/circustrain/gcp/GCPCredentialConfigurerTest.java uses unchecked or unsafe operations.
[INFO] /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/src/test/java/com/hotels/bdp/circustrain/gcp/GCPCredentialConfigurerTest.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-gcp ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.gcp.BindGoogleHadoopFileSystemTest
2018-05-25 11:39:47,114 DEBUG com.hotels.bdp.circustrain.gcp.BindGoogleHadoopFileSystem:46 - Binding GoogleHadoopFileSystem
2018-05-25 11:39:47,170 DEBUG com.hotels.bdp.circustrain.core.util.LibJarDeployer:61 - Found libjar for 'class com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem' at 'file:/Users/cedwards/.m2/repository/com/google/cloud/bigdataoss/gcs-connector/1.6.3-hadoop2/gcs-connector-1.6.3-hadoop2.jar'
2018-05-25 11:39:47,170 DEBUG com.hotels.bdp.circustrain.core.util.LibJarDeployer:61 - Found libjar for 'class com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS' at 'file:/Users/cedwards/.m2/repository/com/google/cloud/bigdataoss/gcs-connector/1.6.3-hadoop2/gcs-connector-1.6.3-hadoop2.jar'
2018-05-25 11:39:47,337 WARN  org.apache.hadoop.util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-25 11:39:47,450 INFO  com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.578 sec
Running com.hotels.bdp.circustrain.gcp.context.GCPBeanPostProcessorTest
2018-05-25 11:39:47,667 DEBUG com.hotels.bdp.circustrain.gcp.context.GCPBeanPostProcessor:60 - Configuring google hadoop connector
2018-05-25 11:39:47,708 DEBUG com.hotels.bdp.circustrain.gcp.context.GCPBeanPostProcessor:60 - Configuring google hadoop connector
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.205 sec
Running com.hotels.bdp.circustrain.gcp.GCPCredentialConfigurerTest
2018-05-25 11:39:49,110 DEBUG com.hotels.bdp.circustrain.gcp.GCPCredentialConfigurer:41 - Configuring GCP Credentials
2018-05-25 11:39:49,118 DEBUG com.hotels.bdp.circustrain.gcp.GCPCredentialCopier:71 - Copying credential into working directory /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/ct-gcp-key-03b0cbfc-fc19-40bc-a24f-f33aa961bd331527244789113.json
2018-05-25 11:39:49,187 DEBUG com.hotels.bdp.circustrain.gcp.GCPCredentialCopier:80 - Copying credential into HDFS hdfs:/tmp/ct-gcp-03b0cbfc-fc19-40bc-a24f-f33aa961bd331527244789113/ct-gcp-key-03b0cbfc-fc19-40bc-a24f-f33aa961bd331527244789113.json
2018-05-25 11:39:49,187 DEBUG com.hotels.bdp.circustrain.gcp.GCPCredentialCopier:85 - hdfs:///tmp/ct-gcp-03b0cbfc-fc19-40bc-a24f-f33aa961bd331527244789113 added to distributed cache with symlink ./ct-gcp-key-03b0cbfc-fc19-40bc-a24f-f33aa961bd331527244789113.json
2018-05-25 11:39:49,281 DEBUG com.hotels.bdp.circustrain.gcp.GCPCredentialConfigurer:41 - Configuring GCP Credentials
2018-05-25 11:39:49,293 DEBUG com.hotels.bdp.circustrain.gcp.GCPCredentialConfigurer:41 - Configuring GCP Credentials
2018-05-25 11:39:49,294 DEBUG com.hotels.bdp.circustrain.gcp.GCPCredentialCopier:71 - Copying credential into working directory /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/ct-gcp-key-03b0cbfc-fc19-40bc-a24f-f33aa961bd331527244789113.json
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.576 sec
Running com.hotels.bdp.circustrain.gcp.GCPCredentialCopierTest
2018-05-25 11:39:50,248 DEBUG com.hotels.bdp.circustrain.gcp.GCPCredentialCopier:71 - Copying credential into working directory /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/ct-gcp-key-ca0edbee-8525-4f24-9588-7c397d38d45c1527244790245.json
2018-05-25 11:39:50,261 DEBUG com.hotels.bdp.circustrain.gcp.GCPCredentialCopier:80 - Copying credential into HDFS hdfs:/tmp/ct-gcp-ca0edbee-8525-4f24-9588-7c397d38d45c1527244790245/ct-gcp-key-ca0edbee-8525-4f24-9588-7c397d38d45c1527244790245.json
2018-05-25 11:39:50,263 DEBUG com.hotels.bdp.circustrain.gcp.GCPCredentialCopier:85 - hdfs:///tmp/ct-gcp-ca0edbee-8525-4f24-9588-7c397d38d45c1527244790245 added to distributed cache with symlink ./ct-gcp-key-ca0edbee-8525-4f24-9588-7c397d38d45c1527244790245.json
2018-05-25 11:39:50,329 DEBUG com.hotels.bdp.circustrain.gcp.GCPCredentialCopier:71 - Copying credential into working directory /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/ct-gcp-key-ca0edbee-8525-4f24-9588-7c397d38d45c1527244790245.json
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.033 sec

Results :

Tests run: 10, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-gcp ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/target/circus-train-gcp-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-gcp ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/target/circus-train-gcp-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-gcp/11.5.1-SNAPSHOT/circus-train-gcp-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-gcp/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-gcp/11.5.1-SNAPSHOT/circus-train-gcp-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Common Test Classes 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-common-test ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-common-test/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-common-test ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-common-test ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-common-test ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-common-test/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-common-test ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-common-test ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-common-test ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-common-test ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 4 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-common-test/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[WARNING] /Users/cedwards/Documents/workspace/circus-train/circus-train-common-test/src/main/java/com/hotels/bdp/circustrain/common/test/junit/rules/ServerSocketRule.java:[48,57] sameThreadExecutor() in com.google.common.util.concurrent.MoreExecutors has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-common-test ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-common-test/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-common-test ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 1 source file to /Users/cedwards/Documents/workspace/circus-train/circus-train-common-test/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-common-test ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-common-test/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.common.test.junit.rules.ServerSocketRuleTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.474 sec

Results :

Tests run: 5, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-common-test ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-common-test/target/circus-train-common-test-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-common-test ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-common-test/target/circus-train-common-test-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-common-test/11.5.1-SNAPSHOT/circus-train-common-test-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-common-test/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-common-test/11.5.1-SNAPSHOT/circus-train-common-test-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building S3 MapReduce Copy 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-s3-mapreduce-cp ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-s3-mapreduce-cp ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-s3-mapreduce-cp ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-s3-mapreduce-cp ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-s3-mapreduce-cp ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-s3-mapreduce-cp ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-s3-mapreduce-cp ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-s3-mapreduce-cp ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 35 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[WARNING] /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/src/main/java/com/hotels/bdp/circustrain/s3mapreducecp/mapreduce/lib/DynamicInputChunk.java:[89,26] createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile.CompressionType) in org.apache.hadoop.io.SequenceFile has been deprecated
[INFO] /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/src/main/java/com/hotels/bdp/circustrain/s3mapreducecp/mapreduce/lib/DynamicRecordReader.java: /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/src/main/java/com/hotels/bdp/circustrain/s3mapreducecp/mapreduce/lib/DynamicRecordReader.java uses unchecked or unsafe operations.
[INFO] /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/src/main/java/com/hotels/bdp/circustrain/s3mapreducecp/mapreduce/lib/DynamicRecordReader.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-s3-mapreduce-cp ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-s3-mapreduce-cp ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 23 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-s3-mapreduce-cp ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.s3mapreducecp.aws.AwsS3ClientFactoryTest
2018-05-25 11:39:56,649 INFO  com.hotels.bdp.circustrain.s3mapreducecp.aws.AwsS3ClientFactory:57 - Creating AWS S3 client with a retry policy of 7 retries and 333 ms of exponential backoff delay
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.028 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.aws.AwsUtilTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.aws.CounterBasedRetryConditionTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.134 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.aws.ExponentialBackoffStrategyTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest
2018-05-25 11:39:57,493 ERROR com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand:89 - Failure in Retriable command: MyRetriableCommand
java.lang.Exception: Transient failure#1
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest$MyRetriableCommand.doExecute(RetriableCommandTest.java:49)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand.execute(RetriableCommand.java:87)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest.typical(RetriableCommandTest.java:58)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:39:59,836 ERROR com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand:89 - Failure in Retriable command: MyRetriableCommand
java.lang.Exception: Transient failure#2
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest$MyRetriableCommand.doExecute(RetriableCommandTest.java:49)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand.execute(RetriableCommand.java:87)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest.typical(RetriableCommandTest.java:58)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:40:02,839 ERROR com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand:89 - Failure in Retriable command: MyRetriableCommand
java.lang.Exception: Transient failure#3
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest$MyRetriableCommand.doExecute(RetriableCommandTest.java:49)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand.execute(RetriableCommand.java:87)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest.typical(RetriableCommandTest.java:58)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:40:02,840 ERROR com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand:89 - Failure in Retriable command: MyRetriableCommand
java.lang.Exception: Transient failure#1
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest$MyRetriableCommand.doExecute(RetriableCommandTest.java:49)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand.execute(RetriableCommand.java:87)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest.typical(RetriableCommandTest.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:40:05,239 ERROR com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand:89 - Failure in Retriable command: MyRetriableCommand
java.lang.Exception: Transient failure#2
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest$MyRetriableCommand.doExecute(RetriableCommandTest.java:49)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand.execute(RetriableCommand.java:87)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest.typical(RetriableCommandTest.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:40:10,480 ERROR com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand:89 - Failure in Retriable command: MyRetriableCommand
java.lang.Exception: Transient failure#1
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest$MyRetriableCommand.doExecute(RetriableCommandTest.java:49)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand.execute(RetriableCommand.java:87)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest.typical(RetriableCommandTest.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:40:10,482 ERROR com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand:89 - Failure in Retriable command: MyRetriableCommand
java.lang.Exception: Transient failure#2
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest$MyRetriableCommand.doExecute(RetriableCommandTest.java:49)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand.execute(RetriableCommand.java:87)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest.typical(RetriableCommandTest.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:40:10,482 ERROR com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand:89 - Failure in Retriable command: MyRetriableCommand
java.lang.Exception: Transient failure#3
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest$MyRetriableCommand.doExecute(RetriableCommandTest.java:49)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand.execute(RetriableCommand.java:87)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest.typical(RetriableCommandTest.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-05-25 11:40:10,483 ERROR com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand:89 - Failure in Retriable command: MyRetriableCommand
java.lang.Exception: Transient failure#4
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest$MyRetriableCommand.doExecute(RetriableCommandTest.java:49)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommand.execute(RetriableCommand.java:87)
	at com.hotels.bdp.circustrain.s3mapreducecp.command.RetriableCommandTest.typical(RetriableCommandTest.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.995 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.CopyListingTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.028 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.io.BytesFormatterTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.io.ThrottledInputStreamTest
2018-05-25 11:40:10,535 INFO  com.hotels.bdp.circustrain.s3mapreducecp.io.ThrottledInputStreamTest:103 - ThrottledInputStream{bytesRead=1048576, maxBytesPerSec=9223372036854775807, bytesPerSec=1048576, totalSleepTime=0}
2018-05-25 11:40:30,567 INFO  com.hotels.bdp.circustrain.s3mapreducecp.io.ThrottledInputStreamTest:103 - ThrottledInputStream{bytesRead=1048576, maxBytesPerSec=52428, bytesPerSec=52428, totalSleepTime=18700}
2018-05-25 11:40:50,621 INFO  com.hotels.bdp.circustrain.s3mapreducecp.io.ThrottledInputStreamTest:103 - ThrottledInputStream{bytesRead=1048576, maxBytesPerSec=52428, bytesPerSec=52428, totalSleepTime=18700}
2018-05-25 11:41:10,843 INFO  com.hotels.bdp.circustrain.s3mapreducecp.io.ThrottledInputStreamTest:103 - ThrottledInputStream{bytesRead=1048576, maxBytesPerSec=52428, bytesPerSec=52428, totalSleepTime=14850}
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 60.326 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.jcommander.PathConverterTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.jcommander.PositiveLongTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.jcommander.PositiveNonZeroIntegerTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.jcommander.PositiveNonZeroLongTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.jcommander.RegionValidatorTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.jcommander.StorageClassValidatorTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormatTest
2018-05-25 11:41:10,898 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:446 - starting cluster: numNameNodes=1, numDataNodes=1
2018-05-25 11:41:11,209 WARN  org.apache.hadoop.util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Formatting using clusterid: testClusterID
2018-05-25 11:41:11,714 WARN  org.apache.hadoop.metrics2.impl.MetricsConfig:125 - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2018-05-25 11:41:11,828 WARN  org.apache.hadoop.http.HttpRequestLog:100 - Jetty request log can only be enabled using Log4j
2018-05-25 11:41:11,833 INFO  org.apache.hadoop.http.HttpServer2:710 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-05-25 11:41:11,834 INFO  org.apache.hadoop.http.HttpServer2:685 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2018-05-25 11:41:11,834 INFO  org.apache.hadoop.http.HttpServer2:693 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-05-25 11:41:11,851 INFO  org.apache.hadoop.http.HttpServer2:86 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2018-05-25 11:41:11,854 INFO  org.apache.hadoop.http.HttpServer2:609 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2018-05-25 11:41:11,880 INFO  org.apache.hadoop.http.HttpServer2:915 - Jetty bound to port 58259
2018-05-25 11:41:12,484 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:1413 - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/minicluster/test/data/dfs/data/data1,[DISK]file:/Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/minicluster/test/data/dfs/data/data2
2018-05-25 11:41:12,584 WARN  org.apache.hadoop.http.HttpRequestLog:100 - Jetty request log can only be enabled using Log4j
2018-05-25 11:41:12,584 INFO  org.apache.hadoop.http.HttpServer2:710 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-05-25 11:41:12,585 INFO  org.apache.hadoop.http.HttpServer2:685 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2018-05-25 11:41:12,586 INFO  org.apache.hadoop.http.HttpServer2:693 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-05-25 11:41:12,589 INFO  org.apache.hadoop.http.HttpServer2:915 - Jetty bound to port 58262
2018-05-25 11:41:13,354 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:2303 - dnInfo.length != numDataNodes
2018-05-25 11:41:13,355 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:2255 - Waiting for cluster to become active
2018-05-25 11:41:13,460 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:2303 - dnInfo.length != numDataNodes
2018-05-25 11:41:13,460 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:2255 - Waiting for cluster to become active
2018-05-25 11:41:13,569 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:2286 - Cluster is active
2018-05-25 11:41:16,248 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:298 - nMaps == 1. Why use DynamicInputFormat?
2018-05-25 11:41:16,532 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:243 - distcp.dynamic.max.chunks.ideal should be positive. Fall back to default value: 100
2018-05-25 11:41:16,533 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:254 - distcp.dynamic.min.records_per_chunk should be positive. Fall back to default value: 5
2018-05-25 11:41:16,533 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:266 - distcp.dynamic.split.ratio should be positive. Fall back to default value: 2
2018-05-25 11:41:16,533 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:298 - nMaps == 1. Why use DynamicInputFormat?
2018-05-25 11:41:16,533 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:243 - distcp.dynamic.max.chunks.ideal should be positive. Fall back to default value: 100
2018-05-25 11:41:16,534 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:254 - distcp.dynamic.min.records_per_chunk should be positive. Fall back to default value: 5
2018-05-25 11:41:16,534 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:266 - distcp.dynamic.split.ratio should be positive. Fall back to default value: 2
2018-05-25 11:41:16,534 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:243 - distcp.dynamic.max.chunks.ideal should be positive. Fall back to default value: 100
2018-05-25 11:41:16,534 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:254 - distcp.dynamic.min.records_per_chunk should be positive. Fall back to default value: 5
2018-05-25 11:41:16,535 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:266 - distcp.dynamic.split.ratio should be positive. Fall back to default value: 2
2018-05-25 11:41:16,535 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:243 - distcp.dynamic.max.chunks.ideal should be positive. Fall back to default value: 100
2018-05-25 11:41:16,535 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:254 - distcp.dynamic.min.records_per_chunk should be positive. Fall back to default value: 5
2018-05-25 11:41:16,535 WARN  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:266 - distcp.dynamic.split.ratio should be positive. Fall back to default value: 2
2018-05-25 11:41:16,593 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:446 - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2018-05-25 11:41:16,716 WARN  org.apache.hadoop.http.HttpRequestLog:100 - Jetty request log can only be enabled using Log4j
2018-05-25 11:41:16,717 INFO  org.apache.hadoop.http.HttpServer2:710 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-05-25 11:41:16,717 INFO  org.apache.hadoop.http.HttpServer2:685 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2018-05-25 11:41:16,718 INFO  org.apache.hadoop.http.HttpServer2:693 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-05-25 11:41:16,718 INFO  org.apache.hadoop.http.HttpServer2:86 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2018-05-25 11:41:16,719 INFO  org.apache.hadoop.http.HttpServer2:609 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2018-05-25 11:41:16,723 INFO  org.apache.hadoop.http.HttpServer2:915 - Jetty bound to port 58267
2018-05-25 11:41:17,073 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:1413 - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/minicluster/test/data/dfs/data/data1,[DISK]file:/Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/minicluster/test/data/dfs/data/data2
2018-05-25 11:41:17,147 WARN  org.apache.hadoop.http.HttpRequestLog:100 - Jetty request log can only be enabled using Log4j
2018-05-25 11:41:17,148 INFO  org.apache.hadoop.http.HttpServer2:710 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-05-25 11:41:17,149 INFO  org.apache.hadoop.http.HttpServer2:685 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2018-05-25 11:41:17,150 INFO  org.apache.hadoop.http.HttpServer2:693 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-05-25 11:41:17,151 INFO  org.apache.hadoop.http.HttpServer2:915 - Jetty bound to port 58270
2018-05-25 11:41:17,299 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:2303 - dnInfo.length != numDataNodes
2018-05-25 11:41:17,299 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:2255 - Waiting for cluster to become active
2018-05-25 11:41:17,404 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:2303 - dnInfo.length != numDataNodes
2018-05-25 11:41:17,405 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:2255 - Waiting for cluster to become active
2018-05-25 11:41:17,511 INFO  org.apache.hadoop.hdfs.MiniDFSCluster:2286 - Cluster is active
2018-05-25 11:41:19,738 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/source
2018-05-25 11:41:20,701 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:73 - DynamicInputFormat: Getting splits for job: job__0000
2018-05-25 11:41:46,852 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputFormat:154 - Number of dynamic-chunk-files created: 100
2018-05-25 11:41:46,879 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:186 - Acquiring pre-assigned chunk: hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/task__0000_m_000000
2018-05-25 11:41:46,900 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00007
2018-05-25 11:41:46,909 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00008
2018-05-25 11:41:46,918 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00009
2018-05-25 11:41:46,926 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00010
2018-05-25 11:41:46,933 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00011
2018-05-25 11:41:46,941 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00012
2018-05-25 11:41:46,949 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00013
2018-05-25 11:41:46,957 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00014
2018-05-25 11:41:46,965 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00015
2018-05-25 11:41:46,972 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00016
2018-05-25 11:41:46,979 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00017
2018-05-25 11:41:46,987 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00018
2018-05-25 11:41:46,995 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00019
2018-05-25 11:41:47,002 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00020
2018-05-25 11:41:47,011 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00021
2018-05-25 11:41:47,019 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00022
2018-05-25 11:41:47,028 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00023
2018-05-25 11:41:47,034 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00024
2018-05-25 11:41:47,041 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00025
2018-05-25 11:41:47,048 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00026
2018-05-25 11:41:47,054 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00027
2018-05-25 11:41:47,060 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00028
2018-05-25 11:41:47,068 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00029
2018-05-25 11:41:47,074 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00030
2018-05-25 11:41:47,080 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00031
2018-05-25 11:41:47,086 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00032
2018-05-25 11:41:47,092 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00033
2018-05-25 11:41:47,100 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00034
2018-05-25 11:41:47,107 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00035
2018-05-25 11:41:47,113 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00036
2018-05-25 11:41:47,119 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00037
2018-05-25 11:41:47,125 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00038
2018-05-25 11:41:47,131 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00039
2018-05-25 11:41:47,137 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00040
2018-05-25 11:41:47,143 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00041
2018-05-25 11:41:47,148 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00042
2018-05-25 11:41:47,155 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00043
2018-05-25 11:41:47,161 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00044
2018-05-25 11:41:47,168 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00045
2018-05-25 11:41:47,174 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00046
2018-05-25 11:41:47,180 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00047
2018-05-25 11:41:47,186 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00048
2018-05-25 11:41:47,193 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00049
2018-05-25 11:41:47,199 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00050
2018-05-25 11:41:47,206 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00051
2018-05-25 11:41:47,212 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00052
2018-05-25 11:41:47,219 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00053
2018-05-25 11:41:47,225 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00054
2018-05-25 11:41:47,232 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00055
2018-05-25 11:41:47,238 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00056
2018-05-25 11:41:47,243 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00057
2018-05-25 11:41:47,247 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00058
2018-05-25 11:41:47,252 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00059
2018-05-25 11:41:47,257 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00060
2018-05-25 11:41:47,262 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00061
2018-05-25 11:41:47,267 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00062
2018-05-25 11:41:47,273 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00063
2018-05-25 11:41:47,278 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00064
2018-05-25 11:41:47,283 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00065
2018-05-25 11:41:47,289 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00066
2018-05-25 11:41:47,296 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00067
2018-05-25 11:41:47,302 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00068
2018-05-25 11:41:47,308 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00069
2018-05-25 11:41:47,313 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00070
2018-05-25 11:41:47,319 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00071
2018-05-25 11:41:47,325 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00072
2018-05-25 11:41:47,331 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00073
2018-05-25 11:41:47,336 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00074
2018-05-25 11:41:47,341 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00075
2018-05-25 11:41:47,347 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00076
2018-05-25 11:41:47,353 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00077
2018-05-25 11:41:47,359 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00078
2018-05-25 11:41:47,365 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00079
2018-05-25 11:41:47,371 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00080
2018-05-25 11:41:47,377 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00081
2018-05-25 11:41:47,382 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00082
2018-05-25 11:41:47,388 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00083
2018-05-25 11:41:47,393 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00084
2018-05-25 11:41:47,398 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00085
2018-05-25 11:41:47,404 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00086
2018-05-25 11:41:47,410 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00087
2018-05-25 11:41:47,415 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00088
2018-05-25 11:41:47,421 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00089
2018-05-25 11:41:47,426 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00090
2018-05-25 11:41:47,431 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00091
2018-05-25 11:41:47,436 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00092
2018-05-25 11:41:47,442 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00093
2018-05-25 11:41:47,447 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00094
2018-05-25 11:41:47,453 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00095
2018-05-25 11:41:47,458 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00096
2018-05-25 11:41:47,463 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00097
2018-05-25 11:41:47,468 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00098
2018-05-25 11:41:47,473 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:192 - task__0000_m_000000 acquired hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/fileList.seq.chunk.00099
2018-05-25 11:41:47,478 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:186 - Acquiring pre-assigned chunk: hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/task__0000_m_000001
2018-05-25 11:41:47,482 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:186 - Acquiring pre-assigned chunk: hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/task__0000_m_000002
2018-05-25 11:41:47,487 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:186 - Acquiring pre-assigned chunk: hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/task__0000_m_000003
2018-05-25 11:41:47,491 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:186 - Acquiring pre-assigned chunk: hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/task__0000_m_000004
2018-05-25 11:41:47,496 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:186 - Acquiring pre-assigned chunk: hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/task__0000_m_000005
2018-05-25 11:41:47,500 INFO  com.hotels.bdp.circustrain.s3mapreducecp.mapreduce.lib.DynamicInputChunk:186 - Acquiring pre-assigned chunk: hdfs://localhost:58268/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5076800463114867935/testDynInputFormat/chunkDir/task__0000_m_000006
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.648 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.OptionsParserTest
Tests run: 44, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.066 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.S3MapReduceCpOptionsTest
Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.004 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListingTest
2018-05-25 11:41:47,605 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T
2018-05-25 11:41:47,687 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2524705824266682139/in
2018-05-25 11:41:47,801 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7074145877509969929/source
2018-05-25 11:41:47,808 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7074145877509969929/source
2018-05-25 11:41:47,822 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is /var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7074145877509969929/source
2018-05-25 11:41:47,889 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7664289396294235875/source
2018-05-25 11:41:48,011 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit346009486406240166/source/foo/bar
2018-05-25 11:41:48,018 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit346009486406240166/source/foo/baz
2018-05-25 11:41:48,031 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit346009486406240166/source/foo/bang
2018-05-25 11:41:48,136 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3045506843371547595/source/foo/bar
2018-05-25 11:41:48,143 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3045506843371547595/source/foo/baz
2018-05-25 11:41:48,203 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4139694194624207440/source/foo/bar
2018-05-25 11:41:48,273 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit97654709360138270/in4
2018-05-25 11:41:48,327 INFO  com.hotels.bdp.circustrain.s3mapreducecp.SimpleCopyListing:165 - Root source path is file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7515932490425004714/source
Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.763 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.util.ConfigurationUtilTest
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.072 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.util.IoUtilTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.022 sec
Running com.hotels.bdp.circustrain.s3mapreducecp.util.PathUtilTest
Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
2018-05-25 11:41:48,440 WARN  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:252 - Failed to write dfsUsed to /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/minicluster/test/data/dfs/data/data2/current/BP-733886591-172.21.175.71-1527244871510/current/dfsUsed
java.io.FileNotFoundException: /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/minicluster/test/data/dfs/data/data2/current/BP-733886591-172.21.175.71-1527244871510/current/dfsUsed (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.saveDfsUsed(BlockPoolSlice.java:243)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice$1.run(BlockPoolSlice.java:149)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2018-05-25 11:41:48,441 WARN  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl:252 - Failed to write dfsUsed to /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/minicluster/test/data/dfs/data/data1/current/BP-733886591-172.21.175.71-1527244871510/current/dfsUsed
java.io.FileNotFoundException: /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/minicluster/test/data/dfs/data/data1/current/BP-733886591-172.21.175.71-1527244871510/current/dfsUsed (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.saveDfsUsed(BlockPoolSlice.java:243)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice$1.run(BlockPoolSlice.java:149)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)

Results :

Tests run: 142, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-s3-mapreduce-cp ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/circus-train-s3-mapreduce-cp-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-s3-mapreduce-cp ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/target/circus-train-s3-mapreduce-cp-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-s3-mapreduce-cp/11.5.1-SNAPSHOT/circus-train-s3-mapreduce-cp-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-s3-mapreduce-cp/11.5.1-SNAPSHOT/circus-train-s3-mapreduce-cp-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building S3MapReduceCp Copier 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp-copier/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp-copier/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp-copier/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 4 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp-copier/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 3 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp-copier/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp-copier/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.s3mapreducecpcopier.S3MapReduceCpCopierFactoryTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.56 sec
Running com.hotels.bdp.circustrain.s3mapreducecpcopier.S3MapReduceCpCopierTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.329 sec
Running com.hotels.bdp.circustrain.s3mapreducecpcopier.S3MapReduceCpOptionsParserTest
Tests run: 46, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.02 sec

Results :

Tests run: 51, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp-copier/target/circus-train-s3-mapreduce-cp-copier-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-s3-mapreduce-cp-copier ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp-copier/target/circus-train-s3-mapreduce-cp-copier-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-s3-mapreduce-cp-copier/11.5.1-SNAPSHOT/circus-train-s3-mapreduce-cp-copier-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-mapreduce-cp-copier/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-s3-mapreduce-cp-copier/11.5.1-SNAPSHOT/circus-train-s3-mapreduce-cp-copier-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building S3 To S3 Copier 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-s3-s3-copier ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-s3-copier/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-s3-s3-copier ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-s3-s3-copier ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-s3-s3-copier ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-s3-copier/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-s3-s3-copier ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-s3-s3-copier ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-s3-s3-copier ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-s3-copier/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-s3-s3-copier ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 10 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-s3-copier/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-s3-s3-copier ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-s3-s3-copier ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 4 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-s3-copier/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-s3-s3-copier ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-s3-copier/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.s3s3copier.aws.AmazonS3URIsTest
Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.075 sec
Running com.hotels.bdp.circustrain.s3s3copier.S3S3CopierFactoryTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.295 sec
Running com.hotels.bdp.circustrain.s3s3copier.S3S3CopierOptionsTest
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.008 sec
Running com.hotels.bdp.circustrain.s3s3copier.S3S3CopierTest
2018-05-25 11:41:52,484 INFO  org.gaul.shaded.org.eclipse.jetty.util.log:186 - Logging initialized @1406ms
2018-05-25 11:41:52,555 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:52,589 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@67389cb8{HTTP/1.1}{127.0.0.1:58384}
2018-05-25 11:41:52,589 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @1512ms
2018-05-25 11:41:53,610 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='bar/data1', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:53 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/bar
2018-05-25 11:41:53,613 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/bar/data1' to 'target/foo/data1'
2018-05-25 11:41:53,646 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='bar/data2', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:53 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/bar
2018-05-25 11:41:53,646 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/bar/data2' to 'target/foo/data2'
2018-05-25 11:41:53,646 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:168 - copied object from 'source/bar/data1' to 'target/foo/data1': 7 bytes transferred
2018-05-25 11:41:53,651 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:196 - Replicating...': 50% complete
2018-05-25 11:41:53,655 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:168 - copied object from 'source/bar/data2' to 'target/foo/data2': 7 bytes transferred
2018-05-25 11:41:53,656 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:196 - Replicating...': 100% complete
2018-05-25 11:41:53,670 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@67389cb8{HTTP/1.1}{127.0.0.1:0}
2018-05-25 11:41:53,724 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:53,725 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@27b2faa6{HTTP/1.1}{127.0.0.1:58388}
2018-05-25 11:41:53,725 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @2648ms
2018-05-25 11:41:53,741 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@27b2faa6{HTTP/1.1}{127.0.0.1:0}
2018-05-25 11:41:53,778 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:53,780 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@34b27915{HTTP/1.1}{127.0.0.1:58390}
2018-05-25 11:41:53,780 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @2703ms
2018-05-25 11:41:53,795 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:125 - Starting copyJob from s3://source/year=2016 to s3://target/foo/year=2016
2018-05-25 11:41:53,800 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='year=2016/data', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:53 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/year=2016
2018-05-25 11:41:53,801 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/year=2016/data' to 'target/foo/year=2016/data'
2018-05-25 11:41:53,808 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:168 - copied object from 'source/year=2016/data' to 'target/foo/year=2016/data': 7 bytes transferred
2018-05-25 11:41:53,809 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:196 - Replicating...': 100% complete
2018-05-25 11:41:53,812 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@34b27915{HTTP/1.1}{127.0.0.1:0}
2018-05-25 11:41:53,850 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:53,851 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@3e47a03{HTTP/1.1}{127.0.0.1:58393}
2018-05-25 11:41:53,851 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @2774ms
2018-05-25 11:41:53,887 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='data', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:53 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/null
2018-05-25 11:41:53,888 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/data' to 'target/data'
2018-05-25 11:41:53,894 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@3e47a03{HTTP/1.1}{127.0.0.1:0}
2018-05-25 11:41:53,928 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:53,929 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@288ca5f0{HTTP/1.1}{127.0.0.1:58396}
2018-05-25 11:41:53,929 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @2852ms
2018-05-25 11:41:53,944 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:125 - Starting copyJob from s3://source/year=2016 to s3://target/foo/year=2016
2018-05-25 11:41:53,948 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='year=2016/data', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:53 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/year=2016
2018-05-25 11:41:53,949 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/year=2016/data' to 'target/foo/year=2016/data'
2018-05-25 11:41:53,956 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:168 - copied object from 'source/year=2016/data' to 'target/foo/year=2016/data': 7 bytes transferred
2018-05-25 11:41:53,956 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:196 - Replicating...': 100% complete
2018-05-25 11:41:53,960 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@288ca5f0{HTTP/1.1}{127.0.0.1:0}
2018-05-25 11:41:53,990 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:53,991 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@5f7989fa{HTTP/1.1}{127.0.0.1:58399}
2018-05-25 11:41:53,991 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @2914ms
2018-05-25 11:41:54,007 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='bar/data', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:54 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/bar
2018-05-25 11:41:54,008 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/bar/data' to 'target/foo/data'
2018-05-25 11:41:54,015 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:168 - copied object from 'source/bar/data' to 'target/foo/data': 7 bytes transferred
2018-05-25 11:41:54,015 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:196 - Replicating...': 100% complete
2018-05-25 11:41:54,018 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@5f7989fa{HTTP/1.1}{127.0.0.1:0}
2018-05-25 11:41:54,046 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:54,047 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@242b6e1a{HTTP/1.1}{127.0.0.1:58402}
2018-05-25 11:41:54,047 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @2970ms
2018-05-25 11:41:54,064 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='data', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:54 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/null
2018-05-25 11:41:54,064 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/data' to 'target/data'
2018-05-25 11:41:54,072 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:168 - copied object from 'source/data' to 'target/data': 7 bytes transferred
2018-05-25 11:41:54,072 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:196 - Replicating...': 100% complete
2018-05-25 11:41:54,076 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@242b6e1a{HTTP/1.1}{127.0.0.1:0}
2018-05-25 11:41:54,105 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:54,106 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@6cd3ad8a{HTTP/1.1}{127.0.0.1:58405}
2018-05-25 11:41:54,106 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @3029ms
2018-05-25 11:41:54,127 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='data', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:54 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/null
2018-05-25 11:41:54,127 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/data' to 'target/data'
2018-05-25 11:41:54,130 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@6cd3ad8a{HTTP/1.1}{127.0.0.1:0}
2018-05-25 11:41:54,157 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:54,159 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@3c78e551{HTTP/1.1}{127.0.0.1:58408}
2018-05-25 11:41:54,159 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @3082ms
2018-05-25 11:41:54,177 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='data', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:54 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/null
2018-05-25 11:41:54,177 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/data' to 'target/data'
2018-05-25 11:41:54,178 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@3c78e551{HTTP/1.1}{127.0.0.1:0}
2018-05-25 11:41:54,209 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:54,210 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@313f8301{HTTP/1.1}{127.0.0.1:58411}
2018-05-25 11:41:54,210 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @3133ms
2018-05-25 11:41:54,226 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='data', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:54 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/null
2018-05-25 11:41:54,226 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/data' to 'target/data'
2018-05-25 11:41:54,228 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@313f8301{HTTP/1.1}{127.0.0.1:0}
2018-05-25 11:41:54,250 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:54,252 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@1a0c5e9{HTTP/1.1}{127.0.0.1:58414}
2018-05-25 11:41:54,252 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @3175ms
2018-05-25 11:41:54,268 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='data', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:54 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/null
2018-05-25 11:41:54,268 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/data' to 'target/data'
2018-05-25 11:41:54,269 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@1a0c5e9{HTTP/1.1}{127.0.0.1:0}
2018-05-25 11:41:54,292 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:327 - jetty-9.2.z-SNAPSHOT
2018-05-25 11:41:54,294 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:266 - Started ServerConnector@79518e00{HTTP/1.1}{127.0.0.1:58417}
2018-05-25 11:41:54,294 INFO  org.gaul.shaded.org.eclipse.jetty.server.Server:379 - Started @3217ms
2018-05-25 11:41:54,307 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:125 - Starting copyJob from s3://source/nested/year=2016 to s3://target/foo/year=2016
2018-05-25 11:41:54,311 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:147 - Found objects to copy [S3ObjectSummary{bucketName='source', key='nested/year=2016/data', eTag='eb4572ebaf0b16473576ed5673b09603', size=7, lastModified=Fri May 25 11:41:54 BST 2018, storageClass='STANDARD', owner=S3Owner [name=CustomersName@amazon.com,id=75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a]}], for request source/nested/year=2016
2018-05-25 11:41:54,311 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:153 - copying object from 'source/nested/year=2016/data' to 'target/foo/year=2016/data'
2018-05-25 11:41:54,319 DEBUG com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:168 - copied object from 'source/nested/year=2016/data' to 'target/foo/year=2016/data': 7 bytes transferred
2018-05-25 11:41:54,319 INFO  com.hotels.bdp.circustrain.s3s3copier.S3S3Copier:196 - Replicating...': 100% complete
2018-05-25 11:41:54,322 INFO  org.gaul.shaded.org.eclipse.jetty.server.ServerConnector:306 - Stopped ServerConnector@79518e00{HTTP/1.1}{127.0.0.1:0}
Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.619 sec

Results :

Tests run: 33, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-s3-s3-copier ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-s3-copier/target/circus-train-s3-s3-copier-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-s3-s3-copier ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-s3-copier/target/circus-train-s3-s3-copier-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-s3-s3-copier/11.5.1-SNAPSHOT/circus-train-s3-s3-copier-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-s3-s3-copier/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-s3-s3-copier/11.5.1-SNAPSHOT/circus-train-s3-s3-copier-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Circus Train Housekeeping 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-housekeeping ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-housekeeping/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-housekeeping ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-housekeeping ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-housekeeping ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-housekeeping/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-housekeeping ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-housekeeping ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-housekeeping ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-housekeeping ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 3 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-housekeeping/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-housekeeping ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-housekeeping ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 2 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-housekeeping/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-housekeeping ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-housekeeping/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.housekeeping.HousekeepingRunnerTest
2018-05-25 11:41:55,206 INFO  com.hotels.bdp.circustrain.housekeeping.HousekeepingRunner:59 - Housekeeping at instant 2018-05-23T10:41:55.176Z has started
2018-05-25 11:41:55,210 INFO  com.hotels.bdp.circustrain.housekeeping.HousekeepingRunner:63 - Housekeeping at instant 2018-05-23T10:41:55.176Z has finished
2018-05-25 11:41:55,231 INFO  com.hotels.bdp.circustrain.housekeeping.HousekeepingRunner:59 - Housekeeping at instant 2018-05-23T10:41:55.231Z has started
2018-05-25 11:41:55,233 ERROR com.hotels.bdp.circustrain.housekeeping.HousekeepingRunner:66 - Housekeeping at instant 2018-05-23T10:41:55.231Z has failed
java.lang.IllegalStateException
	at com.hotels.bdp.circustrain.housekeeping.HousekeepingRunner.run(HousekeepingRunner.java:62)
	at com.hotels.bdp.circustrain.housekeeping.HousekeepingRunnerTest.rethrowException(HousekeepingRunnerTest.java:68)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.ExpectException.evaluate(ExpectException.java:19)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.mockito.internal.runners.JUnit45AndHigherRunnerImpl.run(JUnit45AndHigherRunnerImpl.java:37)
	at org.mockito.runners.MockitoJUnitRunner.run(MockitoJUnitRunner.java:62)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.38 sec
Running com.hotels.bdp.circustrain.housekeeping.JdbcHousekeepingListenerTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.015 sec

Results :

Tests run: 3, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-housekeeping ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-housekeeping/target/circus-train-housekeeping-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-housekeeping ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-housekeeping/target/circus-train-housekeeping-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-housekeeping/11.5.1-SNAPSHOT/circus-train-housekeeping-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-housekeeping/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-housekeeping/11.5.1-SNAPSHOT/circus-train-housekeeping-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Hive View 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-hive-view ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-hive-view/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-hive-view ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-hive-view ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-hive-view ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-hive-view/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-hive-view ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-hive-view ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-hive-view ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-hive-view/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-hive-view ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 4 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-hive-view/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-hive-view ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-hive-view/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-hive-view ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 5 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-hive-view/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-hive-view ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-hive-view/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.hive.view.transformation.HqlTranslatorTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.316 sec
Running com.hotels.bdp.circustrain.hive.view.transformation.TableProcessorIntegrationTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.185 sec
Running com.hotels.bdp.circustrain.hive.view.transformation.TableProcessorTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.423 sec
Running com.hotels.bdp.circustrain.hive.view.transformation.TableTranslationTest
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running com.hotels.bdp.circustrain.hive.view.transformation.ViewTransformationTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.44 sec

Results :

Tests run: 20, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ circus-train-hive-view ---
[INFO] Building jar: /Users/cedwards/Documents/workspace/circus-train/circus-train-hive-view/target/circus-train-hive-view-11.5.1-SNAPSHOT.jar
[INFO] 
[INFO] --- maven-install-plugin:2.4:install (default-install) @ circus-train-hive-view ---
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-hive-view/target/circus-train-hive-view-11.5.1-SNAPSHOT.jar to /Users/cedwards/.m2/repository/com/hotels/circus-train-hive-view/11.5.1-SNAPSHOT/circus-train-hive-view-11.5.1-SNAPSHOT.jar
[INFO] Installing /Users/cedwards/Documents/workspace/circus-train/circus-train-hive-view/pom.xml to /Users/cedwards/.m2/repository/com/hotels/circus-train-hive-view/11.5.1-SNAPSHOT/circus-train-hive-view-11.5.1-SNAPSHOT.pom
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Integration Tests 11.5.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ circus-train-integration-tests ---
[INFO] Deleting /Users/cedwards/Documents/workspace/circus-train/circus-train-integration-tests/target
[INFO] 
[INFO] --- cobertura-maven-plugin:2.7:clean (default) @ circus-train-integration-tests ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ circus-train-integration-tests ---
[INFO] 
[INFO] --- maven-dependency-plugin:2.9:unpack (unpack) @ circus-train-integration-tests ---
[INFO] Configured Artifact: com.hotels:hotels-oss-plugin-config:1.1.0:jar
[INFO] Unpacking /Users/cedwards/.m2/repository/com/hotels/hotels-oss-plugin-config/1.1.0/hotels-oss-plugin-config-1.1.0.jar to /Users/cedwards/Documents/workspace/circus-train/circus-train-integration-tests/target/plugin-config with includes "" and excludes ""
[INFO] 
[INFO] --- buildnumber-maven-plugin:1.4:create-timestamp (default) @ circus-train-integration-tests ---
[INFO] 
[INFO] --- license-maven-plugin:3.0:format (default) @ circus-train-integration-tests ---
[INFO] Updating license headers...
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ circus-train-integration-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/cedwards/Documents/workspace/circus-train/circus-train-integration-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ circus-train-integration-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ circus-train-integration-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ circus-train-integration-tests ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 6 source files to /Users/cedwards/Documents/workspace/circus-train/circus-train-integration-tests/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 1.7
[WARNING] /Users/cedwards/Documents/workspace/circus-train/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/utils/TestUtils.java:[115,20] updateTableColumnStatistics(org.apache.hadoop.hive.metastore.api.ColumnStatistics) in org.apache.hadoop.hive.metastore.HiveMetaStoreClient has been deprecated
[WARNING] /Users/cedwards/Documents/workspace/circus-train/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/utils/TestUtils.java:[152,20] updateTableColumnStatistics(org.apache.hadoop.hive.metastore.api.ColumnStatistics) in org.apache.hadoop.hive.metastore.HiveMetaStoreClient has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ circus-train-integration-tests ---
[INFO] Surefire report directory: /Users/cedwards/Documents/workspace/circus-train/circus-train-integration-tests/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest
2018-05-25 11:42:01,008 INFO  org.apache.hadoop.hive.conf.HiveConf:181 - Found configuration file null
2018-05-25 11:42:01,661 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:01,711 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:01,836 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:01,837 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:03,232 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:04,902 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:04,904 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:04,977 WARN  org.apache.hadoop.hive.metastore.ObjectStore:7566 - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
2018-05-25 11:42:04,977 WARN  org.apache.hadoop.hive.metastore.ObjectStore:7654 - setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore cedwards@172.21.175.71
2018-05-25 11:42:04,993 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:05,092 WARN  org.apache.hadoop.util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-25 11:42:05,439 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:05,441 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:05,487 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:05,611 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:05,616 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58422]...
2018-05-25 11:42:05,616 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:05,616 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:05,616 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:06,682 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58422
2018-05-25 11:42:06,698 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 1
2018-05-25 11:42:06,754 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:06,787 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58422
2018-05-25 11:42:06,788 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:42:06,789 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:06,795 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 2: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5859487012904016404/ct_database, parameters:null)
2018-05-25 11:42:06,796 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5859487012904016404/ct_database, parameters:null)	
2018-05-25 11:42:06,830 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:06,831 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:06,837 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:06,837 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:06,839 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:06,841 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5859487012904016404/ct_database
2018-05-25 11:42:06,919 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoSuchMethodError: com.google.common.base.Enums.valueOfFunction(Ljava/lang/Class;)Lcom/google/common/base/Function;
	at org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand.<clinit>(XAttrCommands.java:70)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:06,919 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 2: Cleaning up thread local RawStore...
2018-05-25 11:42:06,919 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:06,920 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 2: Done cleaning up thread local RawStore
2018-05-25 11:42:06,920 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:06,924 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 1
2018-05-25 11:42:07,134 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:07,139 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:07,159 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:07,159 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:07,644 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:08,192 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:08,192 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:08,195 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:08,258 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:08,260 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:08,291 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:08,291 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:08,291 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58427]...
2018-05-25 11:42:08,291 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:08,292 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:08,292 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:09,332 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58427
2018-05-25 11:42:09,333 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 2
2018-05-25 11:42:09,334 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:09,336 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58427
2018-05-25 11:42:09,336 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 3
2018-05-25 11:42:09,337 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:09,337 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 5: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit75069821017964098/ct_database, parameters:null)
2018-05-25 11:42:09,338 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit75069821017964098/ct_database, parameters:null)	
2018-05-25 11:42:09,373 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:09,374 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:09,382 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:09,382 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:09,383 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:09,384 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit75069821017964098/ct_database
2018-05-25 11:42:09,394 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:09,394 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 5: Cleaning up thread local RawStore...
2018-05-25 11:42:09,394 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:09,394 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 5: Done cleaning up thread local RawStore
2018-05-25 11:42:09,394 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:09,395 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 2
2018-05-25 11:42:09,545 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:09,547 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:09,561 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:09,561 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:09,968 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:10,460 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:10,460 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:10,463 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:10,524 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:10,525 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:10,551 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:10,551 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:10,551 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58431]...
2018-05-25 11:42:10,552 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:10,552 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:10,552 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:11,591 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58431
2018-05-25 11:42:11,591 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 3
2018-05-25 11:42:11,593 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:11,593 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58431
2018-05-25 11:42:11,594 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 4
2018-05-25 11:42:11,595 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:11,595 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 8: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2549901047030643144/ct_database, parameters:null)
2018-05-25 11:42:11,595 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2549901047030643144/ct_database, parameters:null)	
2018-05-25 11:42:11,627 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:11,628 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:11,638 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:11,638 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:11,640 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:11,641 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2549901047030643144/ct_database
2018-05-25 11:42:11,652 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:11,652 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 8: Cleaning up thread local RawStore...
2018-05-25 11:42:11,652 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:11,652 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 8: Done cleaning up thread local RawStore
2018-05-25 11:42:11,652 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:11,653 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 3
2018-05-25 11:42:11,824 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:11,826 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:11,837 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:11,838 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:12,388 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:12,895 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:12,895 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:12,898 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:12,964 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:12,966 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:13,008 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:13,009 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:13,009 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58435]...
2018-05-25 11:42:13,009 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:13,009 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:13,009 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:14,047 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58435
2018-05-25 11:42:14,048 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 4
2018-05-25 11:42:14,049 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:14,050 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58435
2018-05-25 11:42:14,050 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 5
2018-05-25 11:42:14,051 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:14,052 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 11: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6950083997955348960/ct_database, parameters:null)
2018-05-25 11:42:14,052 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6950083997955348960/ct_database, parameters:null)	
2018-05-25 11:42:14,087 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 11: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:14,088 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:14,096 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:14,097 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:14,098 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:14,099 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6950083997955348960/ct_database
2018-05-25 11:42:14,108 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:14,108 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 11: Cleaning up thread local RawStore...
2018-05-25 11:42:14,109 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:14,109 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 11: Done cleaning up thread local RawStore
2018-05-25 11:42:14,109 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:14,109 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 4
2018-05-25 11:42:14,279 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 12: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:14,283 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:14,296 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:14,296 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:14,732 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:15,423 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:15,423 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:15,426 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:15,485 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:15,487 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:15,512 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:15,513 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:15,513 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58440]...
2018-05-25 11:42:15,513 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:15,513 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:15,513 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:16,549 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58440
2018-05-25 11:42:16,550 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 5
2018-05-25 11:42:16,551 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:16,552 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58440
2018-05-25 11:42:16,552 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 6
2018-05-25 11:42:16,553 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:16,553 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 14: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3973913114080099220/ct_database, parameters:null)
2018-05-25 11:42:16,554 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3973913114080099220/ct_database, parameters:null)	
2018-05-25 11:42:16,587 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:16,588 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:16,597 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:16,597 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:16,598 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:16,599 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3973913114080099220/ct_database
2018-05-25 11:42:16,609 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:16,609 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 14: Cleaning up thread local RawStore...
2018-05-25 11:42:16,610 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:16,610 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 14: Done cleaning up thread local RawStore
2018-05-25 11:42:16,610 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:16,610 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 5
2018-05-25 11:42:16,755 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:16,757 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:16,768 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:16,768 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:17,166 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:17,681 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:17,681 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:17,684 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:17,742 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:17,743 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:17,768 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:17,768 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:17,768 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58444]...
2018-05-25 11:42:17,768 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:17,768 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:17,768 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:18,804 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58444
2018-05-25 11:42:18,805 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 6
2018-05-25 11:42:18,806 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:18,807 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58444
2018-05-25 11:42:18,807 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 7
2018-05-25 11:42:18,808 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:18,808 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 17: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5017506951594826790/ct_database, parameters:null)
2018-05-25 11:42:18,809 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5017506951594826790/ct_database, parameters:null)	
2018-05-25 11:42:18,839 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:18,839 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:18,847 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:18,847 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:18,848 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:18,848 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5017506951594826790/ct_database
2018-05-25 11:42:18,857 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:18,857 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 17: Cleaning up thread local RawStore...
2018-05-25 11:42:18,857 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:18,858 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 17: Done cleaning up thread local RawStore
2018-05-25 11:42:18,858 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:18,858 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 6
2018-05-25 11:42:19,006 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:19,007 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:19,020 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:19,020 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:19,509 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:19,964 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:19,964 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:19,967 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:20,018 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:20,019 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:20,042 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:20,042 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:20,042 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58449]...
2018-05-25 11:42:20,043 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:20,043 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:20,043 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:21,082 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58449
2018-05-25 11:42:21,082 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 7
2018-05-25 11:42:21,083 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:21,084 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58449
2018-05-25 11:42:21,085 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 8
2018-05-25 11:42:21,085 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:21,086 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 20: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8459399878709182790/ct_database, parameters:null)
2018-05-25 11:42:21,086 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8459399878709182790/ct_database, parameters:null)	
2018-05-25 11:42:21,112 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 20: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:21,113 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:21,121 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:21,121 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:21,122 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:21,122 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8459399878709182790/ct_database
2018-05-25 11:42:21,131 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:21,132 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 20: Cleaning up thread local RawStore...
2018-05-25 11:42:21,132 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:21,132 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 20: Done cleaning up thread local RawStore
2018-05-25 11:42:21,132 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:21,132 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 7
2018-05-25 11:42:21,271 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 21: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:21,273 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:21,284 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:21,285 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:21,671 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:22,138 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:22,139 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:22,141 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:22,200 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:22,202 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:22,226 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:22,227 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:22,227 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58453]...
2018-05-25 11:42:22,227 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:22,227 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:22,227 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:23,260 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58453
2018-05-25 11:42:23,260 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 8
2018-05-25 11:42:23,262 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:23,263 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58453
2018-05-25 11:42:23,264 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 9
2018-05-25 11:42:23,265 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:23,266 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 23: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3319363624936518493/ct_database, parameters:null)
2018-05-25 11:42:23,266 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3319363624936518493/ct_database, parameters:null)	
2018-05-25 11:42:23,296 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 23: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:23,297 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:23,305 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:23,305 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:23,307 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:23,307 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3319363624936518493/ct_database
2018-05-25 11:42:23,317 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:23,317 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 23: Cleaning up thread local RawStore...
2018-05-25 11:42:23,317 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:23,317 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 23: Done cleaning up thread local RawStore
2018-05-25 11:42:23,317 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:23,318 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 8
2018-05-25 11:42:23,483 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 24: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:23,484 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:23,498 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:23,498 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:23,856 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:24,286 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:24,286 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:24,288 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:24,342 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:24,343 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:24,364 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:24,364 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:24,365 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58457]...
2018-05-25 11:42:24,365 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:24,365 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:24,365 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:25,395 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58457
2018-05-25 11:42:25,395 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 9
2018-05-25 11:42:25,396 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:25,398 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58457
2018-05-25 11:42:25,398 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 10
2018-05-25 11:42:25,399 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:25,399 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 26: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5940736059397908013/ct_database, parameters:null)
2018-05-25 11:42:25,400 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5940736059397908013/ct_database, parameters:null)	
2018-05-25 11:42:25,426 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 26: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:25,427 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:25,434 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:25,434 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:25,435 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:25,436 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5940736059397908013/ct_database
2018-05-25 11:42:25,450 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:25,450 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 26: Cleaning up thread local RawStore...
2018-05-25 11:42:25,450 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:25,450 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 26: Done cleaning up thread local RawStore
2018-05-25 11:42:25,450 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:25,451 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 9
2018-05-25 11:42:25,587 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 27: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:25,588 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:25,599 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:25,600 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:25,992 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:26,531 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:26,532 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:26,537 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:26,805 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:26,807 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:26,902 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:26,903 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:26,904 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58462]...
2018-05-25 11:42:26,907 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:26,907 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:26,907 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:27,946 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58462
2018-05-25 11:42:27,947 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 10
2018-05-25 11:42:27,948 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:27,949 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58462
2018-05-25 11:42:27,950 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 11
2018-05-25 11:42:27,951 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:27,951 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 29: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7868898320593128046/ct_database, parameters:null)
2018-05-25 11:42:27,952 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7868898320593128046/ct_database, parameters:null)	
2018-05-25 11:42:28,010 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 29: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:28,011 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:28,023 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:28,024 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:28,026 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:28,026 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7868898320593128046/ct_database
2018-05-25 11:42:28,040 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:28,040 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 29: Cleaning up thread local RawStore...
2018-05-25 11:42:28,040 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:28,040 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 29: Done cleaning up thread local RawStore
2018-05-25 11:42:28,041 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:28,041 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 10
2018-05-25 11:42:28,272 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 30: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:28,273 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:28,425 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:28,425 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:28,844 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:29,301 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:29,301 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:29,303 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:29,354 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:29,355 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:29,375 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:29,376 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:29,376 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58466]...
2018-05-25 11:42:29,376 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:29,376 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:29,376 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:30,418 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58466
2018-05-25 11:42:30,419 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 11
2018-05-25 11:42:30,421 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:30,422 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58466
2018-05-25 11:42:30,423 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 12
2018-05-25 11:42:30,424 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:30,424 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 32: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8087920412112194194/ct_database, parameters:null)
2018-05-25 11:42:30,424 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8087920412112194194/ct_database, parameters:null)	
2018-05-25 11:42:30,460 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 32: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:30,460 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:30,468 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:30,469 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:30,470 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:30,471 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8087920412112194194/ct_database
2018-05-25 11:42:30,485 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:30,485 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 32: Cleaning up thread local RawStore...
2018-05-25 11:42:30,485 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:30,485 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 32: Done cleaning up thread local RawStore
2018-05-25 11:42:30,486 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:30,486 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 11
2018-05-25 11:42:30,638 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 33: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:30,639 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:30,652 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:30,652 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:31,021 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:31,463 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:31,463 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:31,465 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:31,517 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:31,518 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:31,540 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:31,540 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:31,540 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58470]...
2018-05-25 11:42:31,540 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:31,540 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:31,540 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:32,575 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58470
2018-05-25 11:42:32,575 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 12
2018-05-25 11:42:32,576 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:32,577 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58470
2018-05-25 11:42:32,578 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 13
2018-05-25 11:42:32,578 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:32,579 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 35: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6643065959415150826/ct_database, parameters:null)
2018-05-25 11:42:32,579 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6643065959415150826/ct_database, parameters:null)	
2018-05-25 11:42:32,606 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 35: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:32,607 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:32,613 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:32,614 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:32,614 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:32,615 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6643065959415150826/ct_database
2018-05-25 11:42:32,625 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:32,625 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 35: Cleaning up thread local RawStore...
2018-05-25 11:42:32,625 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:32,625 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 35: Done cleaning up thread local RawStore
2018-05-25 11:42:32,625 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:32,626 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 12
2018-05-25 11:42:32,760 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 36: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:32,761 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:32,772 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:32,772 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:33,180 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:33,594 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:33,594 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:33,596 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:33,647 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:33,648 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:33,671 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:33,671 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:33,671 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58474]...
2018-05-25 11:42:33,671 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:33,672 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:33,672 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:34,705 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58474
2018-05-25 11:42:34,706 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 13
2018-05-25 11:42:34,707 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:34,708 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58474
2018-05-25 11:42:34,709 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 14
2018-05-25 11:42:34,710 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:34,710 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 38: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6987860697816921018/ct_database, parameters:null)
2018-05-25 11:42:34,710 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6987860697816921018/ct_database, parameters:null)	
2018-05-25 11:42:34,738 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 38: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:34,739 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:34,746 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:34,746 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:34,747 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:34,747 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6987860697816921018/ct_database
2018-05-25 11:42:34,762 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:34,762 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 38: Cleaning up thread local RawStore...
2018-05-25 11:42:34,762 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:34,762 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 38: Done cleaning up thread local RawStore
2018-05-25 11:42:34,762 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:34,763 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 13
2018-05-25 11:42:34,890 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 39: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:34,890 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:34,900 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:34,901 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:35,250 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:35,660 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:35,661 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:35,662 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:35,715 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:35,716 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:35,737 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:35,738 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:35,738 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58478]...
2018-05-25 11:42:35,738 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:35,738 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:35,738 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:36,772 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58478
2018-05-25 11:42:36,773 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 14
2018-05-25 11:42:36,774 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:36,776 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58478
2018-05-25 11:42:36,776 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 15
2018-05-25 11:42:36,778 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:36,778 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 41: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7268182741692080410/ct_database, parameters:null)
2018-05-25 11:42:36,778 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7268182741692080410/ct_database, parameters:null)	
2018-05-25 11:42:36,803 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 41: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:36,803 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:36,811 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:36,811 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:36,812 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:36,813 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7268182741692080410/ct_database
2018-05-25 11:42:36,823 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:36,823 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 41: Cleaning up thread local RawStore...
2018-05-25 11:42:36,823 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:36,823 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 41: Done cleaning up thread local RawStore
2018-05-25 11:42:36,823 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:36,824 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 14
2018-05-25 11:42:36,957 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 42: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:36,958 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:36,969 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:36,969 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:37,345 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:37,884 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:37,885 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:37,887 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:37,946 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:37,947 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:37,973 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:37,974 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:37,974 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58482]...
2018-05-25 11:42:37,974 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:37,974 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:37,974 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:39,136 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58482
2018-05-25 11:42:39,136 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 15
2018-05-25 11:42:39,138 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:39,138 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58482
2018-05-25 11:42:39,139 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 16
2018-05-25 11:42:39,140 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:39,140 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 44: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5383540856612835629/ct_database, parameters:null)
2018-05-25 11:42:39,140 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5383540856612835629/ct_database, parameters:null)	
2018-05-25 11:42:39,164 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 44: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:39,165 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:39,172 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:39,172 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:39,173 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:39,173 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit5383540856612835629/ct_database
2018-05-25 11:42:39,184 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:39,184 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 44: Cleaning up thread local RawStore...
2018-05-25 11:42:39,184 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:39,184 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 44: Done cleaning up thread local RawStore
2018-05-25 11:42:39,184 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:39,185 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 15
2018-05-25 11:42:39,321 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 45: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:39,323 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:39,335 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:39,336 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:39,684 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:40,116 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:40,116 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:40,119 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:40,181 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:40,182 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:40,204 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:40,204 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:40,205 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58486]...
2018-05-25 11:42:40,205 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:40,205 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:40,205 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:41,240 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58486
2018-05-25 11:42:41,240 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 16
2018-05-25 11:42:41,242 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:41,242 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58486
2018-05-25 11:42:41,243 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 17
2018-05-25 11:42:41,244 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:41,244 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 47: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8778587164551617333/ct_database, parameters:null)
2018-05-25 11:42:41,244 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8778587164551617333/ct_database, parameters:null)	
2018-05-25 11:42:41,274 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 47: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:41,275 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:41,284 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:41,284 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:41,285 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:41,285 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8778587164551617333/ct_database
2018-05-25 11:42:41,301 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:41,301 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 47: Cleaning up thread local RawStore...
2018-05-25 11:42:41,302 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:41,302 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 47: Done cleaning up thread local RawStore
2018-05-25 11:42:41,302 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:41,302 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 16
2018-05-25 11:42:41,430 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 48: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:41,431 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:41,441 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:41,441 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:41,822 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:42,278 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:42,278 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:42,281 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:42,334 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:42,335 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:42,360 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:42,360 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:42,360 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58491]...
2018-05-25 11:42:42,360 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:42,360 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:42,360 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:43,394 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58491
2018-05-25 11:42:43,395 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 17
2018-05-25 11:42:43,396 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:43,396 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58491
2018-05-25 11:42:43,397 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 18
2018-05-25 11:42:43,398 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:43,398 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 50: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4485406687627054390/ct_database, parameters:null)
2018-05-25 11:42:43,398 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4485406687627054390/ct_database, parameters:null)	
2018-05-25 11:42:43,428 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 50: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:43,429 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:43,436 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:43,436 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:43,437 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:43,437 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit4485406687627054390/ct_database
2018-05-25 11:42:43,451 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:43,451 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 50: Cleaning up thread local RawStore...
2018-05-25 11:42:43,451 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:43,451 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 50: Done cleaning up thread local RawStore
2018-05-25 11:42:43,451 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:43,452 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 17
2018-05-25 11:42:43,577 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 51: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:43,578 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:43,588 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:43,588 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:44,126 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:44,828 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:44,828 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:44,830 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:44,880 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:44,881 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:44,900 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:44,901 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:44,901 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58495]...
2018-05-25 11:42:44,901 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:44,901 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:44,901 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:45,930 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58495
2018-05-25 11:42:45,930 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 18
2018-05-25 11:42:45,931 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:45,932 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58495
2018-05-25 11:42:45,932 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 19
2018-05-25 11:42:45,933 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:45,933 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 53: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2716412019478793557/ct_database, parameters:null)
2018-05-25 11:42:45,934 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2716412019478793557/ct_database, parameters:null)	
2018-05-25 11:42:45,958 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 53: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:45,959 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:45,965 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:45,966 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:45,966 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:45,967 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2716412019478793557/ct_database
2018-05-25 11:42:45,977 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:45,977 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 53: Cleaning up thread local RawStore...
2018-05-25 11:42:45,977 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:45,977 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 53: Done cleaning up thread local RawStore
2018-05-25 11:42:45,977 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:45,978 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 18
2018-05-25 11:42:46,110 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 54: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:46,111 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:46,121 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:46,121 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:46,452 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:46,844 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:46,844 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:46,846 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:46,891 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:46,892 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:46,913 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:46,913 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:46,913 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58500]...
2018-05-25 11:42:46,913 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:46,913 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:46,913 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:47,948 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58500
2018-05-25 11:42:47,948 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 19
2018-05-25 11:42:47,949 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:47,950 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58500
2018-05-25 11:42:47,951 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 20
2018-05-25 11:42:47,951 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:47,952 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 56: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3879514325813479954/ct_database, parameters:null)
2018-05-25 11:42:47,952 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3879514325813479954/ct_database, parameters:null)	
2018-05-25 11:42:47,977 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 56: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:47,978 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:47,984 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:47,985 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:47,986 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:47,986 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3879514325813479954/ct_database
2018-05-25 11:42:47,997 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:47,997 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 56: Cleaning up thread local RawStore...
2018-05-25 11:42:47,997 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:47,997 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 56: Done cleaning up thread local RawStore
2018-05-25 11:42:47,997 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:47,998 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 19
2018-05-25 11:42:48,123 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 57: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:48,124 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:48,134 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:48,134 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:48,472 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:48,866 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:48,866 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:48,868 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:48,916 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:48,917 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:48,938 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:48,938 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:48,939 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58504]...
2018-05-25 11:42:48,939 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:48,939 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:48,939 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:49,972 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58504
2018-05-25 11:42:49,973 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 20
2018-05-25 11:42:49,974 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:49,975 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58504
2018-05-25 11:42:49,975 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 21
2018-05-25 11:42:49,976 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:49,977 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 59: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3591294034728038251/ct_database, parameters:null)
2018-05-25 11:42:49,977 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3591294034728038251/ct_database, parameters:null)	
2018-05-25 11:42:50,001 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 59: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:50,002 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:50,009 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:50,009 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:50,011 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:50,011 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3591294034728038251/ct_database
2018-05-25 11:42:50,021 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:50,021 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 59: Cleaning up thread local RawStore...
2018-05-25 11:42:50,021 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:50,021 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 59: Done cleaning up thread local RawStore
2018-05-25 11:42:50,021 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:50,022 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 20
2018-05-25 11:42:50,148 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 60: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:50,149 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:50,158 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:50,158 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:50,538 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:50,940 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:50,940 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:50,942 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:50,990 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:50,991 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:51,012 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:51,012 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:51,012 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58508]...
2018-05-25 11:42:51,013 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:51,013 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:51,013 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:52,044 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58508
2018-05-25 11:42:52,044 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 21
2018-05-25 11:42:52,046 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:52,046 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58508
2018-05-25 11:42:52,047 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 22
2018-05-25 11:42:52,049 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:52,049 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 62: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6542691719195382438/ct_database, parameters:null)
2018-05-25 11:42:52,049 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6542691719195382438/ct_database, parameters:null)	
2018-05-25 11:42:52,074 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 62: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:52,074 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:52,084 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:52,085 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:52,085 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:52,086 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit6542691719195382438/ct_database
2018-05-25 11:42:52,096 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:52,096 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 62: Cleaning up thread local RawStore...
2018-05-25 11:42:52,096 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:52,096 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 62: Done cleaning up thread local RawStore
2018-05-25 11:42:52,097 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:52,097 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 21
2018-05-25 11:42:52,223 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 63: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:52,224 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:52,234 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:52,234 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:52,565 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:52,973 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:52,974 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:52,975 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:53,024 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:53,025 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:53,047 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:53,047 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:53,048 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58512]...
2018-05-25 11:42:53,048 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:53,048 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:53,048 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:54,083 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58512
2018-05-25 11:42:54,083 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 22
2018-05-25 11:42:54,084 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:54,085 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58512
2018-05-25 11:42:54,085 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 23
2018-05-25 11:42:54,085 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:54,086 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 65: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7883731056412643333/ct_database, parameters:null)
2018-05-25 11:42:54,086 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7883731056412643333/ct_database, parameters:null)	
2018-05-25 11:42:54,110 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 65: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:54,111 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:54,116 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:54,116 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:54,117 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:54,117 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7883731056412643333/ct_database
2018-05-25 11:42:54,128 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:54,128 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 65: Cleaning up thread local RawStore...
2018-05-25 11:42:54,129 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:54,129 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 65: Done cleaning up thread local RawStore
2018-05-25 11:42:54,129 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:54,129 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 22
2018-05-25 11:42:54,254 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 66: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:54,255 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:54,264 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:54,264 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:54,591 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:54,995 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:54,995 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:54,997 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:55,048 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:55,049 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:55,067 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:55,067 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:55,067 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58516]...
2018-05-25 11:42:55,067 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:55,067 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:55,067 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:56,102 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58516
2018-05-25 11:42:56,102 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 23
2018-05-25 11:42:56,103 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:56,104 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58516
2018-05-25 11:42:56,105 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 24
2018-05-25 11:42:56,105 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:56,106 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 68: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit1111604892490496148/ct_database, parameters:null)
2018-05-25 11:42:56,106 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit1111604892490496148/ct_database, parameters:null)	
2018-05-25 11:42:56,135 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 68: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:56,135 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:56,141 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:56,141 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:56,142 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:56,142 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit1111604892490496148/ct_database
2018-05-25 11:42:56,157 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:56,157 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 68: Cleaning up thread local RawStore...
2018-05-25 11:42:56,157 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:56,157 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 68: Done cleaning up thread local RawStore
2018-05-25 11:42:56,157 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:56,158 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 23
2018-05-25 11:42:56,288 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 69: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:56,288 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:56,301 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:56,302 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:56,665 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:57,065 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:57,065 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:57,067 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:57,114 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:57,115 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:57,136 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:57,136 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:57,136 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58520]...
2018-05-25 11:42:57,136 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:57,136 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:57,136 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:42:58,170 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58520
2018-05-25 11:42:58,171 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 24
2018-05-25 11:42:58,171 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:58,172 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58520
2018-05-25 11:42:58,172 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 25
2018-05-25 11:42:58,173 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:42:58,173 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 71: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3741510902998077381/ct_database, parameters:null)
2018-05-25 11:42:58,174 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3741510902998077381/ct_database, parameters:null)	
2018-05-25 11:42:58,201 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 71: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:58,202 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:58,207 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:58,208 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:58,208 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:42:58,209 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit3741510902998077381/ct_database
2018-05-25 11:42:58,218 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:42:58,219 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 71: Cleaning up thread local RawStore...
2018-05-25 11:42:58,219 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:42:58,219 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 71: Done cleaning up thread local RawStore
2018-05-25 11:42:58,219 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:42:58,219 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 24
2018-05-25 11:42:58,353 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 72: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:42:58,354 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:42:58,365 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:42:58,365 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:42:58,727 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:42:59,148 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:42:59,148 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:42:59,150 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:42:59,204 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:42:59,205 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:42:59,226 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:42:59,226 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:42:59,226 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58524]...
2018-05-25 11:42:59,226 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:42:59,226 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:42:59,226 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:43:00,260 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58524
2018-05-25 11:43:00,260 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 25
2018-05-25 11:43:00,261 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:00,262 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58524
2018-05-25 11:43:00,262 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 26
2018-05-25 11:43:00,263 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:00,263 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 74: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit1657863956348297978/ct_database, parameters:null)
2018-05-25 11:43:00,263 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit1657863956348297978/ct_database, parameters:null)	
2018-05-25 11:43:00,290 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 74: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:43:00,291 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:43:00,297 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:43:00,298 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:43:00,298 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:43:00,299 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit1657863956348297978/ct_database
2018-05-25 11:43:00,310 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:43:00,310 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 74: Cleaning up thread local RawStore...
2018-05-25 11:43:00,310 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:43:00,310 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 74: Done cleaning up thread local RawStore
2018-05-25 11:43:00,310 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:43:00,311 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 25
Tests run: 25, Failures: 0, Errors: 25, Skipped: 0, Time elapsed: 59.638 sec <<< FAILURE!
unpartitionedTableMetadataUpdate(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 5.445 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedTableHousekeepingEnabledWithAudit(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.347 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedView(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.17 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

multipleTransformationsApplied(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.351 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

noTablesReplicated(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.408 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

unpartitionedTableHousekeepingEnabledWithAudit(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.165 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedTableUrlEncodedPaths(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.189 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionTableReplicateIgnoringMissingData(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.104 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

unpartitionedViewWithMappings(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.025 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

unpartitionedTableReplicateAvroSchema(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.511 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedViewFailure(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.315 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

unpartitionedTableMetadataUpdateAvroSchema(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.047 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

unpartitionedTableHousekeepingEnabledNoAudit(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.063 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

housekeepingOnly(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 1.99 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

twoTablesWithGraphiteNoHousekeeping(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.282 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedTableHousekeepingEnabledNoAuditPartialReplication(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.039 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

unpartitionedTableReplicateAvroSchemaOverride(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.076 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedTableMetadataUpdateAvroSchema(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.455 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedTablePartitionFilterGenerationEnabled(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 1.948 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedTableMetadataMirror(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 1.954 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

replicaInSourceMetastore(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.002 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedTableMetadataUpdate(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 1.963 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedTableHousekeepingEnabledNoAudit(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 1.957 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

unpartitionedView(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 1.986 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

unpartitionedTableMetadataMirror(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)  Time elapsed: 2.015 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running com.hotels.bdp.circustrain.integration.CircusTrainHdfsS3IntegrationTest
2018-05-25 11:43:01,026 INFO  org.gaul.shaded.org.eclipse.jetty.util.log:186 - Logging initialized @60666ms
2018-05-25 11:43:01,187 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 75: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:43:01,188 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:43:01,198 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:43:01,198 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:43:01,570 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:43:02,006 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:43:02,006 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:43:02,008 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:43:02,056 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:43:02,057 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:43:02,077 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:43:02,078 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:43:02,078 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58528]...
2018-05-25 11:43:02,078 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:43:02,078 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:43:02,078 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:43:03,113 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58528
2018-05-25 11:43:03,114 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 26
2018-05-25 11:43:03,115 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:03,115 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58528
2018-05-25 11:43:03,116 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 27
2018-05-25 11:43:03,117 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:03,117 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 77: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit342209462620703023/ct_database, parameters:null)
2018-05-25 11:43:03,117 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit342209462620703023/ct_database, parameters:null)	
2018-05-25 11:43:03,160 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 77: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:43:03,161 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:43:03,175 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:43:03,175 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:43:03,177 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:43:03,178 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit342209462620703023/ct_database
2018-05-25 11:43:03,242 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:43:03,242 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 77: Cleaning up thread local RawStore...
2018-05-25 11:43:03,242 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:43:03,242 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 77: Done cleaning up thread local RawStore
2018-05-25 11:43:03,242 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:43:03,244 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 26
2018-05-25 11:43:03,528 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 78: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:43:03,529 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:43:03,546 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:43:03,546 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:43:03,981 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:43:04,514 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:43:04,514 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:43:04,516 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:43:04,561 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:43:04,562 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:43:04,594 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:43:04,595 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:43:04,595 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58532]...
2018-05-25 11:43:04,595 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:43:04,595 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:43:04,595 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:43:05,631 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58532
2018-05-25 11:43:05,632 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 27
2018-05-25 11:43:05,632 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:05,633 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58532
2018-05-25 11:43:05,634 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 28
2018-05-25 11:43:05,634 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:05,635 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 80: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2347185970970678283/ct_database, parameters:null)
2018-05-25 11:43:05,635 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2347185970970678283/ct_database, parameters:null)	
2018-05-25 11:43:05,664 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 80: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:43:05,665 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:43:05,672 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:43:05,672 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:43:05,672 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:43:05,673 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2347185970970678283/ct_database
2018-05-25 11:43:05,684 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:43:05,684 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 80: Cleaning up thread local RawStore...
2018-05-25 11:43:05,684 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:43:05,684 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 80: Done cleaning up thread local RawStore
2018-05-25 11:43:05,685 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:43:05,685 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 27
2018-05-25 11:43:05,857 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 81: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:43:05,858 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:43:05,870 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:43:05,870 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:43:06,234 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:43:06,689 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:43:06,689 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:43:06,691 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:43:06,746 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:43:06,747 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:43:06,767 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:43:06,767 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:43:06,767 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58542]...
2018-05-25 11:43:06,767 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:43:06,767 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:43:06,767 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:43:07,807 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58542
2018-05-25 11:43:07,809 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 28
2018-05-25 11:43:07,809 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:07,810 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58542
2018-05-25 11:43:07,811 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 29
2018-05-25 11:43:07,811 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:07,812 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 83: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8705218437804457223/ct_database, parameters:null)
2018-05-25 11:43:07,812 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8705218437804457223/ct_database, parameters:null)	
2018-05-25 11:43:07,842 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 83: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:43:07,842 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:43:07,850 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:43:07,850 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:43:07,850 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:43:07,851 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit8705218437804457223/ct_database
2018-05-25 11:43:07,863 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:43:07,863 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 83: Cleaning up thread local RawStore...
2018-05-25 11:43:07,863 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:43:07,863 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 83: Done cleaning up thread local RawStore
2018-05-25 11:43:07,863 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:43:07,864 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 28
Tests run: 3, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 7.53 sec <<< FAILURE!
partitionedTableWithNoPartitions(com.hotels.bdp.circustrain.integration.CircusTrainHdfsS3IntegrationTest)  Time elapsed: 2.113 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedTableWithNoPartitionsMetadataUpdate(com.hotels.bdp.circustrain.integration.CircusTrainHdfsS3IntegrationTest)  Time elapsed: 2.233 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

unpartitionedTable(com.hotels.bdp.circustrain.integration.CircusTrainHdfsS3IntegrationTest)  Time elapsed: 2.065 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running com.hotels.bdp.circustrain.integration.CircusTrainS3S3IntegrationTest
2018-05-25 11:43:08,054 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 84: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:43:08,055 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:43:08,067 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:43:08,068 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:43:08,433 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:43:08,863 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:43:08,863 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:43:08,864 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:43:08,913 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:43:08,914 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:43:08,937 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:43:08,937 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:43:08,937 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58547]...
2018-05-25 11:43:08,937 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:43:08,937 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:43:08,937 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:43:09,970 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58547
2018-05-25 11:43:09,970 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 29
2018-05-25 11:43:09,971 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:09,972 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58547
2018-05-25 11:43:09,972 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 30
2018-05-25 11:43:09,973 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:09,973 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 86: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7337300484821373586/ct_database, parameters:null)
2018-05-25 11:43:09,973 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7337300484821373586/ct_database, parameters:null)	
2018-05-25 11:43:10,001 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 86: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:43:10,001 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:43:10,009 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:43:10,009 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:43:10,010 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:43:10,010 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit7337300484821373586/ct_database
2018-05-25 11:43:10,023 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:43:10,023 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 86: Cleaning up thread local RawStore...
2018-05-25 11:43:10,023 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:43:10,023 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 86: Done cleaning up thread local RawStore
2018-05-25 11:43:10,023 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:43:10,024 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 29
2018-05-25 11:43:10,256 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 87: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:43:10,257 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:43:10,267 INFO  DataNucleus.Persistence:77 - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2018-05-25 11:43:10,267 INFO  DataNucleus.Persistence:77 - Property datanucleus.cache.level2 unknown - will be ignored
2018-05-25 11:43:10,618 INFO  org.apache.hadoop.hive.metastore.ObjectStore:524 - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2018-05-25 11:43:11,049 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:43:11,049 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:43:11,051 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database default, returning NoSuchObjectException
2018-05-25 11:43:11,104 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:694 - Added admin role in metastore
2018-05-25 11:43:11,105 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:703 - Added public role in metastore
2018-05-25 11:43:11,138 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:743 - No user is added in admin role, since config is empty
2018-05-25 11:43:11,138 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7172 - Starting DB backed MetaStore Server with SetUGI enabled
2018-05-25 11:43:11,138 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7252 - Started the new metaserver on port [58551]...
2018-05-25 11:43:11,138 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7254 - Options.minWorkerThreads = 200
2018-05-25 11:43:11,138 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7256 - Options.maxWorkerThreads = 1000
2018-05-25 11:43:11,138 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:7258 - TCP keepalive = true
2018-05-25 11:43:12,170 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58551
2018-05-25 11:43:12,170 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 30
2018-05-25 11:43:12,171 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:12,172 INFO  hive.metastore:407 - Trying to connect to metastore with URI thrift://localhost:58551
2018-05-25 11:43:12,172 INFO  hive.metastore:481 - Opened a connection to metastore, current connections: 31
2018-05-25 11:43:12,173 INFO  hive.metastore:534 - Connected to metastore.
2018-05-25 11:43:12,173 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 89: source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2006644614841468708/ct_database, parameters:null)
2018-05-25 11:43:12,173 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ct_database, description:null, locationUri:file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2006644614841468708/ct_database, parameters:null)	
2018-05-25 11:43:12,199 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:610 - 89: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2018-05-25 11:43:12,199 INFO  org.apache.hadoop.hive.metastore.ObjectStore:401 - ObjectStore, initialize called
2018-05-25 11:43:12,206 INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql:146 - Using direct SQL, underlying DB is DERBY
2018-05-25 11:43:12,207 INFO  org.apache.hadoop.hive.metastore.ObjectStore:315 - Initialized ObjectStore
2018-05-25 11:43:12,207 WARN  org.apache.hadoop.hive.metastore.ObjectStore:721 - Failed to get database ct_database, returning NoSuchObjectException
2018-05-25 11:43:12,207 INFO  org.apache.hadoop.hive.common.FileUtils:520 - Creating directory if it doesn't exist: file:/var/folders/jj/xjyn53ws44l7x5n_pnh0h3x067p7tm/T/junit2006644614841468708/ct_database
2018-05-25 11:43:12,220 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler:204 - java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.fs.shell.XAttrCommands$GetfattrCommand
	at sun.reflect.GeneratedConstructorAccessor243.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:132)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:125)
	at org.apache.hadoop.fs.shell.CommandFactory.getInstance(CommandFactory.java:109)
	at org.apache.hadoop.fs.FsShell.printInfo(FsShell.java:222)
	at org.apache.hadoop.fs.FsShell.printUsage(FsShell.java:185)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:326)
	at org.apache.hadoop.hive.io.HdfsUtils.run(HdfsUtils.java:201)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:124)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:94)
	at org.apache.hadoop.hive.io.HdfsUtils.setFullFileStatus(HdfsUtils.java:77)
	at org.apache.hadoop.hive.common.FileUtils.mkdir(FileUtils.java:544)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:876)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:935)
	at sun.reflect.GeneratedMethodAccessor81.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy13.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10721)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:10705)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2018-05-25 11:43:12,220 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 89: Cleaning up thread local RawStore...
2018-05-25 11:43:12,220 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2018-05-25 11:43:12,220 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore:777 - 89: Done cleaning up thread local RawStore
2018-05-25 11:43:12,221 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit:309 - ugi=cedwards	ip=127.0.0.1	cmd=Done cleaning up thread local RawStore	
2018-05-25 11:43:12,222 INFO  hive.metastore:564 - Closed a connection to metastore, current connections: 30
Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 4.35 sec <<< FAILURE!
unpartitionedTable(com.hotels.bdp.circustrain.integration.CircusTrainS3S3IntegrationTest)  Time elapsed: 2.024 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

partitionedTableWithNoPartitionsMirror(com.hotels.bdp.circustrain.integration.CircusTrainS3S3IntegrationTest)  Time elapsed: 2.073 sec  <<< ERROR!
org.apache.thrift.transport.TTransportException
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_create_database(ThriftHiveMetastore.java:749)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.create_database(ThriftHiveMetastore.java:736)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)
	at com.hotels.beeju.BeejuJUnitRule.createDatabase(BeejuJUnitRule.java:170)
	at com.hotels.beeju.HiveMetaStoreJUnitRule.createDatabase(HiveMetaStoreJUnitRule.java:53)
	at com.hotels.beeju.BeejuJUnitRule.before(BeejuJUnitRule.java:114)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:46)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)


Results :

Tests in error: 
  unpartitionedTableMetadataUpdate(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionedTableHousekeepingEnabledWithAudit(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionedView(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  multipleTransformationsApplied(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  noTablesReplicated(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  unpartitionedTableHousekeepingEnabledWithAudit(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionedTableUrlEncodedPaths(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionTableReplicateIgnoringMissingData(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  unpartitionedViewWithMappings(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  unpartitionedTableReplicateAvroSchema(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionedViewFailure(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  unpartitionedTableMetadataUpdateAvroSchema(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  unpartitionedTableHousekeepingEnabledNoAudit(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  housekeepingOnly(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  twoTablesWithGraphiteNoHousekeeping(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionedTableHousekeepingEnabledNoAuditPartialReplication(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  unpartitionedTableReplicateAvroSchemaOverride(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionedTableMetadataUpdateAvroSchema(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionedTablePartitionFilterGenerationEnabled(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionedTableMetadataMirror(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  replicaInSourceMetastore(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionedTableMetadataUpdate(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionedTableHousekeepingEnabledNoAudit(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  unpartitionedView(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  unpartitionedTableMetadataMirror(com.hotels.bdp.circustrain.integration.CircusTrainHdfsHdfsIntegrationTest)
  partitionedTableWithNoPartitions(com.hotels.bdp.circustrain.integration.CircusTrainHdfsS3IntegrationTest)
  partitionedTableWithNoPartitionsMetadataUpdate(com.hotels.bdp.circustrain.integration.CircusTrainHdfsS3IntegrationTest)
  unpartitionedTable(com.hotels.bdp.circustrain.integration.CircusTrainHdfsS3IntegrationTest)
  unpartitionedTable(com.hotels.bdp.circustrain.integration.CircusTrainS3S3IntegrationTest)
  partitionedTableWithNoPartitionsMirror(com.hotels.bdp.circustrain.integration.CircusTrainS3S3IntegrationTest)

Tests run: 30, Failures: 0, Errors: 30, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Circus Train Parent ................................ SUCCESS [  1.619 s]
[INFO] API ................................................ SUCCESS [  5.126 s]
[INFO] Circus Train Avro .................................. SUCCESS [  3.583 s]
[INFO] Hive ............................................... SUCCESS [  2.989 s]
[INFO] Comparator ......................................... SUCCESS [ 24.313 s]
[INFO] Core ............................................... SUCCESS [ 30.764 s]
[INFO] AWS utils .......................................... SUCCESS [  1.490 s]
[INFO] Metrics ............................................ SUCCESS [  2.364 s]
[INFO] DistCp Copier ...................................... SUCCESS [  3.726 s]
[INFO] Google Cloud Platform Utils ........................ SUCCESS [  4.163 s]
[INFO] Common Test Classes ................................ SUCCESS [  4.803 s]
[INFO] S3 MapReduce Copy .................................. SUCCESS [01:53 min]
[INFO] S3MapReduceCp Copier ............................... SUCCESS [  1.654 s]
[INFO] S3 To S3 Copier .................................... SUCCESS [  3.859 s]
[INFO] Circus Train Housekeeping .......................... SUCCESS [  0.874 s]
[INFO] Hive View .......................................... SUCCESS [  4.413 s]
[INFO] Integration Tests .................................. FAILURE [01:13 min]
[INFO] CT packager ........................................ SKIPPED
[INFO] AWS/SNS Events ..................................... SKIPPED
[INFO] Tools Parent ....................................... SKIPPED
[INFO] Tools Core ......................................... SKIPPED
[INFO] Filter tool ........................................ SKIPPED
[INFO] Vacuum tool ........................................ SKIPPED
[INFO] Comparison tool .................................... SKIPPED
[INFO] Tool Package ....................................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 04:43 min
[INFO] Finished at: 2018-05-25T11:43:12+01:00
[INFO] Final Memory: 158M/827M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.12.4:test (default-test) on project circus-train-integration-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/cedwards/Documents/workspace/circus-train/circus-train-integration-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :circus-train-integration-tests
